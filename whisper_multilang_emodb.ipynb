{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8629e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/115/115_f_32_4_5_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/115/115_f_32_4_6_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/115/115_f_32_4_3_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/115/115_f_32_4_1_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/115/115_f_32_4_0_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/115/115_f_32_4_4_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/115/115_f_32_4_2_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/002/VID20230426143437.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/002/VID20230426143418.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/013/013_f_028_1_0_BA_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/013/013_f_028_1_6_BA_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/013/013_f_028_1_1_BA_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/013/013_f_028_1_2_BA_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/013/013_f_028_1_3_BA_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/013/013_f_028_1_4_BA_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/013/013_f_028_1_5_BA_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/027/027_m_024_1_0_KA_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/027/027_m_024_1_6_KA_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/027/027_m_024_1_5_KA_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/027/027_m_024_1_4_KA_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/027/027_m_024_1_3_KA_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/027/027_m_024_1_2_KA_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/027/027_m_024_1_1_KA_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/028/028_m_025_1_0_UR_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/028/028_m_025_1_6_UR_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/028/028_m_025_1_5_UR_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/028/028_m_025_1_4_UR_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/028/028_m_025_1_1_UR_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/028/028_m_025_1_2_UR_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 4/028/028_m_025_1_3_UR_4.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/013/013_f_028_1_5_BA_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/013/013_f_028_1_0_BA_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/013/013_f_028_1_6_BA_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/013/013_f_028_1_4_BA_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/013/013_f_028_1_3_BA_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/013/013_f_028_1_2_BA_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/013/013_f_028_1_1_BA_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/002/VID20230426142728.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/002/VID20230426142718.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/027/027_m_024_1_6_KA_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/027/027_m_024_1_0_KA_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/027/027_m_024_1_4_KA_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/027/027_m_024_1_2_KA_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/027/027_m_024_1_3_KA_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/027/027_m_024_1_1_KA_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/027/027_m_024_1_5_KA_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/107/107_m_22_3_0_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/107/107_m_22_3_5_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/107/107_m_22_3_6_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/107/107_m_22_3_4_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/107/107_m_22_3_3_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/107/107_m_22_3_1_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/107/107_m_22_3_2_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/108/108_m_22_3_0_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/108/108_m_22_3_1_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/108/108_m_22_3_6_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/108/108_m_22_3_3_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/108/108_m_22_3_2_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/108/108_m_22_3_4_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/115/115_f_32_3_0_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/115/115_f_32_3_5_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/115/115_f_32_3_2_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/115/115_f_32_3_4_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/115/115_f_32_3_3_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/115/115_f_32_3_1_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/115/115_f_32_3_6_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/028/028_m_025_1_0_UR_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/028/028_m_025_1_6_UR_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/028/028_m_025_1_5_UR_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/028/028_m_025_1_4_UR_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/028/028_m_025_1_3_UR_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/028/028_m_025_1_2_UR_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 3/028/028_m_025_1_1_UR_3.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/019/20230427_111433.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_6_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_0_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_5_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_4_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_1_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_3_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_2_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_1_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_5_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_6_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_4_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_0_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_2_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_3_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_5_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_3_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_4_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_1_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_6_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_0_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_2_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/026/20230504_120200.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_0_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_1_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_2_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_3_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_4_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_5_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_6_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_2_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_4_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_3_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_0_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_5_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_1_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_6_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_0_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_1_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_2_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_3_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_4_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_5_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_6_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/108/108_m_22_1_6_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/108/108_m_22_1_4_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/108/108_m_22_1_5_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/108/108_m_22_1_3_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/108/108_m_22_1_2_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/108/108_m_22_1_0_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/108/108_m_22_1_1_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/107/107_m_22_1_4_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/107/107_m_22_1_0_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/107/107_m_22_1_1_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/107/107_m_22_1_2_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/107/107_m_22_1_3_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/107/107_m_22_1_5_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/107/107_m_22_1_6_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/115/115_f_32_1_0_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/115/115_f_32_1_5_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/115/115_f_32_1_4_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/115/115_f_32_1_3_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/115/115_f_32_1_1_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/115/115_f_32_1_2_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/115/115_f_32_1_6_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/013/013_f_28_0_0_PK_1.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/013/013_f_28_0_6_PK_1.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/013/013_f_28_0_5_PK_1.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/013/013_f_28_0_2_PK_1.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/013/013_f_28_0_4_PK_1.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/013/013_f_28_0_3_PK_1.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/013/013_f_28_0_1_PK_1.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/028/028_m_25_0_0_PK_1.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/028/028_m_25_0_6_PK_1.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/028/028_m_25_0_4_PK_1.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/028/028_m_25_0_5_PK_1.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/028/028_m_25_0_1_PK_1.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/028/028_m_25_0_2_PK_1.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/028/028_m_25_0_3_PK_1.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 1/023/MVI_0509.MOV\n",
      "CSV creato: NEWEMODB/dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# QUESTO PER EMODB!!!!\n",
    "#\n",
    "#  creare csv con file path e path audio corrispondente CON BABELE\n",
    "# dataset è composto da video_path, audio_path (estratto), label {0: eng, 1: ita, 2: sp, 3: fr}\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import torch\n",
    "\n",
    "os.environ[\"ACCELERATE_MIXED_PRECISION\"] = \"no\"\n",
    "os.environ.pop(\"USE_FP16\", None)\n",
    "os.environ.setdefault(\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\", \"0.0\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "dataset_dir = \"/Volumes/Crucial X9/EMODB\"\n",
    "audio_dir   = os.path.join(\"NEWEMODB/audio_wav\")\n",
    "csv_path    = os.path.join(\"NEWEMODB/dataset.csv\")\n",
    "os.makedirs(audio_dir, exist_ok=True)\n",
    "\n",
    "video_paths = glob.glob(os.path.join(dataset_dir, \"**/*.mp4\"), recursive=True) + \\\n",
    "              glob.glob(os.path.join(dataset_dir, \"**/*.MOV\"), recursive=True)\n",
    "\n",
    "rows = []\n",
    "for vp in video_paths:\n",
    "    if   \"EN\" in vp: label = 0\n",
    "    elif \"IT\" in vp: label = 1\n",
    "    #elif \"French\"  in vp: label = 3\n",
    "    elif \"SP\" in vp: label = 2\n",
    "    else:\n",
    "        print(\"Lingua non riconosciuta → salto:\", vp)\n",
    "        continue\n",
    "\n",
    "    fname = os.path.splitext(os.path.basename(vp))[0]\n",
    "    wav   = os.path.join(audio_dir, f\"{fname}{label}language.wav\")\n",
    "\n",
    "    if not os.path.exists(wav):\n",
    "        res = subprocess.run(\n",
    "            [\"ffmpeg\", \"-i\", vp, \"-ar\", \"16000\", \"-ac\", \"1\",\n",
    "             \"-f\", \"wav\", \"-vn\", wav],\n",
    "            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL\n",
    "        )\n",
    "        if res.returncode != 0:\n",
    "            print(\"ffmpeg errore → salto:\", vp)\n",
    "            continue        # non appendere se fallita conversione\n",
    "\n",
    "    rows.append({\"audio_path\": wav, \"video_path\": vp, \"label\": label})\n",
    "\n",
    "\n",
    "if not os.path.exists(csv_path):\n",
    "    import pandas as pd\n",
    "    pd.DataFrame(rows).to_csv(csv_path, index=False)\n",
    "    print(f\"CSV creato: {csv_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d9a6428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/035/035_m_022_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/035/035_m_022_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/035/035_m_022_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/035/035_m_022_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/035/035_m_022_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/035/035_m_022_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/035/035_m_022_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/120/120_m_29_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/120/120_m_29_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/120/120_m_29_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/120/120_m_29_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/120/120_m_29_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/120/120_m_29_2_3_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/120/120_m_29_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/019/019_m_022_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/019/20230427_111433.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/019/019_m_022_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/019/019_m_022_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/019/019_m_022_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/019/019_m_022_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/019/019_m_022_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/102/102_m_18_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/102/102_m_18_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/102/102_m_18_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/102/102_m_18_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/102/102_m_18_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/102/102_m_18_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/102/102_m_18_2_3_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/109/109_f_22_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/109/109_f_22_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/109/109_f_22_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/109/109_f_22_2_3_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/109/109_f_22_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/109/109_f_22_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/109/109_f_22_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_3_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_6_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_0_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_5_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_4_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_1_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_3_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/108/108_m_22_2_2_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/105/105_m_18_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/105/105_m_18_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/105/105_m_18_2_3_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/105/105_m_18_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/105/105_m_18_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/105/105_m_18_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/105/105_m_18_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/032/032_f_022_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/032/032_f_022_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/032/032_f_022_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/032/032_f_022_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/032/032_f_022_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/032/032_f_022_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/032/032_f_022_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/112/112_m_19_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/112/112_m_19_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/112/112_m_19_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/112/112_m_19_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/112/112_m_19_2_3_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/112/112_m_19_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/112/112_m_19_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/113/113_f_27_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/113/113_f_27_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/113/113_f_27_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/113/113_f_27_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/113/113_f_27_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/113/113_f_27_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/004/004_m_025_0_0_EN_1.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/004/004_m_025_0_5_EN_1.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/004/004_m_025_0_2_EN_1.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/004/004_m_025_0_3_EN_1.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/004/004_m_025_0_6_EN_1.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/004/004_m_025_0_4_EN_1.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/004/004_m_025_0_1_EN_1.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/003/003_f_021_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/003/003_f_021_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/003/003_f_021_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/003/003_f_021_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/003/003_f_021_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/003/003_f_021_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/003/003_f_021_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/007/007_m_25_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/007/007_m_025_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/007/007_m_025_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/007/007_m_025_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/007/007_m_025_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/007/007_m_25_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/007/007_m_25_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/010/010_m_026_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/010/010_m_026_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/010/010_m_026_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/010/010_m_026_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/010/010_m_026_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/010/010_m_026_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/010/010_m_026_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/006/006_f_024_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/006/006_f_024_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/006/006_f_024_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/006/006_f_024_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/006/006_f_024_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/006/006_f_024_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/006/006_f_024_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/025/025_m_022_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/025/025_m_022_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/025/025_m_022_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/025/025_m_022_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/025/025_m_022_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/025/025_m_022_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/025/025_m_022_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/002/002_m_022_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/002/002_m_022_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/002/002_m_022_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/002/002_m_022_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/002/002_m_022_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/002/002_m_022_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/002/002_m_022_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/005/005_m_026_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/005/005_m_026_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/005/005_m_026_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/005/005_m_026_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/005/005_m_026_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/005/005_m_026_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/005/005_m_026_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/033/033_m_022_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/033/033_m_022_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/033/033_m_022_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/033/033_m_022_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/033/033_m_022_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/033/033_m_022_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/033/033_m_022_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_3_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_1_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_5_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_6_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_4_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_0_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_2_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/107/107_m_22_2_3_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_5_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_3_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_3_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_4_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_1_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_6_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_0_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/115/115_f_32_2_2_OT.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/018/018_m_024_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/018/018_m_024_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/018/018_m_024_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/018/018_m_024_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/018/018_m_024_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/018/018_m_024_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/018/018_m_024_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/020/020_m_022_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/020/020_m_022_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/020/020_m_022_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/020/020_m_022_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/020/020_m_022_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/020/020_m_022_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/020/020_m_022_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/029/029_m_022_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/029/029_m_022_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/029/029_m_022_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/029/029_m_022_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/029/029_m_022_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/029/029_m_022_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/029/029_m_022_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/104/104_m_18_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/104/104_m_18_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/104/104_m_18_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/104/104_m_18_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/104/104_m_18_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/104/104_m_18_2_3_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/104/104_m_18_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/106/106_m_18_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/106/106_m_18_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/106/106_m_18_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/106/106_m_18_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/106/106_m_18_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/106/106_m_18_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/106/106_m_18_2_3_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/111/111_m_23_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/111/111_m_23_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/111/111_m_23_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/111/111_m_23_2_3_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/111/111_m_23_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/111/111_m_23_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/111/111_m_23_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/114/114_m_25_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/114/114_m_25_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/114/114_m_25_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/114/114_m_25_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/114/114_m_25_2_3_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/114/114_m_25_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/114/114_m_25_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/118/118_m_23_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/118/118_m_23_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/118/118_m_23_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/118/118_m_23_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/118/118_m_23_2_3_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/118/118_m_23_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/118/118_m_23_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/021/021_m_023_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/021/021_m_023_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/021/021_m_023_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/021/021_m_023_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/021/021_m_023_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/021/021_m_023_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/021/021_m_023_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/026/026_m_022_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/026/026_m_022_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/026/026_m_022_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/026/026_m_022_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/026/026_m_022_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/026/026_m_022_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/026/20230504_120200.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/034/034_m_022_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/034/034_m_022_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/034/034_m_022_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/034/034_m_022_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/034/034_m_022_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/034/034_m_022_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/034/034_m_022_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/101/101_f_23_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/101/101_f_23_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/101/101_f_23_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/101/101_f_23_2_3_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/101/101_f_23_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/101/101_f_23_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/101/101_f_23_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/103/103_f_18_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/103/103_f_18_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/103/103_f_18_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/103/103_f_18_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/103/103_f_18_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/103/103_f_18_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/103/103_f_18_2_3_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/110/110_m_27_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/110/110_m_27_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/110/110_m_27_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/110/110_m_27_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/110/110_m_27_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/110/110_m_27_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/110/110_m_27_2_3_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/119/119_m_23_2_0_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/119/119_m_23_2_3_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/119/119_m_23_2_6_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/119/119_m_23_2_5_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/119/119_m_23_2_2_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/119/119_m_23_2_1_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/119/119_m_23_2_4_EN.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/011/011_m_026_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/011/011_m_026_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/011/011_m_026_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/011/011_m_026_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/011/011_m_026_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/011/011_m_026_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/011/011_m_026_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/015/015_m_27_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/015/015_m_27_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/015/015_m_27_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/015/015_m_27_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/015/015_m_27_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/015/015_m_27_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/015/015_m_27_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/017/017_f_023_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/017/017_f_023_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/017/017_f_023_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/017/017_f_023_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/017/017_f_023_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/017/017_f_023_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/017/017_f_023_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/022/022_m_022_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/022/022_m_022_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/022/022_m_022_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/022/022_m_022_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/022/022_m_022_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/022/022_m_022_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/022/022_m_022_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_0_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_1_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_2_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_3_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_4_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_5_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/027/027_m_024_0_6_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/030/030_m_025_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/030/030_m_025_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/030/030_m_025_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/030/030_m_025_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/030/030_m_025_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/030/030_m_025_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/030/030_m_025_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/031/031_m_026_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/031/031_m_026_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/031/031_m_026_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/031/031_m_026_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/031/031_m_026_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/031/031_m_026_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/031/031_m_026_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/037/037_m_023_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/037/037_m_023_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/037/037_m_023_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/037/037_m_023_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/037/037_m_023_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/037/037_m_023_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/037/037_m_023_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/040/040_m_024_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/040/040_m_024_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/040/040_m_024_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/040/040_m_024_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/040/040_m_024_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/040/040_m_024_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/040/040_m_024_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/012/012_m_023_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/012/012_m_023_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/012/012_m_023_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/012/012_m_023_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/012/012_m_023_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/012/012_m_023_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/012/012_m_023_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/016/016_f_25_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/016/016_f_25_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/016/016_f_25_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/016/016_f_25_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/016/016_f_25_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/016/016_f_25_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/016/016_f_25_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_2_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_4_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_3_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_0_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_5_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_1_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/028/028_m_025_0_6_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/038/038_m_027_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/038/038_m_027_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/038/038_m_027_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/038/038_m_027_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/038/038_m_027_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/038/038_m_027_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/038/038_m_027_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/008/008_m_041_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/008/008_m_041_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/008/008_m_041_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/008/008_m_041_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/008/008_m_041_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/008/008_m_041_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/008/008_m_041_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/009/009_f_025_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/009/009_f_025_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/009/009_f_025_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/009/009_f_025_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/009/009_f_025_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/009/009_f_025_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/009/009_f_025_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_0_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_1_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_2_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_3_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_4_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_5_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/013/013_f_028_0_6_PK_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/014/014_f_019_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/014/014_f_019_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/014/014_f_019_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/014/014_f_019_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/014/014_f_019_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/014/014_f_019_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/014/014_f_019_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/023/023_m_022_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/023/023_m_022_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/023/023_m_022_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/023/023_m_022_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/023/023_m_022_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/023/023_m_022_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/023/023_m_022_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/024/024_m_022_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/024/024_m_022_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/024/024_m_022_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/024/024_m_022_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/024/024_m_022_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/024/024_m_022_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/024/024_m_022_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/036/036_m_023_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/036/036_m_023_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/036/036_m_023_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/036/036_m_023_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/036/036_m_023_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/036/036_m_023_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/036/036_m_023_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/039/039_m_022_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/039/039_m_022_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/039/039_m_022_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/039/039_m_022_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/039/039_m_022_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/039/039_m_022_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/039/039_m_022_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/041/041_m_023_0_0_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/041/041_m_023_0_1_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/041/041_m_023_0_2_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/041/041_m_023_0_3_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/041/041_m_023_0_4_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/041/041_m_023_0_5_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/041/041_m_023_0_6_EN_2.mp4\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/045/045_f_22_0_1_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/045/045_f_22_0_2_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/045/045_f_22_0_0_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/045/045_f_22_0_4_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/045/045_f_22_0_3_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/045/045_f_22_0_5_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/045/045_f_22_0_6_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/042/042_f_26_0_0_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/042/042_f_26_0_1_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/042/042_f_26_0_2_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/042/042_f_26_0_5_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/042/042_f_26_0_3_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/042/042_f_26_0_6_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/042/042_f_26_0_4_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/043/043_f_22_0_1_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/043/043_f_22_0_0_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/043/043_f_22_0_2_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/043/043_f_22_0_3_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/043/043_f_22_0_4_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/043/043_f_22_0_6_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/043/043_f_22_0_5_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/044/044_f_22_0_1_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/044/044_f_22_0_0_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/044/044_f_22_0_2_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/044/044_f_22_0_3_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/044/044_f_22_0_4_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/044/044_f_22_0_5_EN_2.MOV\n",
      "Lingua non riconosciuta → salto: /Volumes/Crucial X9/EMODB/Session 2/044/044_f_22_0_6_EN_2.MOV\n",
      "CSV creato: NEWEMODB/dataset_noeng.csv\n"
     ]
    }
   ],
   "source": [
    "# QUESTO PER EMODB - prendere sessione 2 solo con i video in italiano e in spagnolo!!!!\n",
    "#\n",
    "#  creare csv con file path e path audio corrispondente CON BABELE\n",
    "# dataset è composto da video_path, audio_path (estratto), label {0: eng, 1: ita, 2: sp, 3: fr}\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import torch\n",
    "\n",
    "os.environ[\"ACCELERATE_MIXED_PRECISION\"] = \"no\"\n",
    "os.environ.pop(\"USE_FP16\", None)\n",
    "os.environ.setdefault(\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\", \"0.0\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "dataset_dir = \"/Volumes/Crucial X9/EMODB/Session 2\"\n",
    "audio_dir   = os.path.join(\"NEWEMODB/audio_wav\")\n",
    "csv_path    = os.path.join(\"NEWEMODB/dataset_noeng.csv\")\n",
    "os.makedirs(audio_dir, exist_ok=True)\n",
    "\n",
    "video_paths = glob.glob(os.path.join(dataset_dir, \"**/*.mp4\"), recursive=True) + \\\n",
    "              glob.glob(os.path.join(dataset_dir, \"**/*.MOV\"), recursive=True)\n",
    "\n",
    "rows = []\n",
    "for vp in video_paths:\n",
    "    #if   \"EN\" in vp: label = 0\n",
    "    if \"IT\" in vp: label = 1\n",
    "    #elif \"French\"  in vp: label = 3\n",
    "    elif \"SP\" in vp: label = 2\n",
    "    else:\n",
    "        print(\"Lingua non riconosciuta → salto:\", vp)\n",
    "        continue\n",
    "\n",
    "    fname = os.path.splitext(os.path.basename(vp))[0]\n",
    "    wav   = os.path.join(audio_dir, f\"{fname}{label}language.wav\")\n",
    "\n",
    "    if not os.path.exists(wav):\n",
    "        res = subprocess.run(\n",
    "            [\"ffmpeg\", \"-i\", vp, \"-ar\", \"16000\", \"-ac\", \"1\",\n",
    "             \"-f\", \"wav\", \"-vn\", wav],\n",
    "            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL\n",
    "        )\n",
    "        if res.returncode != 0:\n",
    "            print(\"ffmpeg errore → salto:\", vp)\n",
    "            continue        # non appendere se fallita conversione\n",
    "\n",
    "    rows.append({\"audio_path\": wav, \"video_path\": vp, \"label\": label})\n",
    "\n",
    "\n",
    "if not os.path.exists(csv_path):\n",
    "    import pandas as pd\n",
    "    pd.DataFrame(rows).to_csv(csv_path, index=False)\n",
    "    print(f\"CSV creato: {csv_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b0e381f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV creato: VidTIMIT/dataset.csv  (98 righe)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# build_vidtimit_csv.py\n",
    "# Crea NEWEMODB/dataset.csv con: video_path (cartella frame), audio_path (.wav), label=0\n",
    "\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "\n",
    "# ---- Config ----\n",
    "VIDTIMIT_ROOT = \"VidTIMIT/\"         \n",
    "OUT_DIR       = \"VidTIMIT/\"\n",
    "CSV_OUT       = os.path.join(OUT_DIR, \"dataset.csv\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Assunzione struttura:\n",
    "# VidTIMIT/<speaker>/audio/si649.wav\n",
    "# VidTIMIT/<speaker>/video/si649/001 002 003 ...\n",
    "spk_dirs = sorted([d for d in glob.glob(os.path.join(VIDTIMIT_ROOT, \"*\")) if os.path.isdir(d)])\n",
    "\n",
    "def has_frames(folder: str) -> bool:\n",
    "    # al minimo 1 file dentro (anche senza estensione)\n",
    "    try:\n",
    "        return any(os.path.isfile(os.path.join(folder, f)) for f in os.listdir(folder))\n",
    "    except FileNotFoundError:\n",
    "        return False\n",
    "\n",
    "for spk in spk_dirs:\n",
    "    audio_dir = os.path.join(spk, \"audio\")\n",
    "    video_dir = os.path.join(spk, \"video\")\n",
    "    if not (os.path.isdir(audio_dir) and os.path.isdir(video_dir)):\n",
    "        continue\n",
    "\n",
    "    wavs = sorted(glob.glob(os.path.join(audio_dir, \"*.wav\")))\n",
    "    for wav in wavs:\n",
    "        stem = os.path.splitext(os.path.basename(wav))[0]  # es: si649\n",
    "        frame_folder = os.path.join(video_dir, stem)\n",
    "        if not has_frames(frame_folder):\n",
    "            print(f\"[WARN] Niente frame per {wav} → skip\")\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"audio_path\": wav,            # .wav allineato\n",
    "            \"video_path\": frame_folder,   # cartella con i frame\n",
    "            \"label\": 0                    # VidTIMIT = inglese\n",
    "        })\n",
    "\n",
    "assert rows, \"Non ho trovato coppie audio+frame.\"\n",
    "pd.DataFrame(rows).to_csv(CSV_OUT, index=False)\n",
    "print(f\"✅ CSV creato: {CSV_OUT}  ({len(rows)} righe)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f16cc697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    98\n",
      "2    97\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    14\n",
      "2    14\n",
      "Name: persona, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "it_cont = 0\n",
    "sp_cont = 0\n",
    "\n",
    "df = pd.read_csv('/Users/ludovicagenovese/Documents/GitHub/mothertongueVSspoken/NEWEMODB/dataset_filtrato.csv')\n",
    "df = pd.DataFrame(df)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(df['label'].value_counts())\n",
    "df['persona'] = df['audio_path'].apply(lambda x: re.search(r'audio_wav/(\\d+)', x).group(1))\n",
    "\n",
    "cont = df.groupby('label')['persona'].nunique()\n",
    "\n",
    "\n",
    "print(cont)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9938c3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persone con label 1 scelte: ['002', '035', '021', '009', '034', '036', '026', '010', '016', '012', '024', '004', '032', '022']\n",
      "File salvato come dataset_filtrato.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "\n",
    "\n",
    "df = pd.read_csv('NEWEMODB/dataset_noeng.csv')\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "df['persona'] = df['audio_path'].apply(lambda x: re.search(r'audio_wav/(\\d+)', x).group(1))\n",
    "\n",
    "persone_label1 = df.loc[df['label'] == 1, 'persona'].unique()\n",
    "\n",
    "persone_label1_scelte = random.sample(list(persone_label1), 14)\n",
    "\n",
    "df_filtrato = df[( (df['label'] == 1) & (df['persona'].isin(persone_label1_scelte)) ) | (df['label'] == 2)]\n",
    "\n",
    "df_filtrato.to_csv('dataset_filtrato.csv', index=False)\n",
    "\n",
    "print(f\"Persone con label 1 scelte: {persone_label1_scelte}\")\n",
    "print(\"File salvato come dataset_filtrato.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3ee967a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Teacher: 100%|██████████| 195/195 [00:00<00:00, 4518.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Manifest scritto in NEWEMODB/distillation_dataset_filtrato.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import whisper, torch, soundfile as sf, json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ───── Config ─────────────────────────────────────────────\n",
    "MODEL   = \"small\"\n",
    "SR      = 16000\n",
    "CLIP_S  = 10\n",
    "CLIP_N  = CLIP_S * SR\n",
    "CSV_IN  = \"NEWEMODB/dataset_filtrato.csv\"            # video_path,audio_path,label\n",
    "CSV_OUT = \"NEWEMODB/distillation_dataset_filtrato.csv\"\n",
    "id2lang = {0: \"en\", 1: \"it\", 2: \"es\"}\n",
    "\n",
    "# ───── Load Whisper una sola volta ───────────────────────\n",
    "model  = whisper.load_model(MODEL)\n",
    "device = model.device\n",
    "\n",
    "# ───── Utility: verifica se i 3 file di output esistono ──\n",
    "def already_done(wav: str) -> bool:\n",
    "    return all(Path(wav + suff).is_file() for suff in\n",
    "               (\".hid.npy\", \".feat.npy\", \".probs.json\"))\n",
    "\n",
    "# ───── Main loop ─────────────────────────────────────────\n",
    "rows = []\n",
    "ds = pd.read_csv(CSV_IN)\n",
    "\n",
    "for vid, wav, lbl in tqdm(ds[[\"video_path\",\"audio_path\",\"label\"]].values,\n",
    "                          total=len(ds), desc=\"Teacher\"):\n",
    "\n",
    "    # ↓ Lenght del file senza caricarlo in RAM\n",
    "    n_frames = sf.info(wav).frames\n",
    "    mid      = n_frames // 2\n",
    "    start    = max(mid - CLIP_N // 2, 0)\n",
    "    end      = min(start + CLIP_N, n_frames)\n",
    "\n",
    "    hid_path   = wav + \".hid.npy\"\n",
    "    feats_path = wav + \".feat.npy\"\n",
    "    probs_path = wav + \".probs.json\"\n",
    "\n",
    "    if already_done(wav):\n",
    "        # File già processato → salta inferenza\n",
    "        rows.append([vid, wav, json.dumps([(start / SR, end / SR)]),\n",
    "                     probs_path, hid_path, feats_path, id2lang[lbl]])\n",
    "        continue\n",
    "\n",
    "    # ───── Pipeline completa (solo se non ancora fatto) ───\n",
    "    audio, sr = sf.read(wav)\n",
    "    if sr != SR:\n",
    "        raise ValueError(f\"{wav}: samplerate ≠ {SR} Hz\")\n",
    "    if audio.ndim == 2:\n",
    "        audio = audio.mean(axis=1)\n",
    "\n",
    "    clip = torch.from_numpy(audio[start:end]).float().to(device)\n",
    "    clip = whisper.pad_or_trim(clip)               # esattamente 10 s\n",
    "\n",
    "    mel = whisper.log_mel_spectrogram(clip).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, probs = model.detect_language(mel)\n",
    "        enc      = model.encoder(mel.unsqueeze(0))\n",
    "\n",
    "    enc_seq = enc.squeeze(0).cpu().numpy()         # [T, 768]\n",
    "    emb     = enc_seq.mean(0)                      # [768]\n",
    "\n",
    "    s = probs[\"en\"] + probs[\"it\"] + probs[\"es\"]\n",
    "    probs3 = {k: float(probs[k] / s) for k in (\"en\", \"it\", \"es\")}\n",
    "\n",
    "    np.save(hid_path,  emb)\n",
    "    np.save(feats_path, enc_seq)\n",
    "    json.dump(probs3, open(probs_path, \"w\"))\n",
    "\n",
    "    rows.append([vid, wav, json.dumps([(start / SR, end / SR)]),\n",
    "                 probs_path, hid_path, feats_path, id2lang[lbl]])\n",
    "\n",
    "# ───── Export manifest ───────────────────────────────────\n",
    "pd.DataFrame(rows,\n",
    "    columns=[\"video_path\",\"audio_path\",\"segments\",\n",
    "             \"probs_path\",\"hid_path\",\"feats_path\",\"label\"]\n",
    ").to_csv(CSV_OUT, index=False)\n",
    "\n",
    "print(\"✅  Manifest scritto in\", CSV_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e562d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(41575) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Teacher: 100%|██████████| 98/98 [01:36<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Manifest scritto in VidTIMIT/distillation_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import json, numpy as np, pandas as pd\n",
    "import whisper, torch, soundfile as sf\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import scipy.signal\n",
    "\n",
    "# ── Config ─────────────────────────────────────────────\n",
    "MODEL   = \"small\"\n",
    "SR      = 16000\n",
    "CLIP_S  = 10\n",
    "CLIP_N  = CLIP_S * SR\n",
    "CSV_IN  = \"VidTIMIT/dataset.csv\"\n",
    "CSV_OUT = \"VidTIMIT/distillation_dataset.csv\"\n",
    "id2lang = {0: \"en\", 1: \"it\", 2: \"es\"}\n",
    "\n",
    "# ── Load Whisper una sola volta ───────────────────────\n",
    "model  = whisper.load_model(MODEL)\n",
    "device = model.device\n",
    "\n",
    "def already_done(wav: str) -> bool:\n",
    "    return all(Path(wav + suff).is_file() for suff in\n",
    "               (\".hid.npy\", \".feat.npy\", \".probs.json\"))\n",
    "\n",
    "rows = []\n",
    "ds = pd.read_csv(CSV_IN)\n",
    "\n",
    "for vid, wav, lbl in tqdm(ds[[\"video_path\",\"audio_path\",\"label\"]].values,\n",
    "                          total=len(ds), desc=\"Teacher\"):\n",
    "\n",
    "    n_frames = sf.info(wav).frames\n",
    "    sr_orig  = sf.info(wav).samplerate\n",
    "    mid      = n_frames // 2\n",
    "    start    = max(mid - CLIP_N // 2, 0)\n",
    "    end      = min(start + CLIP_N, n_frames)\n",
    "\n",
    "    hid_path   = wav + \".hid.npy\"\n",
    "    feats_path = wav + \".feat.npy\"\n",
    "    probs_path = wav + \".probs.json\"\n",
    "\n",
    "    if already_done(wav):\n",
    "        rows.append([vid, wav, json.dumps([(start / SR, end / SR)]),\n",
    "                     probs_path, hid_path, feats_path, id2lang[int(lbl)]])\n",
    "        continue\n",
    "\n",
    "    audio, sr = sf.read(wav)\n",
    "    if audio.ndim == 2:\n",
    "        audio = audio.mean(axis=1)\n",
    "\n",
    "    if sr != SR:\n",
    "        gcd = np.gcd(sr, SR)\n",
    "        audio = scipy.signal.resample_poly(audio, SR // gcd, sr // gcd)\n",
    "        sr = SR\n",
    "\n",
    "    clip = torch.from_numpy(audio[start:end]).float().to(device)\n",
    "    clip = whisper.pad_or_trim(clip)\n",
    "\n",
    "    mel = whisper.log_mel_spectrogram(clip).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, probs = model.detect_language(mel)\n",
    "        enc      = model.encoder(mel.unsqueeze(0))\n",
    "\n",
    "    enc_seq = enc.squeeze(0).cpu().numpy()\n",
    "    emb     = enc_seq.mean(0)\n",
    "\n",
    "    s = probs[\"en\"] + probs.get(\"it\",0) + probs.get(\"es\",0)\n",
    "    probs3 = {\"en\": float(probs[\"en\"]/s), \"it\": float(probs.get(\"it\",0)/s), \"es\": float(probs.get(\"es\",0)/s)}\n",
    "\n",
    "    np.save(hid_path,  emb)\n",
    "    np.save(feats_path, enc_seq)\n",
    "    json.dump(probs3, open(probs_path, \"w\"))\n",
    "\n",
    "    rows.append([vid, wav, json.dumps([(start / SR, end / SR)]),\n",
    "                 probs_path, hid_path, feats_path, id2lang[int(lbl)]])\n",
    "\n",
    "pd.DataFrame(rows,\n",
    "    columns=[\"video_path\",\"audio_path\",\"segments\",\n",
    "             \"probs_path\",\"hid_path\",\"feats_path\",\"label\"]\n",
    ").to_csv(CSV_OUT, index=False)\n",
    "\n",
    "print(\"✅ Manifest scritto in\", CSV_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2191bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Whisper teacher per KD L2 multi-livello — preserva TUTTE le colonne (es. 'mouth_path')\n",
    "Aggiunge:\n",
    "- probs_path (JSON con p_en/it/es normalizzate)\n",
    "- hid_path (embedding medio finale)\n",
    "- feats_path (sequenza hidden finale T×D)\n",
    "- layer10_mean_path (media penultimo blocco)\n",
    "- layer11_mean_path (media finale encoder)\n",
    "\"\"\"\n",
    "\n",
    "import os, json\n",
    "from typing import Tuple, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import whisper\n",
    "\n",
    "# ===== Config =====\n",
    "MODEL       = \"small\"\n",
    "SR          = 16000\n",
    "CLIP_S      = 10\n",
    "\n",
    "CSV_IN      = \"BABELE/distillation_dataset.csv\"       # contiene mouth_path\n",
    "CSV_OUT     = None                               # None => sovrascrive CSV_IN; altrimenti scrive qui\n",
    "\n",
    "SAVE_MODE   = \"append\"                           # \"append\" | \"outdir\"\n",
    "OUT_DIR     = \"teacher_features\"\n",
    "\n",
    "AUDIO_COL   = \"audio_path\"\n",
    "MOUTH_COL   = \"mouth_path\"                       # non toccata\n",
    "LANG_SUBSET = [\"en\", \"it\", \"es\"]\n",
    "\n",
    "# ===== Utils =====\n",
    "def ensure_dir(path: str) -> None:\n",
    "    d = os.path.dirname(path)\n",
    "    if d and not os.path.exists(d):\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "\n",
    "def central_clip(audio: np.ndarray, sr: int, target_len_s: int) -> Tuple[np.ndarray, int, int]:\n",
    "    n_target = target_len_s * sr\n",
    "    mid = len(audio) // 2\n",
    "    start = max(mid - n_target // 2, 0)\n",
    "    end = min(start + n_target, len(audio))\n",
    "    return audio[start:end], start, end\n",
    "\n",
    "def detect_lang_and_encode(model, mel: torch.Tensor) -> Tuple[Dict[str, float], torch.Tensor]:\n",
    "    with torch.no_grad():\n",
    "        _, probs = model.detect_language(mel)\n",
    "        enc = model.encoder(mel.unsqueeze(0))  # [1,T',D]\n",
    "    return probs, enc\n",
    "\n",
    "# ===== Main =====\n",
    "def main():\n",
    "    df = pd.read_csv(CSV_IN)\n",
    "\n",
    "    # Verifica che mouth_path esista e venga mantenuta\n",
    "    if MOUTH_COL not in df.columns:\n",
    "        print(f\"Avviso: '{MOUTH_COL}' non è nel CSV. Procedo comunque, ma non posso 'preservarla'.\")\n",
    "    assert AUDIO_COL in df.columns, f\"Colonna '{AUDIO_COL}' assente.\"\n",
    "\n",
    "    model = whisper.load_model(MODEL)\n",
    "    device = model.device\n",
    "\n",
    "    # Hook penultimo blocco per L10\n",
    "    assert len(model.encoder.blocks) >= 2, \"Modello Whisper privo di sufficienti blocchi.\"\n",
    "    mid_cache = {}\n",
    "    def _mid_hook(m, i, o): mid_cache[\"x\"] = o.detach()\n",
    "    h_mid = model.encoder.blocks[-2].register_forward_hook(_mid_hook)\n",
    "\n",
    "    probs_paths, hid_paths, feats_paths, l10_paths, l11_paths = [], [], [], [], []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Teacher\"):\n",
    "        wav = str(row[AUDIO_COL])\n",
    "        p_probs = p_hid = p_feats = p_l10 = p_l11 = np.nan\n",
    "        try:\n",
    "            audio, sr = sf.read(wav)\n",
    "            if sr != SR: raise ValueError(f\"{wav}: SR {sr} != {SR}\")\n",
    "            if audio.ndim == 2: audio = audio.mean(axis=1)\n",
    "\n",
    "            clip, _, _ = central_clip(audio, sr, CLIP_S)\n",
    "            clip_t = torch.from_numpy(clip).float().to(device)\n",
    "            clip_t = whisper.pad_or_trim(clip_t)\n",
    "            mel = whisper.log_mel_spectrogram(clip_t).to(device)\n",
    "\n",
    "            mid_cache.clear()\n",
    "            probs_all, enc = detect_lang_and_encode(model, mel)\n",
    "            enc_seq = enc.squeeze(0).cpu().numpy()         # [T',D]\n",
    "            emb = enc_seq.mean(0)                          # [D]\n",
    "\n",
    "            if \"x\" not in mid_cache: raise RuntimeError(\"Hook non ha catturato L10.\")\n",
    "            l10_seq = mid_cache[\"x\"].squeeze(0).cpu().numpy()\n",
    "            l10 = l10_seq.mean(0)\n",
    "            l11 = emb\n",
    "\n",
    "            s = sum(float(probs_all.get(k, 0.0)) for k in LANG_SUBSET)\n",
    "            probs_sub = ({k: 1.0/len(LANG_SUBSET) for k in LANG_SUBSET} if s<=0.0\n",
    "                         else {k: float(probs_all.get(k, 0.0)/s) for k in LANG_SUBSET})\n",
    "\n",
    "            if SAVE_MODE == \"append\":\n",
    "                base = wav\n",
    "                p_probs = base + \".probs.json\"\n",
    "                p_hid   = base + \".hid.npy\"\n",
    "                p_feats = base + \".feat.npy\"\n",
    "                p_l10   = base + \".layer10_mean.npy\"\n",
    "                p_l11   = base + \".layer11_mean.npy\"\n",
    "            else:\n",
    "                base_id = os.path.splitext(os.path.basename(wav))[0]\n",
    "                p_probs = os.path.join(OUT_DIR, \"probs\", f\"{base_id}.json\")\n",
    "                p_hid   = os.path.join(OUT_DIR, \"hid\",   f\"{base_id}.npy\")\n",
    "                p_feats = os.path.join(OUT_DIR, \"feats\", f\"{base_id}.npy\")\n",
    "                p_l10   = os.path.join(OUT_DIR, \"L10\",   f\"{base_id}.npy\")\n",
    "                p_l11   = os.path.join(OUT_DIR, \"L11\",   f\"{base_id}.npy\")\n",
    "\n",
    "            for p in [p_probs, p_hid, p_feats, p_l10, p_l11]: ensure_dir(p)\n",
    "            with open(p_probs, \"w\") as f: json.dump(probs_sub, f)\n",
    "            np.save(p_hid,   emb.astype(\"float32\"))\n",
    "            np.save(p_feats, enc_seq.astype(\"float32\"))\n",
    "            np.save(p_l10,   l10.astype(\"float32\"))\n",
    "            np.save(p_l11,   l11.astype(\"float32\"))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        probs_paths.append(p_probs); hid_paths.append(p_hid)\n",
    "        feats_paths.append(p_feats); l10_paths.append(p_l10); l11_paths.append(p_l11)\n",
    "\n",
    "    h_mid.remove()\n",
    "\n",
    "    # Aggiunge le nuove colonne SENZA rimuovere le esistenti (mouth_path inclusa)\n",
    "    df[\"probs_path\"]        = probs_paths\n",
    "    df[\"hid_path\"]          = hid_paths\n",
    "    df[\"feats_path\"]        = feats_paths\n",
    "    df[\"layer10_mean_path\"] = l10_paths\n",
    "    df[\"layer11_mean_path\"] = l11_paths\n",
    "\n",
    "    out_csv = CSV_OUT or CSV_IN\n",
    "    os.makedirs(os.path.dirname(out_csv) or \".\", exist_ok=True)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "\n",
    "    # Check: la colonna mouth_path deve essere ancora presente\n",
    "    if MOUTH_COL in df.columns:\n",
    "        print(\"OK: 'mouth_path' è ancora presente ed è stata preservata.\")\n",
    "    else:\n",
    "        print(\"Nota: 'mouth_path' non era nel CSV di input.\")\n",
    "\n",
    "    cover = df[\"layer10_mean_path\"].notna() & df[\"layer11_mean_path\"].notna()\n",
    "    print(f\"✅ CSV scritto: {out_csv}\")\n",
    "    print(f\"   Coverage L10&L11: {cover.mean()*100:.1f}% su {len(df)} righe\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "caaaf0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifest aggiornato.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import os, cv2, json, numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "import face_alignment\n",
    "from face_alignment import FaceAlignment\n",
    "\n",
    "def mouth_roi(frame, landmarks, size=96, scale=1.4):\n",
    "    h_frame, w_frame = frame.shape[:2]\n",
    "    pts = landmarks[48:68]\n",
    "    cx, cy = pts.mean(axis=0)\n",
    "    w = max(np.ptp(pts[:,0]), np.ptp(pts[:,1])) * scale\n",
    "    x1 = max(0, int(cx - w/2)); y1 = max(0, int(cy - w/2))\n",
    "    x2 = min(w_frame, int(cx + w/2)); y2 = min(h_frame, int(cy + w/2))\n",
    "    if x2 <= x1 or y2 <= y1: return None\n",
    "    crop = frame[y1:y2, x1:x2]\n",
    "    if crop.size == 0: return None\n",
    "    return cv2.resize(crop, (size, size))\n",
    "\n",
    "# Inizializza\n",
    "fa      = FaceAlignment(face_alignment.LandmarksType.TWO_D, device=\"cpu\")\n",
    "distill = \"NEWEMODB/distillation_dataset_filtrato.csv\"\n",
    "out_dir = \"NEWEMODB/video_path\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "mani = pd.read_csv(distill, dtype={\"segments\": str})\n",
    "\n",
    "# 1) Pre-calcola il numero totale di frame da processare (sommando tutti i segmenti di tutti i video)\n",
    "def frames_in_video(video_path, segments, fps):\n",
    "    return sum(max(0, int((e - s) * fps)) for s, e in segments)\n",
    "\n",
    "total_frames_all = 0\n",
    "fps_cache = {}\n",
    "segments_cache = {}\n",
    "\n",
    "for _, row in mani.iterrows():\n",
    "    video_path = row[\"video_path\"]\n",
    "    segments = json.loads(row[\"segments\"])\n",
    "    segments_cache[video_path] = segments\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 25\n",
    "    cap.release()\n",
    "    fps_cache[video_path] = fps\n",
    "    total_frames_all += frames_in_video(video_path, segments, fps)\n",
    "\n",
    "mouth_paths = []\n",
    "pbar = tqdm(total=total_frames_all, desc=\"Elaborazione totale\", unit=\"frame\",\n",
    "            mininterval=0.3, miniters=10, leave=False, dynamic_ncols=True)\n",
    "\n",
    "for idx, row in mani.iterrows():\n",
    "    video_path = row[\"video_path\"]\n",
    "    outp = os.path.join(out_dir, os.path.basename(video_path) + \".npy\")\n",
    "\n",
    "    if os.path.exists(outp):\n",
    "        mouth_paths.append(outp)\n",
    "        # Avanza comunque la barra globale del numero di frame teorici di questo video\n",
    "        pbar.set_description(f\"Skip {os.path.basename(video_path)}\")\n",
    "        pbar.update(frames_in_video(video_path, segments_cache[video_path], fps_cache[video_path]))\n",
    "        continue\n",
    "\n",
    "    segments = segments_cache[video_path]\n",
    "    fps      = fps_cache[video_path]\n",
    "    frames   = []\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    pbar.set_description(f\"Video {idx+1}/{len(mani)}: {os.path.basename(video_path)}\")\n",
    "\n",
    "    for start_s, end_s in segments:\n",
    "        start_f = int(start_s * fps)\n",
    "        end_f   = int(end_s   * fps)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_f)\n",
    "\n",
    "        for _ in range(start_f, end_f):\n",
    "            ok, frame = cap.read()\n",
    "            if not ok:\n",
    "                # se fallisce la lettura, consideriamo il frame “consumato” per non bloccare la barra\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            lm = fa.get_landmarks(frame)\n",
    "            if lm and len(lm) > 0:\n",
    "                roi = mouth_roi(frame, lm[0])\n",
    "                if roi is not None:\n",
    "                    frames.append(roi)\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if frames:\n",
    "        arr = np.stack(frames).astype(\"uint8\")\n",
    "        np.save(outp, arr)\n",
    "        mouth_paths.append(outp)\n",
    "    else:\n",
    "        mouth_paths.append(\"\")\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Aggiorna manifest\n",
    "mani[\"mouth_path\"] = mouth_paths\n",
    "mani.to_csv(distill, index=False)\n",
    "print(\"Manifest aggiornato.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4be352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Video: 100%|██████████| 98/98 [1:16:21<00:00, 46.75s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Manifest aggiornato: VidTIMIT/distillation_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f967816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe totali CSV: 293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Teacher (full): 100%|██████████| 293/293 [04:40<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV scritto: NEWEMODB/distillation_dataset_filtrato_finale.csv\n",
      "   Coverage (tutte le nuove colonne non-NaN): 100.0% su 293 righe\n",
      "OK: 'mouth_path' è stato preservato.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Whisper teacher per KD L2 multi-livello — estrazione su TUTTO il dataset.\n",
    "- Preserva tutte le colonne esistenti (es. 'mouth_path', 'video_path', ecc.)\n",
    "- Aggiunge/aggiorna per ogni riga:\n",
    "  • probs_path (JSON con p_en/it/es normalizzate)\n",
    "  • hid_path (embedding medio finale)\n",
    "  • feats_path (sequenza hidden finale T×D)\n",
    "  • layer10_mean_path (media penultimo blocco encoder)\n",
    "  • layer11_mean_path (media finale encoder)\n",
    "- Risampla automaticamente a 16 kHz se l'audio non è a 16000 Hz\n",
    "- Nessun filtro: processa tutte le righe del CSV\n",
    "\"\"\"\n",
    "\n",
    "import os, json\n",
    "from typing import Tuple, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import whisper\n",
    "\n",
    "# ===== Config =====\n",
    "MODEL       = \"small\"\n",
    "TARGET_SR   = 16000         # Whisper vuole 16 kHz\n",
    "CLIP_S      = 10            # clip centrale (s)\n",
    "\n",
    "# CSV di input (contiene almeno 'audio_path' e, opzionale ma tipica, 'mouth_path')\n",
    "CSV_IN      = \"NEWEMODB/distillation_dataset_filtrato_finale.csv\"\n",
    "\n",
    "# None => sovrascrive l'input; altrimenti scrive su un nuovo file\n",
    "CSV_OUT     = None\n",
    "\n",
    "# Dove salvare i file .npy/.json delle feature\n",
    "SAVE_MODE   = \"append\"      # \"append\" | \"outdir\"\n",
    "OUT_DIR     = \"teacher_features\"\n",
    "\n",
    "AUDIO_COL   = \"audio_path\"\n",
    "MOUTH_COL   = \"mouth_path\"  # preservata se presente\n",
    "LANG_SUBSET = [\"en\", \"it\", \"es\"]\n",
    "\n",
    "# Se True, salta la riga solo se TUTTI i file di output esistono già\n",
    "SKIP_IF_ALL_EXIST = False   # per estrarre tutto da zero, lascia False\n",
    "\n",
    "# ===== Utils =====\n",
    "def ensure_dir(path: str) -> None:\n",
    "    d = os.path.dirname(path)\n",
    "    if d and not os.path.exists(d):\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "\n",
    "def central_clip(audio: np.ndarray, sr: int, target_len_s: int) -> Tuple[np.ndarray, int, int]:\n",
    "    n_target = target_len_s * sr\n",
    "    mid = len(audio) // 2\n",
    "    start = max(mid - n_target // 2, 0)\n",
    "    end = min(start + n_target, len(audio))\n",
    "    return audio[start:end], start, end\n",
    "\n",
    "def resample_to(audio: np.ndarray, sr_in: int, sr_out: int) -> np.ndarray:\n",
    "    \"\"\"Risampling 1D semplice via interpolazione (senza dipendenze extra).\"\"\"\n",
    "    audio = np.asarray(audio, dtype=np.float32)\n",
    "    if sr_in == sr_out:\n",
    "        return audio\n",
    "    n_out = int(round(len(audio) * sr_out / sr_in))\n",
    "    if n_out <= 1:\n",
    "        return np.zeros((sr_out,), dtype=np.float32)  # fallback\n",
    "    x_old = np.linspace(0.0, 1.0, num=len(audio), endpoint=False)\n",
    "    x_new = np.linspace(0.0, 1.0, num=n_out,      endpoint=False)\n",
    "    return np.interp(x_new, x_old, audio).astype(np.float32)\n",
    "\n",
    "def detect_lang_and_encode(model, mel: torch.Tensor) -> Tuple[Dict[str, float], torch.Tensor]:\n",
    "    with torch.no_grad():\n",
    "        _, probs = model.detect_language(mel)\n",
    "        enc = model.encoder(mel.unsqueeze(0))  # [1,T',D]\n",
    "    return probs, enc\n",
    "\n",
    "# ===== Main =====\n",
    "def main():\n",
    "    df = pd.read_csv(CSV_IN)\n",
    "\n",
    "    if AUDIO_COL not in df.columns:\n",
    "        raise ValueError(f\"Colonna '{AUDIO_COL}' assente in {CSV_IN}\")\n",
    "\n",
    "    print(f\"Righe totali CSV: {len(df)}\")\n",
    "\n",
    "    # Carica Whisper + hook penultimo blocco\n",
    "    model = whisper.load_model(MODEL)\n",
    "    device = model.device\n",
    "    assert len(model.encoder.blocks) >= 2, \"Modello Whisper privo di sufficienti blocchi.\"\n",
    "    mid_cache = {}\n",
    "    def _mid_hook(m, i, o): mid_cache[\"x\"] = o.detach()\n",
    "    h_mid = model.encoder.blocks[-2].register_forward_hook(_mid_hook)\n",
    "\n",
    "    # Prepara i vettori di output (parto da quelli già presenti, se esistono)\n",
    "    probs_paths = df.get(\"probs_path\",        pd.Series([np.nan]*len(df))).tolist()\n",
    "    hid_paths   = df.get(\"hid_path\",          pd.Series([np.nan]*len(df))).tolist()\n",
    "    feats_paths = df.get(\"feats_path\",        pd.Series([np.nan]*len(df))).tolist()\n",
    "    l10_paths   = df.get(\"layer10_mean_path\", pd.Series([np.nan]*len(df))).tolist()\n",
    "    l11_paths   = df.get(\"layer11_mean_path\", pd.Series([np.nan]*len(df))).tolist()\n",
    "\n",
    "    # Loop su TUTTE le righe\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Teacher (full)\"):\n",
    "        wav = str(row[AUDIO_COL])\n",
    "\n",
    "        # Percorsi di salvataggio\n",
    "        if SAVE_MODE == \"append\":\n",
    "            base = wav\n",
    "            p_probs = base + \".probs.json\"\n",
    "            p_hid   = base + \".hid.npy\"\n",
    "            p_feats = base + \".feat.npy\"\n",
    "            p_l10   = base + \".layer10_mean.npy\"\n",
    "            p_l11   = base + \".layer11_mean.npy\"\n",
    "        else:  # outdir\n",
    "            base_id = os.path.splitext(os.path.basename(wav))[0]\n",
    "            p_probs = os.path.join(OUT_DIR, \"probs\", f\"{base_id}.json\")\n",
    "            p_hid   = os.path.join(OUT_DIR, \"hid\",   f\"{base_id}.npy\")\n",
    "            p_feats = os.path.join(OUT_DIR, \"feats\", f\"{base_id}.npy\")\n",
    "            p_l10   = os.path.join(OUT_DIR, \"L10\",   f\"{base_id}.npy\")\n",
    "            p_l11   = os.path.join(OUT_DIR, \"L11\",   f\"{base_id}.npy\")\n",
    "\n",
    "        # Skip opzionale se TUTTI i file già esistono\n",
    "        if SKIP_IF_ALL_EXIST and all(os.path.exists(p) for p in [p_probs, p_hid, p_feats, p_l10, p_l11]):\n",
    "            probs_paths[idx] = p_probs; hid_paths[idx] = p_hid\n",
    "            feats_paths[idx] = p_feats; l10_paths[idx] = p_l10; l11_paths[idx] = p_l11\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Leggi audio\n",
    "            audio, sr = sf.read(wav)\n",
    "            if audio.ndim == 2:\n",
    "                audio = audio.mean(axis=1)\n",
    "            # Risampling a 16 kHz se necessario\n",
    "            audio = resample_to(audio, sr, TARGET_SR)\n",
    "\n",
    "            # Clip centrale + pad/trim a durata fissa (Whisper usa pad_or_trim a 30s, va bene anche clip 10s)\n",
    "            clip, _, _ = central_clip(audio, TARGET_SR, CLIP_S)\n",
    "            clip_t = torch.from_numpy(clip).float().to(device)\n",
    "            clip_t = whisper.pad_or_trim(clip_t)\n",
    "            mel = whisper.log_mel_spectrogram(clip_t).to(device)\n",
    "\n",
    "            # Forward Whisper\n",
    "            mid_cache.clear()\n",
    "            probs_all, enc = detect_lang_and_encode(model, mel)\n",
    "            enc_seq = enc.squeeze(0).cpu().numpy()         # [T',D]\n",
    "            emb = enc_seq.mean(0)                          # [D]\n",
    "\n",
    "            if \"x\" not in mid_cache:\n",
    "                raise RuntimeError(\"Hook non ha catturato il penultimo blocco (L10).\")\n",
    "            l10_seq = mid_cache[\"x\"].squeeze(0).cpu().numpy()\n",
    "            l10 = l10_seq.mean(0)\n",
    "            l11 = emb\n",
    "\n",
    "            # Normalizza probabilità su sottoinsieme lingue\n",
    "            s = sum(float(probs_all.get(k, 0.0)) for k in LANG_SUBSET)\n",
    "            probs_sub = ({k: 1.0/len(LANG_SUBSET) for k in LANG_SUBSET} if s<=0.0\n",
    "                         else {k: float(probs_all.get(k, 0.0)/s) for k in LANG_SUBSET})\n",
    "\n",
    "            # Crea dir e salva\n",
    "            for p in [p_probs, p_hid, p_feats, p_l10, p_l11]:\n",
    "                ensure_dir(p)\n",
    "\n",
    "            with open(p_probs, \"w\") as f:\n",
    "                json.dump(probs_sub, f)\n",
    "            np.save(p_hid,   emb.astype(\"float32\"))\n",
    "            np.save(p_feats, enc_seq.astype(\"float32\"))\n",
    "            np.save(p_l10,   l10.astype(\"float32\"))\n",
    "            np.save(p_l11,   l11.astype(\"float32\"))\n",
    "\n",
    "            # Aggiorna i path nel buffer\n",
    "            probs_paths[idx] = p_probs\n",
    "            hid_paths[idx]   = p_hid\n",
    "            feats_paths[idx] = p_feats\n",
    "            l10_paths[idx]   = p_l10\n",
    "            l11_paths[idx]   = p_l11\n",
    "\n",
    "        except Exception as e:\n",
    "            # Se qualcosa va storto, lascio NaN e loggo\n",
    "            print(f\"[ERRORE] {wav}: {e}\")\n",
    "            probs_paths[idx] = np.nan\n",
    "            hid_paths[idx]   = np.nan\n",
    "            feats_paths[idx] = np.nan\n",
    "            l10_paths[idx]   = np.nan\n",
    "            l11_paths[idx]   = np.nan\n",
    "\n",
    "    # Rimuovi hook\n",
    "    h_mid.remove()\n",
    "\n",
    "    # Scrivi colonne senza toccare le altre\n",
    "    df[\"probs_path\"]        = probs_paths\n",
    "    df[\"hid_path\"]          = hid_paths\n",
    "    df[\"feats_path\"]        = feats_paths\n",
    "    df[\"layer10_mean_path\"] = l10_paths\n",
    "    df[\"layer11_mean_path\"] = l11_paths\n",
    "\n",
    "    out_csv = CSV_OUT or CSV_IN\n",
    "    os.makedirs(os.path.dirname(out_csv) or \".\", exist_ok=True)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "\n",
    "    # Report finale\n",
    "    have_all = df[[\"probs_path\",\"hid_path\",\"feats_path\",\"layer10_mean_path\",\"layer11_mean_path\"]].notna().all(axis=1)\n",
    "    print(f\"✅ CSV scritto: {out_csv}\")\n",
    "    print(f\"   Coverage (tutte le nuove colonne non-NaN): {have_all.mean()*100:.1f}% su {len(df)} righe\")\n",
    "\n",
    "    if MOUTH_COL in df.columns:\n",
    "        print(\"OK: 'mouth_path' è stato preservato.\")\n",
    "    else:\n",
    "        print(\"Nota: 'mouth_path' non era nel CSV di input.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "650490f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train salvato in NEWEMODB/manifest_train.csv, 209 righe\n",
      "Test salvato in NEWEMODB/manifets_test.csv, 84 righe\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# ── Config ─────────────────────────────────────────────\n",
    "CSV_IN = \"NEWEMODB/distillation_dataset_filtrato_finale.csv\"\n",
    "TRAIN_OUT = \"NEWEMODB/manifest_train.csv\"\n",
    "TEST_OUT  = \"NEWEMODB/manifets_test.csv\"\n",
    "SEED = 42\n",
    "\n",
    "# ── Funzione per estrarre subject_id ───────────────────\n",
    "def extract_subject_id(path_str: str) -> str:\n",
    "    p = str(path_str).replace(\"\\\\\", \"/\")\n",
    "\n",
    "    # Caso 1: EMODB → tre cifre dopo audio_wav/\n",
    "    m = re.search(r\"audio_wav/(\\d{3})\", p, re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "\n",
    "    # Caso 2: VidTIMIT → cartella dopo VidTimit/\n",
    "    m = re.search(r\"VidTimit/([^/]+)\", p, re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "\n",
    "    # Fallback: nome file senza estensione\n",
    "    return Path(p).stem\n",
    "\n",
    "# ── Caricamento dataset ────────────────────────────────\n",
    "df = pd.read_csv(CSV_IN)\n",
    "\n",
    "# Identifica colonna audio\n",
    "audio_col_candidates = [c for c in df.columns if (\"audio\" in c.lower()) or (\"wav\" in c.lower())]\n",
    "audio_col = audio_col_candidates[0]\n",
    "\n",
    "# Identifica colonna lingua\n",
    "lang_col_candidates = [c for c in df.columns if any(k in c.lower() for k in [\"lang\",\"label\",\"language\"])]\n",
    "lang_col = lang_col_candidates[0]\n",
    "\n",
    "# Estrazione subject_id\n",
    "df[\"subject_id\"] = df[audio_col].astype(str).map(extract_subject_id)\n",
    "\n",
    "# ── Split per lingua ───────────────────────────────────\n",
    "rng = np.random.default_rng(SEED)\n",
    "train_subjects_by_lang = {}\n",
    "test_subjects_by_lang = {}\n",
    "\n",
    "for lang, subdf in df.groupby(lang_col):\n",
    "    unique_subjects = sorted(subdf[\"subject_id\"].unique().tolist())\n",
    "    if len(unique_subjects) < 14:\n",
    "        n_train = max(1, round(0.7 * len(unique_subjects)))\n",
    "    else:\n",
    "        n_train = 10\n",
    "    n_test = len(unique_subjects) - n_train\n",
    "\n",
    "    shuffled = unique_subjects.copy()\n",
    "    rng.shuffle(shuffled)\n",
    "\n",
    "    train_subjects_by_lang[lang] = set(shuffled[:n_train])\n",
    "    test_subjects_by_lang[lang]  = set(shuffled[n_train:])\n",
    "\n",
    "# ── Costruzione split finale ───────────────────────────\n",
    "mask_train = df.apply(lambda r: r[\"subject_id\"] in train_subjects_by_lang[str(r[lang_col])], axis=1)\n",
    "mask_test  = df.apply(lambda r: r[\"subject_id\"] in test_subjects_by_lang[str(r[lang_col])], axis=1)\n",
    "\n",
    "train_df = df[mask_train].reset_index(drop=True)\n",
    "test_df  = df[mask_test].reset_index(drop=True)\n",
    "\n",
    "# ── Salvataggio ────────────────────────────────────────\n",
    "train_df.to_csv(TRAIN_OUT, index=False)\n",
    "test_df.to_csv(TEST_OUT, index=False)\n",
    "\n",
    "print(f\"Train salvato in {TRAIN_OUT}, {len(train_df)} righe\")\n",
    "print(f\"Test salvato in {TEST_OUT}, {len(test_df)} righe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa9b2742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/var/folders/jx/nf2g6k1s1550mrw1rrvdw69h0000gn/T/ipykernel_1086/1562018671.py:222: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=(DEVICE.type=='cuda'))\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/jx/nf2g6k1s1550mrw1rrvdw69h0000gn/T/ipykernel_1086/1562018671.py:245: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01  Val-F1=0.532\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it  17  11   0\n",
      "es  18   2   8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/jx/nf2g6k1s1550mrw1rrvdw69h0000gn/T/ipykernel_1086/1562018671.py:245: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02  Val-F1=0.856\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   1   4  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/jx/nf2g6k1s1550mrw1rrvdw69h0000gn/T/ipykernel_1086/1562018671.py:245: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03  Val-F1=0.768\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   0  12  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/jx/nf2g6k1s1550mrw1rrvdw69h0000gn/T/ipykernel_1086/1562018671.py:245: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04  Val-F1=0.478\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   6  22   0\n",
      "es   6  22   0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/jx/nf2g6k1s1550mrw1rrvdw69h0000gn/T/ipykernel_1086/1562018671.py:245: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05  Val-F1=0.681\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   4   6  18\n",
      "es   0   0  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/jx/nf2g6k1s1550mrw1rrvdw69h0000gn/T/ipykernel_1086/1562018671.py:245: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06  Val-F1=0.552\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es  27   1   0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/jx/nf2g6k1s1550mrw1rrvdw69h0000gn/T/ipykernel_1086/1562018671.py:245: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07  Val-F1=0.752\n",
      "    en  it  es\n",
      "en  27   1   0\n",
      "it   0  28   0\n",
      "es   0  18  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/jx/nf2g6k1s1550mrw1rrvdw69h0000gn/T/ipykernel_1086/1562018671.py:245: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08  Val-F1=0.638\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   6  22   0\n",
      "es  15   6   7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/jx/nf2g6k1s1550mrw1rrvdw69h0000gn/T/ipykernel_1086/1562018671.py:245: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09  Val-F1=0.606\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  27   1\n",
      "es  19   6   3\n",
      "Early stopping\n",
      "\n",
      "Best Val-F1 = 0.856\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Video-only LID Student — KD-lite (tardiva, pesata, con agreement)\n",
    "# Train/Val: BABELE (video-only); Test: EMODB (video-only)\n",
    "\n",
    "import os, json, random, copy\n",
    "import numpy as np, pandas as pd\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.video import r3d_18\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "# ───────── Config ────────────────────────────────────────────────────────────\n",
    "SEED, EPOCHS       = 42, 20\n",
    "BATCH_SIZE         = 8\n",
    "LR, WD             = 3e-4, 1e-3\n",
    "NUM_WORKERS        = 0\n",
    "LANGS              = ['en','it','es']\n",
    "DEVICE             = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "OUT_H, OUT_W, L    = 64, 64, 32\n",
    "MIXUP_ALPHA        = 0.3\n",
    "PATIENCE           = 7\n",
    "MAX_LR             = 3e-4\n",
    "DIV_FACTOR         = 10\n",
    "FINAL_DIV          = 100\n",
    "\n",
    "\n",
    "T_KD          = 6.0     # temperatura alta (soft)\n",
    "LAMBDA_KD     = 0.05    # peso piccolissimo\n",
    "WARMUP_EPOCHS = 0  # KD parte tardi\n",
    "CONF_TH       = 0.90    # usa KD solo se teacher è molto sicuro\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def macro_f1(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true, y_pred,\n",
    "                                           average='macro', zero_division=0)[2]\n",
    "\n",
    "# ───────── Augmentazioni ─────────────────────────────────────────────────────\n",
    "class SpecAug3D:\n",
    "    def __init__(self, H, W, T_mask=4, S_mask=4):\n",
    "        self.tf = T.Compose([\n",
    "            T.ToPILImage(),\n",
    "            T.RandomResizedCrop((H,W), scale=(0.95,1.0), ratio=(1.0,1.0)),\n",
    "            T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),\n",
    "            T.RandomHorizontalFlip(0.5),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "        self.T_mask, self.S_mask = T_mask, S_mask\n",
    "\n",
    "    def __call__(self, vid):\n",
    "        frames = []\n",
    "        for f in vid:\n",
    "            img = (f*255).byte()\n",
    "            t   = self.tf(img).squeeze(0)\n",
    "            frames.append(t)\n",
    "        vid = torch.stack(frames)\n",
    "        L_,H,W = vid.shape\n",
    "        if L_ > self.T_mask:\n",
    "            t0 = random.randrange(0, L_-self.T_mask+1)\n",
    "            vid[t0:t0+self.T_mask] = 0\n",
    "        if H>self.S_mask and W>self.S_mask:\n",
    "            fi = random.randrange(0, L_)\n",
    "            h0 = random.randrange(0, H-self.S_mask+1)\n",
    "            w0 = random.randrange(0, W-self.S_mask+1)\n",
    "            vid[fi,h0:h0+self.S_mask,w0:w0+self.S_mask] = 0\n",
    "        return vid\n",
    "\n",
    "class RandomErasing3D:\n",
    "    def __init__(self, p=0.3, size=(8,8,8)):\n",
    "        self.p = p\n",
    "        self.d, self.h, self.w = size\n",
    "    def __call__(self, vid):\n",
    "        if random.random()>self.p: return vid\n",
    "        L_,H,W = vid.shape\n",
    "        sd = random.randint(0, L_-self.d)\n",
    "        sh = random.randint(0, H-self.h)\n",
    "        sw = random.randint(0, W-self.w)\n",
    "        vid[sd:sd+self.d, sh:sh+self.h, sw:sw+self.w] = 0\n",
    "        return vid\n",
    "\n",
    "def mixup(x, y, alpha=MIXUP_ALPHA):\n",
    "    lam = np.random.beta(alpha,alpha)\n",
    "    idx = torch.randperm(x.size(0),device=x.device)\n",
    "    return lam*x + (1-lam)*x[idx], lam*y + (1-lam)*y[idx]\n",
    "\n",
    "# ───────── Loss: soft-label FocalLoss ─────────────────────────────────────────\n",
    "class SoftFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__(); self.alpha, self.gamma = alpha, gamma\n",
    "    def forward(self, logits, y_soft):\n",
    "        logp = F.log_softmax(logits,1)\n",
    "        p    = logp.exp()\n",
    "        ce   = -(y_soft * logp).sum(1)\n",
    "        pt   = (y_soft * p).sum(1)\n",
    "        return ( self.alpha * (1-pt)**self.gamma * ce ).mean()\n",
    "\n",
    "# ───────── MixStyle ───────────────────────────────────────────────────────────\n",
    "class MixStyle(nn.Module):\n",
    "    def __init__(self, p=0.3, α=0.1):\n",
    "        super().__init__(); self.p, self.α = p, α\n",
    "    def forward(self, x):\n",
    "        if not self.training or random.random()>self.p:\n",
    "            return x\n",
    "        B,C    = x.shape\n",
    "        mu     = x.mean(1,keepdim=True)\n",
    "        sig    = (x.var(1,keepdim=True)+1e-6).sqrt()\n",
    "        lm     = np.random.beta(self.α, self.α)\n",
    "        perm   = torch.randperm(B,device=x.device)\n",
    "        mu2    = mu[perm]; sig2 = sig[perm]\n",
    "        mu_mix = lm*mu + (1-lm)*mu2\n",
    "        sig_mix= lm*sig+ (1-lm)*sig2\n",
    "        x_norm = (x-mu)/sig\n",
    "        return x_norm*sig_mix + mu_mix\n",
    "\n",
    "# ───────── Dataset ────────────────────────────────────────────────────────────\n",
    "class MouthDS(Dataset):\n",
    "    \"\"\"\n",
    "    TRAIN (use_teacher=True): (x, y, t_soft)\n",
    "    VAL/TEST (use_teacher=False): (x, y)\n",
    "    \"\"\"\n",
    "    def __init__(self,csv,L=32,augment=False,use_teacher=False):\n",
    "        df = pd.read_csv(csv).query('mouth_path.notna()').reset_index(drop=True)\n",
    "        self.df, self.L = df, L\n",
    "        self.l2i         = {l:i for i,l in enumerate(LANGS)}\n",
    "        self.spec        = SpecAug3D(OUT_H,OUT_W) if augment else None\n",
    "        self.randomerase = RandomErasing3D()      if augment else None\n",
    "        self.use_teacher = use_teacher\n",
    "\n",
    "    def _align(self,a):\n",
    "        T0 = a.shape[0]\n",
    "        if T0>=self.L:\n",
    "            idx = np.linspace(0,T0-1,self.L).astype(int)\n",
    "        else:\n",
    "            idx = np.concatenate([np.arange(T0),\n",
    "                                  np.full(self.L-T0, T0-1)])\n",
    "        return a[idx]\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        r = self.df.iloc[i]\n",
    "        a = np.load(r.mouth_path,allow_pickle=True).astype('float32')/255.\n",
    "        a = a.mean(-1); a = self._align(a)\n",
    "        v = torch.from_numpy(a)\n",
    "        if self.spec:        v = self.spec(v)\n",
    "        if self.randomerase: v = self.randomerase(v)\n",
    "        v3 = v.unsqueeze(0).unsqueeze(0)\n",
    "        v3 = F.interpolate(v3, size=(L,OUT_H,OUT_W),\n",
    "                           mode='trilinear', align_corners=False).squeeze(0)\n",
    "        x  = (v3 - 0.5)/0.5\n",
    "        y  = torch.tensor(self.l2i[r.label],dtype=torch.long)\n",
    "\n",
    "        if not self.use_teacher:\n",
    "            return x, y\n",
    "\n",
    "        # soft-target del Teacher (se presenti nel CSV come probs_path)\n",
    "        t_soft = torch.zeros(len(LANGS), dtype=torch.float32)\n",
    "        if 'probs_path' in self.df.columns and pd.notna(r['probs_path']) and os.path.exists(str(r['probs_path'])):\n",
    "            with open(str(r['probs_path']), 'r') as f:\n",
    "                p = json.load(f)  # {\"en\":..,\"it\":..,\"es\":..}\n",
    "            t_soft = torch.tensor([float(p.get(lang,0.0)) for lang in LANGS], dtype=torch.float32)\n",
    "            s = t_soft.sum().item()\n",
    "            if s>0: t_soft = t_soft / s\n",
    "        else:\n",
    "            t_soft[y] = 1.0  # fallback one-hot\n",
    "\n",
    "        return x, y, t_soft\n",
    "\n",
    "# ───────── Model ──────────────────────────────────────────────────────────────\n",
    "class Student(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = r3d_18(pretrained=True)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.mixstyle   = MixStyle(p=0.3, α=0.1)\n",
    "        self.head       = nn.Sequential(\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Linear(512,256), nn.GELU(), nn.Dropout(0.1),\n",
    "            nn.Linear(256,len(LANGS))\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.repeat(1,3,1,1,1)\n",
    "        f = self.backbone(x)      # [B,512]\n",
    "        f = self.mixstyle(f)\n",
    "        return self.head(f), f\n",
    "\n",
    "# ───────── Training Loop ────────────────────────────────────────────────────\n",
    "def main():\n",
    "    df_tr = pd.read_csv('NEWEMODB/manifest_train.csv')\n",
    "    dl_tr = DataLoader(\n",
    "        MouthDS('NEWEMODB/manifest_train.csv', L, augment=True,  use_teacher=True),\n",
    "        batch_size=BATCH_SIZE, sampler=make_sampler(df_tr),\n",
    "        num_workers=NUM_WORKERS, pin_memory=True\n",
    "    )\n",
    "    dl_ts = DataLoader(\n",
    "        MouthDS('NEWEMODB/manifest_test.csv',   L, augment=False, use_teacher=False),\n",
    "        batch_size=BATCH_SIZE, shuffle=False,\n",
    "        num_workers=NUM_WORKERS, pin_memory=True\n",
    "    )\n",
    "\n",
    "    model = Student().to(DEVICE)\n",
    "    # Freeze BatchNorm3d\n",
    "    for m in model.backbone.modules():\n",
    "        if isinstance(m, nn.BatchNorm3d):\n",
    "            m.eval(); m.weight.requires_grad_(False); m.bias.requires_grad_(False)\n",
    "\n",
    "    ema    = copy.deepcopy(model)\n",
    "    for p in ema.parameters(): p.requires_grad_(False)\n",
    "\n",
    "    opt    = AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "    total  = EPOCHS * len(dl_tr)\n",
    "    sched  = OneCycleLR(opt, max_lr=MAX_LR, total_steps=total,\n",
    "                        pct_start=0.3, div_factor=DIV_FACTOR,\n",
    "                        final_div_factor=FINAL_DIV, anneal_strategy='cos')\n",
    "    scaler = GradScaler(enabled=(DEVICE.type=='cuda'))\n",
    "    crit   = SoftFocalLoss()\n",
    "\n",
    "    best_f1, patience = 0.0, 0\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        use_kd = (ep > WARMUP_EPOCHS)\n",
    "\n",
    "        for batch in dl_tr:\n",
    "            # --- unpack robusto: train -> 3, val/test -> 2 ---\n",
    "            if isinstance(batch, (list, tuple)) and len(batch) == 3:\n",
    "                x, y, t_soft = batch\n",
    "            else:\n",
    "                x, y = batch\n",
    "                t_soft = None\n",
    "\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "            # MixUp su hard labels\n",
    "            y_onehot = F.one_hot(y, len(LANGS)).float()\n",
    "            x_m, y_m = mixup(x, y_onehot)\n",
    "\n",
    "            with autocast():\n",
    "                logits,_ = model(x_m)\n",
    "                loss_sup = crit(logits, y_m)\n",
    "\n",
    "                # --- KD-lite solo quando attiva e disponibile ---\n",
    "                if use_kd and t_soft is not None:\n",
    "                    t_soft = t_soft.to(DEVICE)\n",
    "                    # normalizza + clamp\n",
    "                    t_soft = t_soft / (t_soft.sum(dim=1, keepdim=True) + 1e-8)\n",
    "                    t_soft = torch.clamp(t_soft, 1e-4, 1.0)\n",
    "                    t_soft = t_soft / (t_soft.sum(dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "                    conf   = t_soft.max(dim=1).values\n",
    "                    agree  = (t_soft.argmax(1) == y).float()\n",
    "                    gate   = (conf >= CONF_TH).float() * agree\n",
    "\n",
    "                    logp_T = F.log_softmax(logits / T_KD, dim=1)\n",
    "                    kd_per = (T_KD**2) * F.kl_div(logp_T, t_soft, reduction='none').sum(dim=1)\n",
    "                    loss_kd = (kd_per * gate).sum() / (gate.sum() + 1e-8)\n",
    "\n",
    "                    loss = (1.0 - LAMBDA_KD) * loss_sup + LAMBDA_KD * loss_kd\n",
    "                else:\n",
    "                    loss = loss_sup\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt); scaler.update(); opt.zero_grad()\n",
    "            sched.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for m,e in zip(model.parameters(), ema.parameters()):\n",
    "                    e.mul_(0.999).add_(m, alpha=0.001)\n",
    "\n",
    "            \n",
    "\n",
    "        # ── Validation on Babele ───────────────────────────\n",
    "        model.eval()\n",
    "        preds, gts = [], []\n",
    "        for x,y in dl_ts:\n",
    "            x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                logits,_ = model(x)\n",
    "            preds += logits.argmax(1).cpu().tolist()\n",
    "            gts   += y.cpu().tolist()\n",
    "        f1 = macro_f1(gts, preds)\n",
    "        cm = confusion_matrix(gts, preds, labels=list(range(len(LANGS))))\n",
    "        print(f\"Epoch {ep:02d}  Val-F1={f1:.3f}\")\n",
    "        print(pd.DataFrame(cm, index=LANGS, columns=LANGS))\n",
    "\n",
    "        if f1>best_f1:\n",
    "            best_f1, patience = f1, 0\n",
    "            torch.save(model.state_dict(), 'best_student.pt')\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience>=PATIENCE:\n",
    "                print(\"Early stopping\"); break\n",
    "\n",
    "    print(f\"\\nBest Val-F1 = {best_f1:.3f}\")\n",
    "# ───────── Sampler ───────────────────────────────────────────────────────────\n",
    "def make_sampler(df):\n",
    "    cnt = df['label'].value_counts().reindex(LANGS,fill_value=0).to_dict()\n",
    "    w   = df['label'].map(lambda l:1.0/(cnt[l]+1e-6)).tolist()\n",
    "    return WeightedRandomSampler(w, num_samples=len(w), replacement=True)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c8798f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1-macro: 0.301\n",
      "\n",
      "Confusion Matrix (righe=GT, colonne=Pred):\n",
      "    en  it  es\n",
      "en   5   1   3\n",
      "it   3   4   3\n",
      "es  10   0   0\n",
      "\n",
      "Report per classe:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          en       0.28      0.56      0.37         9\n",
      "          it       0.80      0.40      0.53        10\n",
      "          es       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.31        29\n",
      "   macro avg       0.36      0.32      0.30        29\n",
      "weighted avg       0.36      0.31      0.30        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np, pandas as pd\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.video import r3d_18\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "\n",
    "# ───── Config ─────\n",
    "LANGS   = ['en','it','es']\n",
    "OUT_H, OUT_W, L = 64, 64, 32\n",
    "DEVICE  = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "TEST_CSV   = \"BABELE/manifest_test.csv\"   # <--- path al CSV di test\n",
    "WEIGHTS    = \"best_student.pt\"                   # <--- path ai pesi salvati\n",
    "\n",
    "# ───── Utils ─────\n",
    "def macro_f1(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)[2]\n",
    "\n",
    "# ───── Dataset ─────\n",
    "class MouthDS(Dataset):\n",
    "    def __init__(self, csv_path, L=32):\n",
    "        df = pd.read_csv(csv_path).query('mouth_path.notna() and label.notna()').reset_index(drop=True)\n",
    "        df = df[df['label'].isin(LANGS)].reset_index(drop=True)\n",
    "        self.df, self.L = df, L\n",
    "        self.l2i = {l:i for i,l in enumerate(LANGS)}\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def _align(self, a):\n",
    "        T0 = a.shape[0]\n",
    "        if T0 >= self.L:\n",
    "            idx = np.linspace(0, T0-1, self.L).astype(int)\n",
    "        else:\n",
    "            idx = np.concatenate([np.arange(T0), np.full(self.L - T0, T0-1)])\n",
    "        return a[idx]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        r = self.df.iloc[i]\n",
    "        a = np.load(r.mouth_path, allow_pickle=True).astype('float32')\n",
    "        if a.max() > 1.5: a = a / 255.0\n",
    "        if a.ndim == 4: a = a.mean(-1)   # [T,H,W,C] → grayscale\n",
    "        a = self._align(a)\n",
    "        v = torch.from_numpy(a)\n",
    "        v3 = v.unsqueeze(0).unsqueeze(0)  # [1,1,L,H,W]\n",
    "        v3 = F.interpolate(v3, size=(L, OUT_H, OUT_W), mode='trilinear', align_corners=False).squeeze(0)\n",
    "        x  = (v3 - 0.5) / 0.5\n",
    "        y  = torch.tensor(self.l2i[r.label], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "# ───── Model ─────\n",
    "class Student(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = r3d_18(pretrained=True)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Linear(512,256), nn.GELU(), nn.Dropout(0.1),\n",
    "            nn.Linear(256,len(LANGS))\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.repeat(1,3,1,1,1)\n",
    "        f = self.backbone(x)\n",
    "        return self.head(f)\n",
    "\n",
    "# ───── Carica dati e modello ─────\n",
    "ds = MouthDS(TEST_CSV, L=L)\n",
    "dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = Student().to(DEVICE)\n",
    "state = torch.load(WEIGHTS, map_location=DEVICE)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "# ───── Valutazione ─────\n",
    "all_preds, all_gts = [], []\n",
    "with torch.no_grad():\n",
    "    for x,y in dl:\n",
    "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "        logits = model(x)\n",
    "        preds = logits.argmax(1).cpu().tolist()\n",
    "        all_preds.extend(preds)\n",
    "        all_gts.extend(y.cpu().tolist())\n",
    "\n",
    "f1 = macro_f1(all_gts, all_preds)\n",
    "cm = confusion_matrix(all_gts, all_preds, labels=list(range(len(LANGS))))\n",
    "report = classification_report(all_gts, all_preds, target_names=LANGS, zero_division=0)\n",
    "\n",
    "print(f\"\\nF1-macro: {f1:.3f}\")\n",
    "print(\"\\nConfusion Matrix (righe=GT, colonne=Pred):\")\n",
    "print(pd.DataFrame(cm, index=LANGS, columns=LANGS))\n",
    "print(\"\\nReport per classe:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4b06c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1-macro: 0.461\n",
      "\n",
      "Confusion Matrix (righe=GT, colonne=Pred):\n",
      "    en  it  es\n",
      "en   5   1   1\n",
      "it   3   2   2\n",
      "es   2   2   3\n",
      "\n",
      "Report per classe:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          en       0.50      0.71      0.59         7\n",
      "          it       0.40      0.29      0.33         7\n",
      "          es       0.50      0.43      0.46         7\n",
      "\n",
      "    accuracy                           0.48        21\n",
      "   macro avg       0.47      0.48      0.46        21\n",
      "weighted avg       0.47      0.48      0.46        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np, pandas as pd\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.video import r3d_18\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "\n",
    "# ───── Config ─────\n",
    "LANGS   = ['en','it','es']\n",
    "OUT_H, OUT_W, L = 64, 64, 32\n",
    "DEVICE  = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "TEST_CSV   = \"EMODB/manifest_test.csv\"   # <--- path al CSV di test\n",
    "WEIGHTS    = \"best_student.pt\"                   # <--- path ai pesi salvati\n",
    "\n",
    "# ───── Utils ─────\n",
    "def macro_f1(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)[2]\n",
    "\n",
    "# ───── Dataset ─────\n",
    "class MouthDS(Dataset):\n",
    "    def __init__(self, csv_path, L=32):\n",
    "        df = pd.read_csv(csv_path).query('mouth_path.notna() and label.notna()').reset_index(drop=True)\n",
    "        df = df[df['label'].isin(LANGS)].reset_index(drop=True)\n",
    "        self.df, self.L = df, L\n",
    "        self.l2i = {l:i for i,l in enumerate(LANGS)}\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def _align(self, a):\n",
    "        T0 = a.shape[0]\n",
    "        if T0 >= self.L:\n",
    "            idx = np.linspace(0, T0-1, self.L).astype(int)\n",
    "        else:\n",
    "            idx = np.concatenate([np.arange(T0), np.full(self.L - T0, T0-1)])\n",
    "        return a[idx]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        r = self.df.iloc[i]\n",
    "        a = np.load(r.mouth_path, allow_pickle=True).astype('float32')\n",
    "        if a.max() > 1.5: a = a / 255.0\n",
    "        if a.ndim == 4: a = a.mean(-1)   # [T,H,W,C] → grayscale\n",
    "        a = self._align(a)\n",
    "        v = torch.from_numpy(a)\n",
    "        v3 = v.unsqueeze(0).unsqueeze(0)  # [1,1,L,H,W]\n",
    "        v3 = F.interpolate(v3, size=(L, OUT_H, OUT_W), mode='trilinear', align_corners=False).squeeze(0)\n",
    "        x  = (v3 - 0.5) / 0.5\n",
    "        y  = torch.tensor(self.l2i[r.label], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "# ───── Model ─────\n",
    "class Student(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = r3d_18(pretrained=True)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Linear(512,256), nn.GELU(), nn.Dropout(0.1),\n",
    "            nn.Linear(256,len(LANGS))\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.repeat(1,3,1,1,1)\n",
    "        f = self.backbone(x)\n",
    "        return self.head(f)\n",
    "\n",
    "# ───── Carica dati e modello ─────\n",
    "ds = MouthDS(TEST_CSV, L=L)\n",
    "dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = Student().to(DEVICE)\n",
    "state = torch.load(WEIGHTS, map_location=DEVICE)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "# ───── Valutazione ─────\n",
    "all_preds, all_gts = [], []\n",
    "with torch.no_grad():\n",
    "    for x,y in dl:\n",
    "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "        logits = model(x)\n",
    "        preds = logits.argmax(1).cpu().tolist()\n",
    "        all_preds.extend(preds)\n",
    "        all_gts.extend(y.cpu().tolist())\n",
    "\n",
    "f1 = macro_f1(all_gts, all_preds)\n",
    "cm = confusion_matrix(all_gts, all_preds, labels=list(range(len(LANGS))))\n",
    "report = classification_report(all_gts, all_preds, target_names=LANGS, zero_division=0)\n",
    "\n",
    "print(f\"\\nF1-macro: {f1:.3f}\")\n",
    "print(\"\\nConfusion Matrix (righe=GT, colonne=Pred):\")\n",
    "print(pd.DataFrame(cm, index=LANGS, columns=LANGS))\n",
    "print(\"\\nReport per classe:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1319cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# A/B EVALUATION RUNNER + MCNEMAR\n",
    "# ================================\n",
    "import os, json, math, numpy as np, pandas as pd, torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "# --- Prereq: usa MouthDS, Student, L, DEVICE dal notebook (già definiti dallo script A)\n",
    "assert \"MouthDS\" in globals() and \"Student\" in globals(), \"Definisci prima MouthDS/Student (script A).\"\n",
    "\n",
    "# CONFIG: setta queste 3 variabili\n",
    "ROOT = \"diagnostica_crossdomain/A1_EMODB\"  # oppure A2_BABELE per l'altro approccio\n",
    "CKPT_BASE = \"checkpoints/best_student_old.pt\"    # checkpoint BASELINE (prima delle modifiche)\n",
    "CKPT_NEW  = \"checkpoints/best_student_ema.pt\"    # checkpoint NUOVO (dopo le modifiche, idealmente EMA)\n",
    "\n",
    "# quali subset valutare (se esistono)\n",
    "SUBSETS = [\n",
    "    \"ALL.csv\",\n",
    "    \"L2_en/L2_en.csv\",\n",
    "    \"L1_it_es/L1_it_es.csv\",\n",
    "    \"buckets_blur/blur_low.csv\", \"buckets_blur/blur_high.csv\",\n",
    "    \"buckets_roi_drift/roi_drift_low.csv\", \"buckets_roi_drift/roi_drift_high.csv\",\n",
    "    \"buckets_motion/motion_low.csv\", \"buckets_motion/motion_high.csv\",\n",
    "    \"buckets_contrast/contrast_low.csv\", \"buckets_contrast/contrast_high.csv\",\n",
    "]\n",
    "\n",
    "def _load_model(ckpt_path):\n",
    "    m = Student().to(DEVICE)\n",
    "    state = torch.load(ckpt_path, map_location=DEVICE)\n",
    "    if isinstance(state, dict) and \"model\" in state:\n",
    "        m.load_state_dict(state[\"model\"], strict=True)\n",
    "    else:\n",
    "        m.load_state_dict(state, strict=False)\n",
    "    m.eval()\n",
    "    return m\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_preds(csv_path, ckpt_path, batch_size=16):\n",
    "    ds = MouthDS(csv_path, L=L, augment=False, use_teacher=False)\n",
    "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    model = _load_model(ckpt_path)\n",
    "    y_true, y_pred = [], []\n",
    "    for batch in dl:\n",
    "        x, y = batch\n",
    "        x = x.to(DEVICE); y = y.to(DEVICE)\n",
    "        logits, _ = model(x)\n",
    "        y_true.extend(y.cpu().tolist())\n",
    "        y_pred.extend(torch.argmax(logits, dim=1).cpu().tolist())\n",
    "    y_true = np.array(y_true); y_pred = np.array(y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred) if len(y_true) else 0.0\n",
    "    f1  = f1_score(y_true, y_pred, average=\"macro\") if len(y_true) else 0.0\n",
    "    return y_true, y_pred, acc, f1\n",
    "\n",
    "def mcnemar_pvalue(y_true, y_a, y_b):\n",
    "    \"\"\" esatto binomiale (two-sided) su b+c discordanti \"\"\"\n",
    "    correct_a = (y_a == y_true)\n",
    "    correct_b = (y_b == y_true)\n",
    "    b = int(np.sum(( correct_a) & (~correct_b)))  # A giusto, B sbaglia\n",
    "    c = int(np.sum((~correct_a) & ( correct_b)))  # A sbaglia, B giusto\n",
    "    n = b + c\n",
    "    if n == 0:\n",
    "        return 1.0, b, c\n",
    "    # two-sided esatta: 2 * sum_{i=0}^{min(b,c)} C(n,i) * 0.5^n\n",
    "    from math import comb\n",
    "    k = min(b, c)\n",
    "    p = 2.0 * sum(comb(n, i) for i in range(0, k+1)) / (2.0**n)\n",
    "    p = min(1.0, p)\n",
    "    return p, b, c\n",
    "\n",
    "rows = []\n",
    "missing = []\n",
    "for rel in SUBSETS:\n",
    "    csv_path = os.path.join(ROOT, rel)\n",
    "    if not os.path.exists(csv_path):\n",
    "        missing.append(rel); continue\n",
    "    y, yb, acc_b, f1_b = eval_preds(csv_path, CKPT_BASE)\n",
    "    y, yn, acc_n, f1_n = eval_preds(csv_path, CKPT_NEW)\n",
    "    p, b, c = mcnemar_pvalue(y, yb, yn)\n",
    "    rows.append({\n",
    "        \"subset\": rel,\n",
    "        \"N\": int(len(y)),\n",
    "        \"Acc_base\": round(acc_b,3), \"F1_base\": round(f1_b,3),\n",
    "        \"Acc_new\":  round(acc_n,3), \"F1_new\":  round(f1_n,3),\n",
    "        \"ΔAcc\": round(acc_n-acc_b,3), \"ΔF1\": round(f1_n-f1_b,3),\n",
    "        \"McNemar_p\": float(p), \"b(A✔,N✘)\": b, \"c(A✘,N✔)\": c\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values([\"subset\"])\n",
    "print(df.to_string(index=False))\n",
    "if missing:\n",
    "    print(\"\\n(non trovati):\", missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9a45f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TRAIN E0_baseline | EMB_KD_ON=False  mode=clean  conf={'en': 0.05, 'it': 0.05, 'es': 0.05}  λ={'en': 0.0, 'it': 0.0, 'es': 0.0}  μ=0.0  loss=mse  contrastive=False (μ=0.05, τ=0.07) =====\n",
      "Epoch 01  Val-F1=0.665\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it  12  16   0\n",
      "es  16   0  12\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "  → New best: Val-F1=0.665  saved: ckpts/E0_baseline__embkd0__modeclean__mu0__th_en0.050_it0.050_es0.050__lam_en0.000_it0.000_es0.000__lossmse__contr0/best.pt\n",
      "Epoch 02  Val-F1=0.893\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   6  22   0\n",
      "es   1   2  25\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "  → New best: Val-F1=0.893  saved: ckpts/E0_baseline__embkd0__modeclean__mu0__th_en0.050_it0.050_es0.050__lam_en0.000_it0.000_es0.000__lossmse__contr0/best.pt\n",
      "Epoch 03  Val-F1=0.891\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   5  22   1\n",
      "es   0   3  25\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 04  Val-F1=0.892\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   0   2  26\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 05  Val-F1=0.660\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   3  16   9\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 06  Val-F1=0.641\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   5  15   8\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 07  Val-F1=0.822\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0  14  14\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 08  Val-F1=0.928\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   6  22\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "  → New best: Val-F1=0.928  saved: ckpts/E0_baseline__embkd0__modeclean__mu0__th_en0.050_it0.050_es0.050__lam_en0.000_it0.000_es0.000__lossmse__contr0/best.pt\n",
      "Epoch 09  Val-F1=0.720\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   5  23   0\n",
      "es   0  17  11\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 10  Val-F1=0.786\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  26   2\n",
      "es   0  15  13\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 11  Val-F1=0.710\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   6  22   0\n",
      "es  14   3  11\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 12  Val-F1=0.926\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   2   4  22\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 13  Val-F1=0.900\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   3   5  20\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 14  Val-F1=0.976\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   2  26   0\n",
      "es   0   0  28\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "  → New best: Val-F1=0.976  saved: ckpts/E0_baseline__embkd0__modeclean__mu0__th_en0.050_it0.050_es0.050__lam_en0.000_it0.000_es0.000__lossmse__contr0/best.pt\n",
      "Epoch 15  Val-F1=0.738\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   5  22   1\n",
      "es   0  15  13\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 16  Val-F1=0.940\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   2  26   0\n",
      "es   0   3  25\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 17  Val-F1=0.892\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   3  25   0\n",
      "es   0   6  22\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 18  Val-F1=0.928\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   6  22\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 19  Val-F1=0.964\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   3  25\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 20  Val-F1=0.890\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   9  19\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 21  Val-F1=0.864\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0  11  17\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.976\n",
      "\n",
      "[E0_baseline__IN_VAL] N=84  Acc=0.976  Macro-F1=0.976\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   2  26   0\n",
      "es   0   0  28\n",
      "\n",
      "[E0_baseline__CROSS_EMODB_all] N=21  Acc=0.619  Macro-F1=0.551\n",
      "    en  it  es\n",
      "en   1   4   2\n",
      "it   0   5   2\n",
      "es   0   0   7\n",
      "\n",
      "[E0_baseline__CROSS_EMODB_L1_it_es] N=14  Acc=0.857  Macro-F1=0.854\n",
      "    en  it  es\n",
      "en   0   0   0\n",
      "it   0   5   2\n",
      "es   0   0   7\n",
      "\n",
      "[E0_baseline__CROSS_EMODB_L2_en] N=7  Acc=0.143  Macro-F1=0.083\n",
      "    en  it  es\n",
      "en   1   4   2\n",
      "it   0   0   0\n",
      "es   0   0   0\n",
      "\n",
      "=== EN L1 (BABELE train+val) vs EN L2 (EMODB) ===\n",
      "EN_L1: N=98  Acc(en)=1.000  p(en) mean=0.932  margin mean=3.112\n",
      "EN_L2: N=7  Acc(en)=0.143  p(en) mean=0.136  margin mean=-2.292\n",
      "AUC p(en)=1.000   AUC margin=1.000\n",
      "\n",
      "===== TRAIN E1_EMB_KD_clean_bal | EMB_KD_ON=True  mode=clean  conf={'en': 0.05, 'it': 0.05, 'es': 0.05}  λ={'en': 0.012, 'it': 0.05, 'es': 0.05}  μ=0.15  loss=mse  contrastive=False (μ=0.05, τ=0.07) =====\n",
      "Epoch 01  Val-F1=0.892\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   5  23   0\n",
      "es   0   4  24\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "  → New best: Val-F1=0.892  saved: ckpts/E1_EMB_KD_clean_bal__embkd1__modeclean__mu0.15__th_en0.050_it0.050_es0.050__lam_en0.012_it0.050_es0.050__lossmse__contr0/best.pt\n",
      "Epoch 02  Val-F1=0.928\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   1  27   0\n",
      "es   0   5  23\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "  → New best: Val-F1=0.928  saved: ckpts/E1_EMB_KD_clean_bal__embkd1__modeclean__mu0.15__th_en0.050_it0.050_es0.050__lam_en0.012_it0.050_es0.050__lossmse__contr0/best.pt\n",
      "Epoch 03  Val-F1=0.915\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   0   0  28\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 04  Val-F1=0.964\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   3  25   0\n",
      "es   0   0  28\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "  → New best: Val-F1=0.964  saved: ckpts/E1_EMB_KD_clean_bal__embkd1__modeclean__mu0.15__th_en0.050_it0.050_es0.050__lam_en0.012_it0.050_es0.050__lossmse__contr0/best.pt\n",
      "Epoch 05  Val-F1=0.820\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   2   6  20\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 06  Val-F1=0.745\n",
      "    en  it  es\n",
      "en  23   0   5\n",
      "it   3  25   0\n",
      "es   0  13  15\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 07  Val-F1=0.602\n",
      "    en  it  es\n",
      "en  14   0  14\n",
      "it   7  14   7\n",
      "es   0   5  23\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 08  Val-F1=0.976\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   2  26   0\n",
      "es   0   0  28\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "  → New best: Val-F1=0.976  saved: ckpts/E1_EMB_KD_clean_bal__embkd1__modeclean__mu0.15__th_en0.050_it0.050_es0.050__lam_en0.012_it0.050_es0.050__lossmse__contr0/best.pt\n",
      "Epoch 09  Val-F1=0.779\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   2  26   0\n",
      "es   9   6  13\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 10  Val-F1=0.927\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   1   5  22\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 11  Val-F1=0.852\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it  10  17   1\n",
      "es   1   0  27\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 12  Val-F1=0.723\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   6  22   0\n",
      "es   0  16  12\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 13  Val-F1=0.833\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   3   4  21\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 14  Val-F1=0.939\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   2   3  23\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 15  Val-F1=0.658\n",
      "    en  it  es\n",
      "en   7   0  21\n",
      "it   4  24   0\n",
      "es   0   1  27\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.976\n",
      "\n",
      "[E1_EMB_KD_clean_bal__IN_VAL] N=84  Acc=0.976  Macro-F1=0.976\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   2  26   0\n",
      "es   0   0  28\n",
      "\n",
      "[E1_EMB_KD_clean_bal__CROSS_EMODB_all] N=21  Acc=0.476  Macro-F1=0.392\n",
      "    en  it  es\n",
      "en   0   5   2\n",
      "it   1   4   2\n",
      "es   0   1   6\n",
      "\n",
      "[E1_EMB_KD_clean_bal__CROSS_EMODB_L1_it_es] N=14  Acc=0.714  Macro-F1=0.489\n",
      "    en  it  es\n",
      "en   0   0   0\n",
      "it   1   4   2\n",
      "es   0   1   6\n",
      "\n",
      "[E1_EMB_KD_clean_bal__CROSS_EMODB_L2_en] N=7  Acc=0.000  Macro-F1=0.000\n",
      "    en  it  es\n",
      "en   0   5   2\n",
      "it   0   0   0\n",
      "es   0   0   0\n",
      "\n",
      "=== EN L1 (BABELE train+val) vs EN L2 (EMODB) ===\n",
      "EN_L1: N=98  Acc(en)=1.000  p(en) mean=0.916  margin mean=2.956\n",
      "EN_L2: N=7  Acc(en)=0.000  p(en) mean=0.131  margin mean=-1.969\n",
      "AUC p(en)=1.000   AUC margin=1.000\n",
      "\n",
      "===== TRAIN E2_EMB_KD_mix_bal | EMB_KD_ON=True  mode=mix  conf={'en': 0.05, 'it': 0.05, 'es': 0.05}  λ={'en': 0.012, 'it': 0.05, 'es': 0.05}  μ=0.15  loss=mse  contrastive=False (μ=0.05, τ=0.07) =====\n",
      "Epoch 01  Val-F1=0.767\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  20   1\n",
      "es   3   8  17\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "  → New best: Val-F1=0.767  saved: ckpts/E2_EMB_KD_mix_bal__embkd1__modemix__mu0.15__th_en0.050_it0.050_es0.050__lam_en0.012_it0.050_es0.050__lossmse__contr0/best.pt\n",
      "Epoch 02  Val-F1=0.811\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   7   2  19\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "  → New best: Val-F1=0.811  saved: ckpts/E2_EMB_KD_mix_bal__embkd1__modemix__mu0.15__th_en0.050_it0.050_es0.050__lam_en0.012_it0.050_es0.050__lossmse__contr0/best.pt\n",
      "Epoch 03  Val-F1=0.796\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   6   4  18\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 04  Val-F1=0.831\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   5  23   0\n",
      "es   0   9  19\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "  → New best: Val-F1=0.831  saved: ckpts/E2_EMB_KD_mix_bal__embkd1__modemix__mu0.15__th_en0.050_it0.050_es0.050__lam_en0.012_it0.050_es0.050__lossmse__contr0/best.pt\n",
      "Epoch 05  Val-F1=0.880\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   0   3  25\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "  → New best: Val-F1=0.880  saved: ckpts/E2_EMB_KD_mix_bal__embkd1__modemix__mu0.15__th_en0.050_it0.050_es0.050__lam_en0.012_it0.050_es0.050__lossmse__contr0/best.pt\n",
      "Epoch 06  Val-F1=0.778\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   6  22   0\n",
      "es   5   7  16\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 07  Val-F1=0.964\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   1  27   0\n",
      "es   1   1  26\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "  → New best: Val-F1=0.964  saved: ckpts/E2_EMB_KD_mix_bal__embkd1__modemix__mu0.15__th_en0.050_it0.050_es0.050__lam_en0.012_it0.050_es0.050__lossmse__contr0/best.pt\n",
      "Epoch 08  Val-F1=0.903\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   8  20\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 09  Val-F1=0.819\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  20   1\n",
      "es   1   6  21\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 10  Val-F1=0.822\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0  14  14\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 11  Val-F1=0.801\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   4  11  13\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 12  Val-F1=1.000\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   0  28\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "  → New best: Val-F1=1.000  saved: ckpts/E2_EMB_KD_mix_bal__embkd1__modemix__mu0.15__th_en0.050_it0.050_es0.050__lam_en0.012_it0.050_es0.050__lossmse__contr0/best.pt\n",
      "Epoch 13  Val-F1=0.850\n",
      "    en  it  es\n",
      "en  27   1   0\n",
      "it   0  28   0\n",
      "es   2   9  17\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 14  Val-F1=0.976\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   2  26\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 15  Val-F1=0.864\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0  11  17\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 16  Val-F1=0.769\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   5  12  11\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 17  Val-F1=0.793\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0  16  12\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 18  Val-F1=0.862\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   1  27   0\n",
      "es   6   4  18\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 19  Val-F1=0.940\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   5  23\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 1.000\n",
      "\n",
      "[E2_EMB_KD_mix_bal__IN_VAL] N=84  Acc=1.000  Macro-F1=1.000\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   0  28\n",
      "\n",
      "[E2_EMB_KD_mix_bal__CROSS_EMODB_all] N=21  Acc=0.571  Macro-F1=0.519\n",
      "    en  it  es\n",
      "en   1   5   1\n",
      "it   0   5   2\n",
      "es   0   1   6\n",
      "\n",
      "[E2_EMB_KD_mix_bal__CROSS_EMODB_L1_it_es] N=14  Acc=0.786  Macro-F1=0.785\n",
      "    en  it  es\n",
      "en   0   0   0\n",
      "it   0   5   2\n",
      "es   0   1   6\n",
      "\n",
      "[E2_EMB_KD_mix_bal__CROSS_EMODB_L2_en] N=7  Acc=0.143  Macro-F1=0.083\n",
      "    en  it  es\n",
      "en   1   5   1\n",
      "it   0   0   0\n",
      "es   0   0   0\n",
      "\n",
      "=== EN L1 (BABELE train+val) vs EN L2 (EMODB) ===\n",
      "EN_L1: N=98  Acc(en)=1.000  p(en) mean=0.963  margin mean=3.691\n",
      "EN_L2: N=7  Acc(en)=0.143  p(en) mean=0.217  margin mean=-1.318\n",
      "AUC p(en)=1.000   AUC margin=1.000\n",
      "\n",
      "===== TRAIN E3_EMB_KD_clean_contr | EMB_KD_ON=True  mode=clean  conf={'en': 0.06, 'it': 0.05, 'es': 0.05}  λ={'en': 0.011, 'it': 0.05, 'es': 0.05}  μ=0.14  loss=cos  contrastive=True (μ=0.05, τ=0.07) =====\n",
      "Epoch 01  Val-F1=0.857\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  21   7\n",
      "es   0   5  23\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "  → New best: Val-F1=0.857  saved: ckpts/E3_EMB_KD_clean_contr__embkd1__modeclean__mu0.14__th_en0.060_it0.050_es0.050__lam_en0.011_it0.050_es0.050__losscos__contr1/best.pt\n",
      "Epoch 02  Val-F1=0.903\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   4  22   2\n",
      "es   0   2  26\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "  → New best: Val-F1=0.903  saved: ckpts/E3_EMB_KD_clean_contr__embkd1__modeclean__mu0.14__th_en0.060_it0.050_es0.050__lam_en0.011_it0.050_es0.050__losscos__contr1/best.pt\n",
      "Epoch 03  Val-F1=0.915\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   5  22   1\n",
      "es   0   1  27\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "  → New best: Val-F1=0.915  saved: ckpts/E3_EMB_KD_clean_contr__embkd1__modeclean__mu0.14__th_en0.060_it0.050_es0.050__lam_en0.011_it0.050_es0.050__losscos__contr1/best.pt\n",
      "Epoch 04  Val-F1=0.856\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   0   5  23\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 05  Val-F1=0.900\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   5  20   3\n",
      "es   0   0  28\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 06  Val-F1=0.904\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  21   7\n",
      "es   0   1  27\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 07  Val-F1=0.882\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   2   1  25\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 08  Val-F1=0.914\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   6  21   1\n",
      "es   0   0  28\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 09  Val-F1=0.800\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   9   6  13\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Epoch 10  Val-F1=0.628\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0   3  25\n",
      "es   0   0  28\n",
      "[EMB-KD] gate_rate_total=0.00%  by_lang={'en': 0.0, 'it': 0.0, 'es': 0.0}\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.915\n",
      "\n",
      "[E3_EMB_KD_clean_contr__IN_VAL] N=84  Acc=0.917  Macro-F1=0.915\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   5  22   1\n",
      "es   0   1  27\n",
      "\n",
      "[E3_EMB_KD_clean_contr__CROSS_EMODB_all] N=21  Acc=0.571  Macro-F1=0.568\n",
      "    en  it  es\n",
      "en   3   2   2\n",
      "it   2   5   0\n",
      "es   0   3   4\n",
      "\n",
      "[E3_EMB_KD_clean_contr__CROSS_EMODB_L1_it_es] N=14  Acc=0.643  Macro-F1=0.465\n",
      "    en  it  es\n",
      "en   0   0   0\n",
      "it   2   5   0\n",
      "es   0   3   4\n",
      "\n",
      "[E3_EMB_KD_clean_contr__CROSS_EMODB_L2_en] N=7  Acc=0.429  Macro-F1=0.200\n",
      "    en  it  es\n",
      "en   3   2   2\n",
      "it   0   0   0\n",
      "es   0   0   0\n",
      "\n",
      "=== EN L1 (BABELE train+val) vs EN L2 (EMODB) ===\n",
      "EN_L1: N=98  Acc(en)=1.000  p(en) mean=0.878  margin mean=2.517\n",
      "EN_L2: N=7  Acc(en)=0.429  p(en) mean=0.300  margin mean=-0.526\n",
      "AUC p(en)=1.000   AUC margin=1.000\n",
      "\n",
      "================ ALL RUNS SUMMARY ================\n",
      "                  run  EMB_KD_ON  mode  conf_th_emb_en  conf_th_emb_it  conf_th_emb_es  lambda_emb_en  lambda_emb_it  lambda_emb_es  MU_EMB EMB_LOSS  contrastive    F1_in  F1_x_all  F1_x_L1  F1_x_L2  Acc_en_L1  Acc_en_L2  AUC_p_en  AUC_margin  N_en_L1  N_en_L2  ΔF1_in_vs_baseline  ΔF1_x_vs_baseline  ΔAcc_en_L1_vs_base  ΔAcc_en_L2_vs_base\n",
      "          E0_baseline      False clean            0.05            0.05            0.05          0.000           0.00           0.00    0.00      mse            0 0.976160  0.550926 0.854167 0.083333        1.0   0.142857       1.0         1.0       98        7            0.000000           0.000000                 0.0            0.000000\n",
      "  E1_EMB_KD_clean_bal       True clean            0.05            0.05            0.05          0.012           0.05           0.05    0.15      mse            0 0.976160  0.392157 0.488889 0.000000        1.0   0.000000       1.0         1.0       98        7            0.000000          -0.158769                 0.0           -0.142857\n",
      "    E2_EMB_KD_mix_bal       True   mix            0.05            0.05            0.05          0.012           0.05           0.05    0.15      mse            0 1.000000  0.518519 0.784615 0.083333        1.0   0.142857       1.0         1.0       98        7            0.023840          -0.032407                 0.0            0.000000\n",
      "E3_EMB_KD_clean_contr       True clean            0.06            0.05            0.05          0.011           0.05           0.05    0.14      cos            1 0.915021  0.567873 0.464646 0.200000        1.0   0.428571       1.0         1.0       98        7           -0.061139           0.016947                 0.0            0.285714\n",
      "\n",
      "Saved: reports/emb_kd_feature_strict_summary.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Runner EMB-KD (feature-based rigorosa) — r3d_18 + SpecAug3D + MixUp + MixStyle\n",
    "Accortezze:\n",
    "  • Nessun mismatch MixUp↔KD: selezionabile\n",
    "      - feature_kd_mode=\"clean\": KD su input non-mixato (consigliato)\n",
    "      - feature_kd_mode=\"mix\":   KD su input mixato e anche t_emb, gate, pesi mixati\n",
    "  • Gating per-classe su confidenza/margine in spazio audio (prototipi per lingua)\n",
    "  • Pesi per-classe + anti-dominanza su EN\n",
    "  • (Opzionale) contrastive KD in-batch (InfoNCE) sullo spazio comune\n",
    "\n",
    "Valutazioni:\n",
    "  • In-domain VAL\n",
    "  • Cross EMODB (all, L1 it+es, L2 en)\n",
    "  • EN L1 vs EN L2 (Acc, AUC p_en, AUC margin)\n",
    "\"\"\"\n",
    "\n",
    "import os, json, random, copy, math\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.video import r3d_18, R3D_18_Weights\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "# ───────────── Config base ─────────────\n",
    "SEED = 42\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 8\n",
    "LR, WD = 3e-4, 1e-3\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "LANGS = ['en','it','es']\n",
    "OUT_H, OUT_W, L = 64, 64, 32\n",
    "MIXUP_ALPHA = 0.30\n",
    "PATIENCE = 7\n",
    "MAX_LR = 3e-4\n",
    "DIV_FACTOR = 10\n",
    "FINAL_DIV = 100\n",
    "\n",
    "# Datasets (modifica se necessario)\n",
    "TRAIN_CSV = \"NEWEMODB/manifest_train.csv\"\n",
    "VAL_CSV   = \"NEWEMODB/manifest_test.csv\"\n",
    "CROSS_CSV = \"EMODB/manifest_test.csv\"\n",
    "\n",
    "# Device & AMP\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "AMP_ENABLED = (DEVICE.type == 'cuda')\n",
    "PIN_MEMORY = (DEVICE.type == 'cuda')\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ───────────── EMB-KD config ─────────────\n",
    "PROJ_DIM = 128                 # dimensione spazio comune audio/video\n",
    "EMB_LOSS_TYPE = 'mse'          # 'mse' | 'cos'\n",
    "MU_EMB = 0.15                  # peso della loss di embedding\n",
    "PROTO_GATE = True              # abilita gating basato su prototipi audio\n",
    "# soglie di margine (cos_true - max cos_other) per il gate; tipicamente in [0, 1]\n",
    "CONF_TH_EMB_PER = {'en': 0.05, 'it': 0.05, 'es': 0.05}\n",
    "# pesi per-classe della EMB-KD\n",
    "LAMBDA_EMB_PER = {'en': 0.012, 'it': 0.05, 'es': 0.05}\n",
    "\n",
    "# Opzionale: contrastive KD (InfoNCE) tra z_v e z_a in-batch\n",
    "USE_CONTRASTIVE = False\n",
    "MU_CONTR = 0.05\n",
    "TAU_INFO_NCE = 0.07\n",
    "\n",
    "# Modo rigoroso per evitare mismatch MixUp↔KD:\n",
    "#  - \"clean\": KD sulle feature da input NON mixato (consigliato)\n",
    "#  - \"mix\":   KD sulle feature da input mixato + t_emb mixato con stesso λ/idx + gate e pesi mixati\n",
    "FEATURE_KD_MODE = \"clean\"  # \"clean\" | \"mix\"\n",
    "\n",
    "# ───────────── Metriche ─────────────\n",
    "def macro_f1(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true, y_pred,\n",
    "                                           average='macro', zero_division=0)[2]\n",
    "\n",
    "# ───────────── Augmentazioni ─────────────\n",
    "class SpecAug3D:\n",
    "    def __init__(self, H, W, T_mask=4, S_mask=4):\n",
    "        self.tf = T.Compose([\n",
    "            T.ToPILImage(),\n",
    "            T.RandomResizedCrop((H,W), scale=(0.95,1.0), ratio=(1.0,1.0)),\n",
    "            T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),\n",
    "            T.RandomHorizontalFlip(0.5),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "        self.T_mask, self.S_mask = T_mask, S_mask\n",
    "\n",
    "    def __call__(self, vid):\n",
    "        frames = []\n",
    "        for f in vid:\n",
    "            img = (f*255).byte()\n",
    "            t   = self.tf(img).squeeze(0)\n",
    "            frames.append(t)\n",
    "        vid = torch.stack(frames)\n",
    "        L_,H,W = vid.shape\n",
    "        if L_ > self.T_mask:\n",
    "            t0 = random.randrange(0, L_-self.T_mask+1)\n",
    "            vid[t0:t0+self.T_mask] = 0\n",
    "        if H>self.S_mask and W>self.S_mask:\n",
    "            fi = random.randrange(0, L_)\n",
    "            h0 = random.randrange(0, H-self.S_mask+1)\n",
    "            w0 = random.randrange(0, W-self.S_mask+1)\n",
    "            vid[fi,h0:h0+self.S_mask,w0:w0+self.S_mask] = 0\n",
    "        return vid\n",
    "\n",
    "class RandomErasing3D:\n",
    "    def __init__(self, p=0.3, size=(8,8,8)):\n",
    "        self.p = p\n",
    "        self.d, self.h, self.w = size\n",
    "    def __call__(self, vid):\n",
    "        if random.random()>self.p: return vid\n",
    "        L_,H,W = vid.shape\n",
    "        sd = random.randint(0, max(0, L_-self.d))\n",
    "        sh = random.randint(0, max(0, H-self.h))\n",
    "        sw = random.randint(0, max(0, W-self.w))\n",
    "        vid[sd:sd+self.d, sh:sh+self.h, sw:sw+self.w] = 0\n",
    "        return vid\n",
    "\n",
    "def mixup_return_params(x, y_onehot, alpha=MIXUP_ALPHA):\n",
    "    \"\"\"Ritorna x_mix, y_mix, lam(float), idx(permutation)\"\"\"\n",
    "    if alpha <= 0:\n",
    "        B = x.size(0)\n",
    "        idx = torch.arange(B, device=x.device)\n",
    "        lam = 1.0\n",
    "        return x, y_onehot, lam, idx\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    idx = torch.randperm(x.size(0), device=x.device)\n",
    "    x_m = lam*x + (1-lam)*x[idx]\n",
    "    y_m = lam*y_onehot + (1-lam)*y_onehot[idx]\n",
    "    return x_m, y_m, float(lam), idx\n",
    "\n",
    "# ───────────── Loss ─────────────\n",
    "class SoftFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__(); self.alpha, self.gamma = alpha, gamma\n",
    "    def forward(self, logits, y_soft):\n",
    "        logp = F.log_softmax(logits,1)\n",
    "        p    = logp.exp()\n",
    "        ce   = -(y_soft * logp).sum(1)\n",
    "        pt   = (y_soft * p).sum(1)\n",
    "        return ( self.alpha * (1-pt)**self.gamma * ce ).mean()\n",
    "\n",
    "def emb_loss(z_v, z_a, typ='mse'):\n",
    "    if typ == 'mse':\n",
    "        return F.mse_loss(z_v, z_a, reduction='none').mean(dim=1)  # [B]\n",
    "    elif typ == 'cos':\n",
    "        z_v = F.normalize(z_v, dim=1)\n",
    "        z_a = F.normalize(z_a, dim=1)\n",
    "        return (1 - (z_v * z_a).sum(dim=1))  # [B]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown EMB_LOSS_TYPE: {typ}\")\n",
    "\n",
    "def info_nce_loss(z_v, z_a, tau=0.07):\n",
    "    \"\"\"\n",
    "    In-batch InfoNCE simmetrica (positivi diagonale).\n",
    "    z_v,z_a: [B,d], già nello stesso spazio (non è necessario normalizzare qui: lo facciamo dentro).\n",
    "    \"\"\"\n",
    "    z_vn = F.normalize(z_v, dim=1)\n",
    "    z_an = F.normalize(z_a, dim=1)\n",
    "    # similarità [B,B]\n",
    "    logits_v2a = torch.matmul(z_vn, z_an.t()) / tau  # ogni riga: ancoraggio = v_i, positivi = a_i\n",
    "    logits_a2v = torch.matmul(z_an, z_vn.t()) / tau\n",
    "    labels = torch.arange(z_v.size(0), device=z_v.device)\n",
    "    loss1 = F.cross_entropy(logits_v2a, labels)\n",
    "    loss2 = F.cross_entropy(logits_a2v, labels)\n",
    "    return 0.5*(loss1 + loss2)\n",
    "\n",
    "# ───────────── MixStyle ─────────────\n",
    "class MixStyle(nn.Module):\n",
    "    def __init__(self, p=0.3, α=0.1):\n",
    "        super().__init__(); self.p, self.α = p, α\n",
    "    def forward(self, x):\n",
    "        if not self.training or random.random()>self.p:\n",
    "            return x\n",
    "        B,C    = x.shape\n",
    "        mu     = x.mean(1,keepdim=True)\n",
    "        sig    = (x.var(1,keepdim=True)+1e-6).sqrt()\n",
    "        lm     = np.random.beta(self.α, self.α)\n",
    "        perm   = torch.randperm(B,device=x.device)\n",
    "        mu2    = mu[perm]; sig2 = sig[perm]\n",
    "        mu_mix = lm*mu + (1-lm)*mu2\n",
    "        sig_mix= lm*sig+ (1-lm)*sig2\n",
    "        x_norm = (x-mu)/sig\n",
    "        return x_norm*sig_mix + mu_mix\n",
    "\n",
    "# ───────────── Dataset ─────────────\n",
    "AUDIO_EMB_CANDIDATES = [\n",
    "    'feats_path',  # ← colonna con path embedding audio (Teacher)\n",
    "]\n",
    "\n",
    "class MouthDS(Dataset):\n",
    "    \"\"\"\n",
    "    TRAIN (use_teacher=True): (x, y, t_emb) — t_emb: embedding audio grezzo (np.load)\n",
    "    VAL/TEST (use_teacher=False): (x, y)\n",
    "    \"\"\"\n",
    "    def __init__(self,csv,L=32,augment=False,use_teacher=False):\n",
    "        df = pd.read_csv(csv).query('mouth_path.notna()').reset_index(drop=True)\n",
    "        self.df, self.L = df, L\n",
    "        self.l2i         = {l:i for i,l in enumerate(LANGS)}\n",
    "        self.spec        = SpecAug3D(OUT_H,OUT_W) if augment else None\n",
    "        self.randomerase = RandomErasing3D()      if augment else None\n",
    "        self.use_teacher = use_teacher\n",
    "\n",
    "        # trova colonna embedding audio (se esiste)\n",
    "        self.audio_col = None\n",
    "        for c in AUDIO_EMB_CANDIDATES:\n",
    "            if c in self.df.columns:\n",
    "                self.audio_col = c\n",
    "                break\n",
    "        if self.use_teacher and self.audio_col is None:\n",
    "            raise ValueError(\n",
    "                f\"Nessuna colonna embedding audio trovata. Attese una tra: {AUDIO_EMB_CANDIDATES}.\"\n",
    "            )\n",
    "\n",
    "    def _align(self,a):\n",
    "        T0 = a.shape[0]\n",
    "        if T0>=self.L:\n",
    "            idx = np.linspace(0,T0-1,self.L).astype(int)\n",
    "        else:\n",
    "            idx = np.concatenate([np.arange(T0),\n",
    "                                  np.full(self.L-T0, T0-1)])\n",
    "        return a[idx]\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        r = self.df.iloc[i]\n",
    "        a = np.load(r.mouth_path,allow_pickle=True).astype('float32')/255.\n",
    "        if a.ndim==4 and a.shape[-1]==3:\n",
    "            a = a.mean(-1)\n",
    "        a = self._align(a)\n",
    "        v = torch.from_numpy(a)  # [T,H,W] float32 in [0,1]\n",
    "        if self.spec:        v = self.spec(v)\n",
    "        if self.randomerase: v = self.randomerase(v)\n",
    "        v3 = v.unsqueeze(0).unsqueeze(0)  # [1,1,T,H,W]\n",
    "        v3 = F.interpolate(v3, size=(L,OUT_H,OUT_W),\n",
    "                           mode='trilinear', align_corners=False).squeeze(0)\n",
    "        x  = (v3 - 0.5)/0.5  # [-1,1]\n",
    "        y  = torch.tensor(self.l2i[str(r.label).lower()],dtype=torch.long)\n",
    "\n",
    "        if not self.use_teacher:\n",
    "            return x, y\n",
    "\n",
    "        # EMBEDDING audio\n",
    "        path_emb = str(r[self.audio_col])\n",
    "        if not (isinstance(path_emb, str) and os.path.exists(path_emb)):\n",
    "            raise FileNotFoundError(f\"Embedding audio mancante o path non valido: {path_emb}\")\n",
    "        z_a = np.load(path_emb, allow_pickle=True).astype('float32')\n",
    "        z_a = np.squeeze(z_a)\n",
    "        if z_a.ndim != 1:\n",
    "            # se è [T, D] facciamo una media temporale\n",
    "            z_a = z_a.reshape(-1, z_a.shape[-1]).mean(axis=0).astype('float32')\n",
    "        t_emb = torch.from_numpy(z_a)  # [d_a]\n",
    "        return x, y, t_emb\n",
    "\n",
    "# ───────────── Model ─────────────\n",
    "class Student(nn.Module):\n",
    "    def __init__(self, proj_dim=PROJ_DIM):\n",
    "        super().__init__()\n",
    "        self.backbone = r3d_18(weights=R3D_18_Weights.DEFAULT)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.mixstyle   = MixStyle(p=0.3, α=0.1)\n",
    "        # proiezione video→spazio comune d\n",
    "        self.proj_v     = nn.Sequential(\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Linear(512, proj_dim)\n",
    "        )\n",
    "        self.head       = nn.Sequential(\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Linear(512,256), nn.GELU(), nn.Dropout(0.1),\n",
    "            nn.Linear(256,len(LANGS))\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # x: [B,1,T,H,W]\n",
    "        x = x.repeat(1,3,1,1,1)\n",
    "        f = self.backbone(x)      # [B,512]\n",
    "        f = self.mixstyle(f)\n",
    "        logits = self.head(f)\n",
    "        z_v = self.proj_v(f)      # [B,d]\n",
    "        return logits, f, z_v\n",
    "\n",
    "# ───────────── Helpers EMB-KD ─────────────\n",
    "IDX2LANG = {i:l for i,l in enumerate(LANGS)}\n",
    "\n",
    "def _cos_sim(a, b, eps=1e-8):\n",
    "    a = F.normalize(a, dim=-1)\n",
    "    b = F.normalize(b, dim=-1)\n",
    "    return (a*b).sum(dim=-1)\n",
    "\n",
    "def build_audio_prototypes(train_csv):\n",
    "    \"\"\"Crea prototipi audio per lingua (media degli embedding). Ritorna (protos: dict lang->torch.Tensor[d_a], d_a).\"\"\"\n",
    "    df = pd.read_csv(train_csv).query('mouth_path.notna()')\n",
    "    audio_col = None\n",
    "    for c in AUDIO_EMB_CANDIDATES:\n",
    "        if c in df.columns:\n",
    "            audio_col = c; break\n",
    "    if audio_col is None:\n",
    "        raise ValueError(f\"Colonna embedding audio non trovata in {train_csv}.\")\n",
    "    acc = {l: [] for l in LANGS}\n",
    "    for _,r in df.iterrows():\n",
    "        lp = str(r['label']).lower()\n",
    "        if lp not in acc: continue\n",
    "        p = str(r[audio_col])\n",
    "        if not (isinstance(p,str) and os.path.exists(p)): continue\n",
    "        z = np.load(p, allow_pickle=True).astype('float32')\n",
    "        z = np.squeeze(z)\n",
    "        if z.ndim != 1:\n",
    "            z = z.reshape(-1, z.shape[-1]).mean(axis=0).astype('float32')\n",
    "        acc[lp].append(z)\n",
    "    protos = {}\n",
    "    d_a = None\n",
    "    for l, vecs in acc.items():\n",
    "        if len(vecs)==0:\n",
    "            continue\n",
    "        M = np.stack(vecs, axis=0).mean(axis=0).astype('float32')\n",
    "        d_a = M.shape[0]\n",
    "        protos[l] = torch.tensor(M, dtype=torch.float32)\n",
    "    if len(protos)==0:\n",
    "        raise ValueError(\"Impossibile costruire prototipi audio: nessun embedding letto.\")\n",
    "    return protos, d_a\n",
    "\n",
    "def gate_with_prototypes(t_emb, y, protos, conf_th_emb_per):\n",
    "    \"\"\"\n",
    "    t_emb: [B, d_a] tensor\n",
    "    y:    [B] long\n",
    "    protos: dict lang->tensor[d_a]\n",
    "    Ritorna: gate [B] float{0,1}, margin [B] float\n",
    "    \"\"\"\n",
    "    B = t_emb.size(0)\n",
    "    langs = LANGS\n",
    "    P = torch.stack([protos[l].to(t_emb.device) for l in langs], dim=0)  # [K,d_a]\n",
    "    z = F.normalize(t_emb, dim=1)  # [B,d_a]\n",
    "    Pn = F.normalize(P, dim=1)     # [K,d_a]\n",
    "    sim = torch.matmul(z, Pn.t())  # [B,K]\n",
    "    true_idx = y\n",
    "    true_sim = sim[torch.arange(B, device=z.device), true_idx]\n",
    "    sim_clone = sim.clone()\n",
    "    sim_clone[torch.arange(B, device=z.device), true_idx] = -1e9\n",
    "    max_other = sim_clone.max(dim=1).values\n",
    "    margin = true_sim - max_other  # [B]\n",
    "    th_vec = torch.tensor([conf_th_emb_per[IDX2LANG[int(yi)]] for yi in y.tolist()],\n",
    "                          device=z.device, dtype=torch.float32)\n",
    "    gate = (margin >= th_vec).float()\n",
    "    return gate, margin\n",
    "\n",
    "# ───────────── Sampler ─────────────\n",
    "def make_sampler(df):\n",
    "    cnt = df['label'].astype(str).str.lower().value_counts().reindex(LANGS,fill_value=0).to_dict()\n",
    "    w   = df['label'].astype(str).str.lower().map(lambda l:1.0/(cnt[l]+1e-6)).tolist()\n",
    "    return WeightedRandomSampler(w, num_samples=len(w), replacement=True)\n",
    "\n",
    "# ───────────── Train/Eval ausiliarie ─────────────\n",
    "def build_loaders(train_csv, val_csv, use_teacher=True):\n",
    "    df_tr = pd.read_csv(train_csv)\n",
    "    dl_tr = DataLoader(\n",
    "        MouthDS(train_csv, L, augment=True, use_teacher=use_teacher),\n",
    "        batch_size=BATCH_SIZE, sampler=make_sampler(df_tr),\n",
    "        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY\n",
    "    )\n",
    "    dl_va = DataLoader(\n",
    "        MouthDS(val_csv,   L, augment=False, use_teacher=False),\n",
    "        batch_size=BATCH_SIZE, shuffle=False,\n",
    "        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY\n",
    "    )\n",
    "    return dl_tr, dl_va\n",
    "\n",
    "def evaluate_manifest(csv_path, ckpt_path, title=\"\"):\n",
    "    model = Student().to(DEVICE)\n",
    "    state = torch.load(ckpt_path, map_location=DEVICE)\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    # freeze BN\n",
    "    for m in model.backbone.modules():\n",
    "        if isinstance(m, nn.BatchNorm3d):\n",
    "            m.eval(); m.weight.requires_grad_(False); m.bias.requires_grad_(False)\n",
    "    model.eval()\n",
    "\n",
    "    dl = DataLoader(\n",
    "        MouthDS(csv_path, L, augment=False, use_teacher=False),\n",
    "        batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=PIN_MEMORY\n",
    "    )\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for x,y in dl:\n",
    "            x = x.to(DEVICE); y = y.to(DEVICE)\n",
    "            logits, _, _ = model(x)\n",
    "            y_true += y.cpu().tolist()\n",
    "            y_pred += logits.argmax(1).cpu().tolist()\n",
    "\n",
    "    y_true = np.array(y_true); y_pred = np.array(y_pred)\n",
    "    all_labels = list(range(len(LANGS)))\n",
    "    acc = accuracy_score(y_true, y_pred) if len(y_true) else 0.0\n",
    "    mf1 = f1_score(y_true, y_pred, average=\"macro\") if len(y_true) else 0.0\n",
    "    cm  = confusion_matrix(y_true, y_pred, labels=all_labels) if len(y_true) else np.zeros((len(LANGS),len(LANGS)), dtype=int)\n",
    "\n",
    "    print(f\"\\n[{title}] N={len(y_true)}  Acc={acc:.3f}  Macro-F1={mf1:.3f}\")\n",
    "    print(pd.DataFrame(cm, index=LANGS, columns=LANGS))\n",
    "    return mf1, acc\n",
    "\n",
    "def split_emodb_L1_L2(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['label'] = df['label'].astype(str).str.lower()\n",
    "    l2 = df[df['label']=='en']      # English L2 (nel test EMODB)\n",
    "    l1 = df[df['label'].isin(['it','es'])]\n",
    "    p_all = csv_path\n",
    "    p_l1  = os.path.splitext(csv_path)[0] + \"__L1_it_es.csv\"\n",
    "    p_l2  = os.path.splitext(csv_path)[0] + \"__L2_en.csv\"\n",
    "    l1[['mouth_path','label']].to_csv(p_l1, index=False)\n",
    "    l2[['mouth_path','label']].to_csv(p_l2, index=False)\n",
    "    return p_all, p_l1, p_l2\n",
    "\n",
    "# ======== EN L1 (da BABELE train+val) vs EN L2 (da EMODB) ========\n",
    "def build_enL1_from_babele(train_csv, val_csv, out_csv=\"reports/EN_L1_from_BABELE.csv\"):\n",
    "    os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
    "    dft = pd.read_csv(train_csv)\n",
    "    dfv = pd.read_csv(val_csv)\n",
    "    df  = pd.concat([dft, dfv], ignore_index=True)\n",
    "    df  = df[df['label'].astype(str).str.lower()=='en'][['mouth_path','label']].reset_index(drop=True)\n",
    "    if len(df)==0:\n",
    "        raise ValueError(\"Nessuna riga 'en' trovata in BABELE train+val.\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    return out_csv\n",
    "\n",
    "def _collect_en_scores(csv_path, ckpt_path, run_dir=None, tag=\"\"):\n",
    "    \"\"\"Raccoglie p(en), margine e Acc(en) su un manifest (che dovrebbe contenere label=en).\"\"\"\n",
    "    model = Student().to(DEVICE)\n",
    "    state = torch.load(ckpt_path, map_location=DEVICE)\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    for m in model.backbone.modules():\n",
    "        if isinstance(m, nn.BatchNorm3d):\n",
    "            m.eval(); m.weight.requires_grad_(False); m.bias.requires_grad_(False)\n",
    "    model.eval()\n",
    "\n",
    "    dl = DataLoader(MouthDS(csv_path, L, augment=False, use_teacher=False),\n",
    "                    batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "    en_idx = LANGS.index('en')\n",
    "    probs, margins, preds, paths = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x,y in dl:\n",
    "            x = x.to(DEVICE)\n",
    "            logits,_,_ = model(x)\n",
    "            pr = F.softmax(logits,1)\n",
    "            p_en = pr[:, en_idx]\n",
    "            logit_en = logits[:, en_idx]\n",
    "            others = torch.stack([logits[:, LANGS.index('it')], logits[:, LANGS.index('es')]], dim=1)\n",
    "            margin = logit_en - others.max(dim=1).values\n",
    "            pred = pr.argmax(1)\n",
    "\n",
    "            probs.append(p_en.cpu().numpy())\n",
    "            margins.append(margin.cpu().numpy())\n",
    "            preds.extend((pred.cpu()==en_idx).tolist())\n",
    "            paths.extend(dl.dataset.df['mouth_path'].iloc[len(paths):len(paths)+len(p_en)].tolist())\n",
    "\n",
    "    probs = np.concatenate(probs) if probs else np.array([])\n",
    "    margins = np.concatenate(margins) if margins else np.array([])\n",
    "    acc_en = float(np.mean(preds)) if len(preds) else 0.0\n",
    "\n",
    "    if run_dir is not None:\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "        pd.DataFrame({'path':paths,'p_en':probs,'margin':margins,'pred_is_en':preds}).to_csv(\n",
    "            os.path.join(run_dir, f\"{tag}__per_sample.csv\"), index=False)\n",
    "\n",
    "    return dict(N=len(probs), acc_en=acc_en, p_en=probs, margin=margins)\n",
    "\n",
    "def eval_enL1_vs_enL2(enL1_csv, enL2_csv, ckpt_path, run_dir=None):\n",
    "    sL1 = _collect_en_scores(enL1_csv, ckpt_path, run_dir, tag=\"EN_L1\")\n",
    "    sL2 = _collect_en_scores(enL2_csv, ckpt_path, run_dir, tag=\"EN_L2\")\n",
    "    y  = np.concatenate([np.ones(sL1['N']), np.zeros(sL2['N'])]) if (sL1['N'] and sL2['N']) else np.array([0,1])\n",
    "    sp = np.concatenate([sL1['p_en'], sL2['p_en']]) if (sL1['N'] and sL2['N']) else np.array([0.5,0.5])\n",
    "    sm = np.concatenate([sL1['margin'], sL2['margin']]) if (sL1['N'] and sL2['N']) else np.array([0.0,0.0])\n",
    "    auc_p = roc_auc_score(y, sp) if len(np.unique(y))>1 else float('nan')\n",
    "    auc_m = roc_auc_score(y, sm) if len(np.unique(y))>1 else float('nan')\n",
    "\n",
    "    print(\"\\n=== EN L1 (BABELE train+val) vs EN L2 (EMODB) ===\")\n",
    "    print(f\"EN_L1: N={sL1['N']}  Acc(en)={sL1['acc_en']:.3f}  p(en) mean={np.mean(sL1['p_en']):.3f}  margin mean={np.mean(sL1['margin']):.3f}\")\n",
    "    print(f\"EN_L2: N={sL2['N']}  Acc(en)={sL2['acc_en']:.3f}  p(en) mean={np.mean(sL2['p_en']):.3f}  margin mean={np.mean(sL2['margin']):.3f}\")\n",
    "    print(f\"AUC p(en)={auc_p:.3f}   AUC margin={auc_m:.3f}\")\n",
    "\n",
    "    return {\n",
    "        'Acc_en_L1': sL1['acc_en'],\n",
    "        'Acc_en_L2': sL2['acc_en'],\n",
    "        'AUC_p_en': float(auc_p),\n",
    "        'AUC_margin': float(auc_m),\n",
    "        'N_en_L1': sL1['N'],\n",
    "        'N_en_L2': sL2['N'],\n",
    "        'p_en_mean_L1': float(np.mean(sL1['p_en'])) if sL1['N'] else float('nan'),\n",
    "        'p_en_mean_L2': float(np.mean(sL2['p_en'])) if sL2['N'] else float('nan'),\n",
    "        'margin_mean_L1': float(np.mean(sL1['margin'])) if sL1['N'] else float('nan'),\n",
    "        'margin_mean_L2': float(np.mean(sL2['margin'])) if sL2['N'] else float('nan'),\n",
    "    }\n",
    "\n",
    "# ───────────── Training di UNA RUN ─────────────\n",
    "def train_one_run(run_cfg):\n",
    "    \"\"\"\n",
    "    run_cfg: dict con\n",
    "      - run_id (str)\n",
    "      - emb_kd_on (bool)\n",
    "      - feature_kd_mode (\"clean\"|\"mix\")\n",
    "      - CONF_TH_EMB_PER (dict)\n",
    "      - LAMBDA_EMB_PER (dict)\n",
    "      - MU_EMB (float)\n",
    "      - EMB_LOSS_TYPE ('mse' | 'cos')\n",
    "      - USE_CONTRASTIVE (bool), MU_CONTR (float), TAU_INFO_NCE (float)\n",
    "    \"\"\"\n",
    "    RUN_ID         = run_cfg['run_id']\n",
    "    emb_kd_on      = run_cfg.get('emb_kd_on', True)\n",
    "    CONF_TH_PER    = run_cfg.get('CONF_TH_EMB_PER', CONF_TH_EMB_PER).copy()\n",
    "    lam_per        = run_cfg.get('LAMBDA_EMB_PER', LAMBDA_EMB_PER).copy()\n",
    "    MU             = run_cfg.get('MU_EMB', MU_EMB)\n",
    "    LOSS_TYP       = run_cfg.get('EMB_LOSS_TYPE', EMB_LOSS_TYPE)\n",
    "    feat_mode      = run_cfg.get('feature_kd_mode', FEATURE_KD_MODE)\n",
    "    use_contr      = run_cfg.get('USE_CONTRASTIVE', USE_CONTRASTIVE)\n",
    "    mu_contr       = run_cfg.get('MU_CONTR', MU_CONTR)\n",
    "    tau_contr      = run_cfg.get('TAU_INFO_NCE', TAU_INFO_NCE)\n",
    "\n",
    "    assert feat_mode in (\"clean\",\"mix\"), \"feature_kd_mode deve essere 'clean' o 'mix'\"\n",
    "\n",
    "    print(f\"\\n===== TRAIN {RUN_ID} | EMB_KD_ON={emb_kd_on}  mode={feat_mode}  conf={CONF_TH_PER}  λ={lam_per}  μ={MU}  loss={LOSS_TYP}  contrastive={use_contr} (μ={mu_contr}, τ={tau_contr}) =====\")\n",
    "\n",
    "    dl_tr, dl_va = build_loaders(TRAIN_CSV, VAL_CSV, use_teacher=True)\n",
    "    # prototipi audio per gating\n",
    "    protos, emb_dim = build_audio_prototypes(TRAIN_CSV)\n",
    "\n",
    "    model = Student().to(DEVICE)\n",
    "    # proiezione audio: d_a → d\n",
    "    proj_a = nn.Linear(emb_dim, PROJ_DIM).to(DEVICE)\n",
    "\n",
    "    # Freeze BatchNorm3d\n",
    "    for m in model.backbone.modules():\n",
    "        if isinstance(m, nn.BatchNorm3d):\n",
    "            m.eval(); m.weight.requires_grad_(False); m.bias.requires_grad_(False)\n",
    "\n",
    "    ema    = copy.deepcopy(model)\n",
    "    for p in ema.parameters(): p.requires_grad_(False)\n",
    "\n",
    "    opt    = AdamW(list(model.parameters()) + list(proj_a.parameters()), lr=LR, weight_decay=WD)\n",
    "    total  = EPOCHS * len(dl_tr)\n",
    "    sched  = OneCycleLR(opt, max_lr=MAX_LR, total_steps=total,\n",
    "                        pct_start=0.3, div_factor=DIV_FACTOR,\n",
    "                        final_div_factor=FINAL_DIV, anneal_strategy='cos')\n",
    "    crit   = SoftFocalLoss()\n",
    "\n",
    "    run_name = (\n",
    "        f\"{RUN_ID}__embkd{int(emb_kd_on)}__mode{feat_mode}__mu{MU:g}\"\n",
    "        f\"__th_en{CONF_TH_PER['en']:.3f}_it{CONF_TH_PER['it']:.3f}_es{CONF_TH_PER['es']:.3f}\"\n",
    "        f\"__lam_en{lam_per['en']:.3f}_it{lam_per['it']:.3f}_es{lam_per['es']:.3f}__loss{LOSS_TYP}\"\n",
    "        f\"__contr{int(use_contr)}\"\n",
    "    )\n",
    "    ckpt_dir = os.path.join(\"ckpts\", run_name)\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)\n",
    "    best_path = os.path.join(ckpt_dir, \"best.pt\")\n",
    "    last_path = os.path.join(ckpt_dir, \"last.pt\")\n",
    "\n",
    "    best_f1, patience = 0.0, 0\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train(); proj_a.train()\n",
    "\n",
    "        gate_cnt = {l: 0 for l in LANGS}\n",
    "        seen_cnt = {l: 0 for l in LANGS}\n",
    "\n",
    "        for batch in dl_tr:\n",
    "            # batch: (x, y, t_emb)\n",
    "            if isinstance(batch, (list, tuple)) and len(batch) == 3:\n",
    "                x_clean, y, t_emb = batch\n",
    "            else:\n",
    "                raise RuntimeError(\"Atteso batch (x,y,t_emb) in train con use_teacher=True.\")\n",
    "\n",
    "            x_clean = x_clean.to(DEVICE); y = y.to(DEVICE); t_emb = t_emb.to(DEVICE)\n",
    "\n",
    "            # supervised (mixup per la CE)\n",
    "            y_onehot = F.one_hot(y, len(LANGS)).float()\n",
    "            x_m, y_m, lam, idx = mixup_return_params(x_clean, y_onehot)\n",
    "\n",
    "            with torch.amp.autocast(device_type=DEVICE.type, enabled=AMP_ENABLED):\n",
    "                # 1) Supervised path: logits su input mixato\n",
    "                logits_m, _, z_v_m = model(x_m)\n",
    "                loss_sup = crit(logits_m, y_m)\n",
    "\n",
    "                # 2) EMBEDDING KD\n",
    "                loss_emb = torch.tensor(0.0, device=DEVICE)\n",
    "                loss_contr = torch.tensor(0.0, device=DEVICE)\n",
    "\n",
    "                if emb_kd_on:\n",
    "                    # Gating su ORIGINALI (per affidabilità del teacher)\n",
    "                    if PROTO_GATE and all(l in protos for l in LANGS):\n",
    "                        gate_orig, margin = gate_with_prototypes(t_emb, y, protos, CONF_TH_PER)\n",
    "                        for yi, gi in zip(y.tolist(), gate_orig.detach().cpu().tolist()):\n",
    "                            lang = IDX2LANG[int(yi)]\n",
    "                            seen_cnt[lang] += 1\n",
    "                            if gi >= 0.5:\n",
    "                                gate_cnt[lang] += 1\n",
    "                    else:\n",
    "                        gate_orig = torch.ones(x_clean.size(0), device=DEVICE)\n",
    "                        margin = torch.zeros(x_clean.size(0), device=DEVICE)\n",
    "\n",
    "                    # Proiezione audio\n",
    "                    z_a_clean = proj_a(t_emb)  # [B,d]\n",
    "\n",
    "                    if feat_mode == \"clean\":\n",
    "                        # KD su INPUT NON MIXATO (nessun mismatch)\n",
    "                        _, _, z_v_clean = model(x_clean)\n",
    "                        loss_per = emb_loss(z_v_clean, z_a_clean, typ=LOSS_TYP)  # [B]\n",
    "\n",
    "                        # pesi per-classe (hard) e gate (hard)\n",
    "                        lam_vec = torch.tensor(\n",
    "                            [lam_per[IDX2LANG[int(yi)]] for yi in y.tolist()],\n",
    "                            device=DEVICE, dtype=torch.float32\n",
    "                        )\n",
    "                        emb_w = lam_vec * gate_orig\n",
    "                        if emb_w.sum() > 0:\n",
    "                            loss_emb = (loss_per * emb_w).sum() / emb_w.sum()\n",
    "\n",
    "                        # opzionale contrastive in-batch su clean\n",
    "                        if use_contr:\n",
    "                            loss_contr_raw = info_nce_loss(z_v_clean, z_a_clean, tau=tau_contr)\n",
    "                            # pesatura con gate medio (stesso valore per batch, ma mascheriamo se 0)\n",
    "                            gmean = gate_orig.mean()\n",
    "                            if gmean > 0:\n",
    "                                loss_contr = loss_contr_raw * gmean\n",
    "\n",
    "                    else:  # feat_mode == \"mix\"\n",
    "                        # Mix anche l'embedding audio e i pesi/gate\n",
    "                        t_emb_mix = lam * t_emb + (1-lam) * t_emb[idx]\n",
    "                        z_a_mix   = proj_a(t_emb_mix)\n",
    "\n",
    "                        # pesa per-classe mixata: λ*λ(y) + (1-λ)*λ(y[idx])\n",
    "                        lam_vec_hard = torch.tensor([lam_per[IDX2LANG[int(yi)]] for yi in y.tolist()],\n",
    "                                                    device=DEVICE, dtype=torch.float32)\n",
    "                        lam_vec_mix = lam*lam_vec_hard + (1-lam)*lam_vec_hard[idx]\n",
    "\n",
    "                        # gate mixato: λ*g + (1-λ)*g[idx]\n",
    "                        gate_mix = lam*gate_orig + (1-lam)*gate_orig[idx]\n",
    "\n",
    "                        loss_per = emb_loss(z_v_m, z_a_mix, typ=LOSS_TYP)  # [B]\n",
    "                        emb_w = lam_vec_mix * gate_mix\n",
    "                        if emb_w.sum() > 0:\n",
    "                            loss_emb = (loss_per * emb_w).sum() / emb_w.sum()\n",
    "\n",
    "                        if use_contr:\n",
    "                            loss_contr_raw = info_nce_loss(z_v_m, z_a_mix, tau=tau_contr)\n",
    "                            gmean = gate_mix.mean()\n",
    "                            if gmean > 0:\n",
    "                                loss_contr = loss_contr_raw * gmean\n",
    "\n",
    "                loss = loss_sup + MU * loss_emb + (mu_contr * loss_contr if use_contr else 0.0)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(list(model.parameters())+list(proj_a.parameters()), 5.0)\n",
    "            opt.step(); opt.zero_grad()\n",
    "            sched.step()\n",
    "\n",
    "            # EMA (solo dello student; qui non la usiamo in eval)\n",
    "            with torch.no_grad():\n",
    "                for m,e in zip(model.parameters(), ema.parameters()):\n",
    "                    e.mul_(0.999).add_(m, alpha=0.001)\n",
    "\n",
    "        # ── Validation in-domain ───────────────────────────\n",
    "        model.eval()\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for x,y in DataLoader(MouthDS(VAL_CSV, L, augment=False, use_teacher=False),\n",
    "                                  batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=PIN_MEMORY):\n",
    "                x = x.to(DEVICE); y = y.to(DEVICE)\n",
    "                logits,_,_ = model(x)\n",
    "                preds += logits.argmax(1).cpu().tolist()\n",
    "                gts   += y.cpu().tolist()\n",
    "        f1 = macro_f1(gts, preds)\n",
    "        cm = confusion_matrix(gts, preds, labels=list(range(len(LANGS))))\n",
    "        print(f\"Epoch {ep:02d}  Val-F1={f1:.3f}\")\n",
    "        print(pd.DataFrame(cm, index=LANGS, columns=LANGS))\n",
    "\n",
    "        # stampa gate per-classe\n",
    "        total_seen = sum(seen_cnt.values())\n",
    "        total_gated= sum(gate_cnt.values())\n",
    "        rates = {l: (gate_cnt[l] / max(1, seen_cnt[l])) for l in LANGS}\n",
    "        print(f\"[EMB-KD] gate_rate_total={ (total_gated/max(1,total_seen))*100:.2f}%  by_lang={rates}\")\n",
    "\n",
    "        # anti-dominanza su 'en' (adatta soglia e peso)\n",
    "        en_r = rates.get('en', 0.0); others = [r for l,r in rates.items() if l!='en']\n",
    "        mean_others = sum(others)/max(1, len(others))\n",
    "        if emb_kd_on and en_r > 2.0*max(1e-6, mean_others) + 0.05:\n",
    "            old_th  = CONF_TH_PER['en']\n",
    "            old_lam = lam_per['en']\n",
    "            CONF_TH_PER['en']  = min(0.50, CONF_TH_PER['en'] + 0.02)   # soglie di margin tipicamente <= 0.5\n",
    "            lam_per['en']      = max(0.2*old_lam, old_lam*0.8)\n",
    "            print(f\"[EMB-KD][anti-dom] en troppo dominante → th_en {old_th:.3f}->{CONF_TH_PER['en']:.3f}, λ_en {old_lam:.4f}->{lam_per['en']:.4f}\")\n",
    "\n",
    "        # early stopping + save\n",
    "        if f1>best_f1:\n",
    "            best_f1, patience = f1, 0\n",
    "            torch.save(model.state_dict(), best_path)   # salvo SOLO lo student (evaluation invariata)\n",
    "            print(f\"  → New best: Val-F1={f1:.3f}  saved: {best_path}\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= PATIENCE:\n",
    "                print(\"Early stopping\"); break\n",
    "\n",
    "    torch.save(model.state_dict(), last_path)\n",
    "    print(f\"Best Val-F1 (VAL) = {best_f1:.3f}\")\n",
    "    return best_path, run_name\n",
    "\n",
    "# ───────────── RUN SUITE + REPORT ─────────────\n",
    "def run_suite():\n",
    "    # esperimenti (baseline + EMB-KD; includo sia mode='clean' che 'mix' per confronto)\n",
    "    EXPERIMENTS = [\n",
    "        dict(run_id=\"E0_baseline\",\n",
    "            emb_kd_on=False,\n",
    "            feature_kd_mode=\"clean\",\n",
    "            CONF_TH_EMB_PER={'en':0.05,'it':0.05,'es':0.05},\n",
    "            LAMBDA_EMB_PER={'en':0.00,'it':0.00,'es':0.00},\n",
    "            MU_EMB=0.0, EMB_LOSS_TYPE='mse',\n",
    "            USE_CONTRASTIVE=False),\n",
    "\n",
    "        dict(run_id=\"E1_EMB_KD_clean_bal\",\n",
    "            emb_kd_on=True,\n",
    "            feature_kd_mode=\"clean\",\n",
    "            CONF_TH_EMB_PER={'en':0.05,'it':0.05,'es':0.05},\n",
    "            LAMBDA_EMB_PER={'en':0.012,'it':0.05,'es':0.05},\n",
    "            MU_EMB=0.15, EMB_LOSS_TYPE='mse',\n",
    "            USE_CONTRASTIVE=False),\n",
    "\n",
    "        dict(run_id=\"E2_EMB_KD_mix_bal\",\n",
    "            emb_kd_on=True,\n",
    "            feature_kd_mode=\"mix\",\n",
    "            CONF_TH_EMB_PER={'en':0.05,'it':0.05,'es':0.05},\n",
    "            LAMBDA_EMB_PER={'en':0.012,'it':0.05,'es':0.05},\n",
    "            MU_EMB=0.15, EMB_LOSS_TYPE='mse',\n",
    "            USE_CONTRASTIVE=False),\n",
    "\n",
    "        dict(run_id=\"E3_EMB_KD_clean_contr\",\n",
    "            emb_kd_on=True,\n",
    "            feature_kd_mode=\"clean\",\n",
    "            CONF_TH_EMB_PER={'en':0.06,'it':0.05,'es':0.05},\n",
    "            LAMBDA_EMB_PER={'en':0.011,'it':0.05,'es':0.05},\n",
    "            MU_EMB=0.14, EMB_LOSS_TYPE='cos',\n",
    "            USE_CONTRASTIVE=True, MU_CONTR=0.05, TAU_INFO_NCE=0.07),\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Pre-split EMODB L1/L2 e costruzione EN_L1 (TRAIN+VAL)\n",
    "    emodb_all, emodb_L1, emodb_L2 = split_emodb_L1_L2(CROSS_CSV)\n",
    "    enL1_csv = build_enL1_from_babele(TRAIN_CSV, VAL_CSV, out_csv=\"reports/EN_L1_from_BABELE.csv\")\n",
    "\n",
    "    for cfg in EXPERIMENTS:\n",
    "        best_ckpt, run_name = train_one_run(cfg)\n",
    "\n",
    "        # Eval IN-domain (VAL)\n",
    "        f1_in, acc_in = evaluate_manifest(VAL_CSV, best_ckpt, title=f\"{cfg['run_id']}__IN_VAL\")\n",
    "\n",
    "        # Eval CROSS EMODB (all, L1, L2)\n",
    "        f1_x_all, acc_x_all = evaluate_manifest(emodb_all, best_ckpt, title=f\"{cfg['run_id']}__CROSS_EMODB_all\")\n",
    "        f1_x_L1,  acc_x_L1  = evaluate_manifest(emodb_L1,  best_ckpt, title=f\"{cfg['run_id']}__CROSS_EMODB_L1_it_es\")\n",
    "        f1_x_L2,  acc_x_L2  = evaluate_manifest(emodb_L2,  best_ckpt, title=f\"{cfg['run_id']}__CROSS_EMODB_L2_en\")\n",
    "\n",
    "        # EN L1 (TRAIN+VAL) vs EN L2 (EMODB)\n",
    "        run_dir = os.path.join(\"reports\", run_name)\n",
    "        en_stats = eval_enL1_vs_enL2(enL1_csv, emodb_L2, best_ckpt, run_dir=run_dir)\n",
    "\n",
    "        results.append({\n",
    "            \"run\": cfg['run_id'],\n",
    "            \"EMB_KD_ON\": cfg['emb_kd_on'],\n",
    "            \"mode\": cfg['feature_kd_mode'],\n",
    "            \"conf_th_emb_en\": cfg['CONF_TH_EMB_PER']['en'],\n",
    "            \"conf_th_emb_it\": cfg['CONF_TH_EMB_PER']['it'],\n",
    "            \"conf_th_emb_es\": cfg['CONF_TH_EMB_PER']['es'],\n",
    "            \"lambda_emb_en\": cfg['LAMBDA_EMB_PER']['en'],\n",
    "            \"lambda_emb_it\": cfg['LAMBDA_EMB_PER']['it'],\n",
    "            \"lambda_emb_es\": cfg['LAMBDA_EMB_PER']['es'],\n",
    "            \"MU_EMB\": cfg['MU_EMB'],\n",
    "            \"EMB_LOSS\": cfg['EMB_LOSS_TYPE'],\n",
    "            \"contrastive\": int(cfg.get('USE_CONTRASTIVE', False)),\n",
    "            \"F1_in\":  float(f1_in),\n",
    "            \"F1_x_all\": float(f1_x_all),\n",
    "            \"F1_x_L1\": float(f1_x_L1),\n",
    "            \"F1_x_L2\": float(f1_x_L2),\n",
    "\n",
    "            # EN L1 vs L2\n",
    "            \"Acc_en_L1\": en_stats['Acc_en_L1'],\n",
    "            \"Acc_en_L2\": en_stats['Acc_en_L2'],\n",
    "            \"AUC_p_en\":  en_stats['AUC_p_en'],\n",
    "            \"AUC_margin\": en_stats['AUC_margin'],\n",
    "            \"N_en_L1\": en_stats['N_en_L1'],\n",
    "            \"N_en_L2\": en_stats['N_en_L2'],\n",
    "        })\n",
    "\n",
    "    # Riepilogo e delta vs baseline\n",
    "    df = pd.DataFrame(results)\n",
    "    base = df.iloc[0]\n",
    "    df[\"ΔF1_in_vs_baseline\"]   = df[\"F1_in\"]    - base[\"F1_in\"]\n",
    "    df[\"ΔF1_x_vs_baseline\"]    = df[\"F1_x_all\"] - base[\"F1_x_all\"]\n",
    "    df[\"ΔAcc_en_L1_vs_base\"]   = df[\"Acc_en_L1\"] - base[\"Acc_en_L1\"]\n",
    "    df[\"ΔAcc_en_L2_vs_base\"]   = df[\"Acc_en_L2\"] - base[\"Acc_en_L2\"]\n",
    "    print(\"\\n================ ALL RUNS SUMMARY ================\")\n",
    "    print(df.to_string(index=False))\n",
    "    os.makedirs(\"reports\", exist_ok=True)\n",
    "    df.to_csv(\"reports/emb_kd_feature_strict_summary.csv\", index=False)\n",
    "    print(\"\\nSaved: reports/emb_kd_feature_strict_summary.csv\")\n",
    "\n",
    "# ───────────── MAIN ─────────────\n",
    "if __name__ == \"__main__\":\n",
    "    run_suite()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19abedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Runner EMB-KD (strumentato) — r3d_18 + SpecAug3D + MixUp + MixStyle\n",
    "Novità:\n",
    "  • Logging per-epoca di loss_sup_mean, loss_emb_mean, gate_rate e cosine(z_v,z_a)\n",
    "  • Soft-gate opzionale con temperatura (pesi continui invece di gate {0,1})\n",
    "  • Salvataggio anche del proj_a (per valutare allineamento a posteriori)\n",
    "  • Suite di esperimenti: baseline, KD forzata, intermedia, rigorosa, controllo MU=0\n",
    "\"\"\"\n",
    "\n",
    "import os, json, random, copy, math\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.video import r3d_18, R3D_18_Weights\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "# ───────────── Config base ─────────────\n",
    "SEED = 42\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 8\n",
    "LR, WD = 3e-4, 1e-3\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "LANGS = ['en','it','es']\n",
    "OUT_H, OUT_W, L = 64, 64, 32\n",
    "MIXUP_ALPHA = 0.30\n",
    "PATIENCE = 7\n",
    "MAX_LR = 3e-4\n",
    "DIV_FACTOR = 10\n",
    "FINAL_DIV = 100\n",
    "\n",
    "# Datasets\n",
    "TRAIN_CSV = \"BABELE/manifest_train.csv\"\n",
    "VAL_CSV   = \"BABELE/manifest_test.csv\"\n",
    "CROSS_CSV = \"EMODB/manifest_test.csv\"\n",
    "\n",
    "# Device & AMP\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "AMP_ENABLED = (DEVICE.type == 'cuda')\n",
    "PIN_MEMORY = (DEVICE.type == 'cuda')\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ───────────── EMB-KD config (default) ─────────────\n",
    "PROJ_DIM = 128                 # dimensione spazio comune audio/video\n",
    "EMB_LOSS_TYPE = 'mse'          # 'mse' | 'cos'\n",
    "MU_EMB = 0.15                  # peso della loss di embedding\n",
    "PROTO_GATE = True              # abilita gating basato su prototipi audio\n",
    "CONF_TH_EMB_PER = {'en': 0.05, 'it': 0.05, 'es': 0.05}\n",
    "LAMBDA_EMB_PER = {'en': 0.012, 'it': 0.05, 'es': 0.05}\n",
    "\n",
    "# Contrastive opzionale (InfoNCE)\n",
    "USE_CONTRASTIVE = False\n",
    "MU_CONTR = 0.05\n",
    "TAU_INFO_NCE = 0.07\n",
    "\n",
    "# Modalità KD feature\n",
    "FEATURE_KD_MODE = \"clean\"     # \"clean\" | \"mix\"\n",
    "\n",
    "# Soft-gate opzionale\n",
    "SOFT_GATE = False\n",
    "SOFT_TEMP = 0.05  # più piccolo => più \"duro\"\n",
    "\n",
    "# ───────────── Metriche ─────────────\n",
    "def macro_f1(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true, y_pred,\n",
    "                                           average='macro', zero_division=0)[2]\n",
    "\n",
    "# ───────────── Augmentazioni ─────────────\n",
    "class SpecAug3D:\n",
    "    def __init__(self, H, W, T_mask=4, S_mask=4):\n",
    "        self.tf = T.Compose([\n",
    "            T.ToPILImage(),\n",
    "            T.RandomResizedCrop((H,W), scale=(0.95,1.0), ratio=(1.0,1.0)),\n",
    "            T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),\n",
    "            T.RandomHorizontalFlip(0.5),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "        self.T_mask, self.S_mask = T_mask, S_mask\n",
    "    def __call__(self, vid):\n",
    "        frames = []\n",
    "        for f in vid:\n",
    "            img = (f*255).byte()\n",
    "            t   = self.tf(img).squeeze(0)\n",
    "            frames.append(t)\n",
    "        vid = torch.stack(frames)\n",
    "        L_,H,W = vid.shape\n",
    "        if L_ > self.T_mask:\n",
    "            t0 = random.randrange(0, L_-self.T_mask+1)\n",
    "            vid[t0:t0+self.T_mask] = 0\n",
    "        if H>self.S_mask and W>self.S_mask:\n",
    "            fi = random.randrange(0, L_)\n",
    "            h0 = random.randrange(0, H-self.S_mask+1)\n",
    "            w0 = random.randrange(0, W-self.S_mask+1)\n",
    "            vid[fi,h0:h0+self.S_mask,w0:w0+self.S_mask] = 0\n",
    "        return vid\n",
    "\n",
    "class RandomErasing3D:\n",
    "    def __init__(self, p=0.3, size=(8,8,8)):\n",
    "        self.p = p; self.d, self.h, self.w = size\n",
    "    def __call__(self, vid):\n",
    "        if random.random()>self.p: return vid\n",
    "        L_,H,W = vid.shape\n",
    "        sd = random.randint(0, max(0, L_-self.d))\n",
    "        sh = random.randint(0, max(0, H-self.h))\n",
    "        sw = random.randint(0, max(0, W-self.w))\n",
    "        vid[sd:sd+self.d, sh:sh+self.h, sw:sw+self.w] = 0\n",
    "        return vid\n",
    "\n",
    "def mixup_return_params(x, y_onehot, alpha=MIXUP_ALPHA):\n",
    "    if alpha <= 0:\n",
    "        B = x.size(0); idx = torch.arange(B, device=x.device); lam = 1.0\n",
    "        return x, y_onehot, lam, idx\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    idx = torch.randperm(x.size(0), device=x.device)\n",
    "    x_m = lam*x + (1-lam)*x[idx]\n",
    "    y_m = lam*y_onehot + (1-lam)*y_onehot[idx]\n",
    "    return x_m, y_m, float(lam), idx\n",
    "\n",
    "# ───────────── Loss ─────────────\n",
    "class SoftFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__(); self.alpha, self.gamma = alpha, gamma\n",
    "    def forward(self, logits, y_soft):\n",
    "        logp = F.log_softmax(logits,1)\n",
    "        p    = logp.exp()\n",
    "        ce   = -(y_soft * logp).sum(1)\n",
    "        pt   = (y_soft * p).sum(1)\n",
    "        return ( self.alpha * (1-pt)**self.gamma * ce ).mean()\n",
    "\n",
    "def emb_loss(z_v, z_a, typ='mse'):\n",
    "    if typ == 'mse':\n",
    "        return F.mse_loss(z_v, z_a, reduction='none').mean(dim=1)  # [B]\n",
    "    elif typ == 'cos':\n",
    "        z_v = F.normalize(z_v, dim=1)\n",
    "        z_a = F.normalize(z_a, dim=1)\n",
    "        return (1 - (z_v * z_a).sum(dim=1))  # [B]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown EMB_LOSS_TYPE: {typ}\")\n",
    "\n",
    "def info_nce_loss(z_v, z_a, tau=0.07):\n",
    "    z_vn = F.normalize(z_v, dim=1)\n",
    "    z_an = F.normalize(z_a, dim=1)\n",
    "    logits_v2a = torch.matmul(z_vn, z_an.t()) / tau\n",
    "    logits_a2v = torch.matmul(z_an, z_vn.t()) / tau\n",
    "    labels = torch.arange(z_v.size(0), device=z_v.device)\n",
    "    loss1 = F.cross_entropy(logits_v2a, labels)\n",
    "    loss2 = F.cross_entropy(logits_a2v, labels)\n",
    "    return 0.5*(loss1 + loss2)\n",
    "\n",
    "# ───────────── MixStyle ─────────────\n",
    "class MixStyle(nn.Module):\n",
    "    def __init__(self, p=0.3, α=0.1):\n",
    "        super().__init__(); self.p, self.α = p, α\n",
    "    def forward(self, x):\n",
    "        if not self.training or random.random()>self.p:\n",
    "            return x\n",
    "        B,C = x.shape\n",
    "        mu  = x.mean(1,keepdim=True)\n",
    "        sig = (x.var(1,keepdim=True)+1e-6).sqrt()\n",
    "        lm  = np.random.beta(self.α, self.α)\n",
    "        perm= torch.randperm(B,device=x.device)\n",
    "        mu2, sig2 = mu[perm], sig[perm]\n",
    "        x_norm = (x-mu)/sig\n",
    "        return x_norm*(lm*sig + (1-lm)*sig2) + (lm*mu + (1-lm)*mu2)\n",
    "\n",
    "# ───────────── Dataset ─────────────\n",
    "AUDIO_EMB_CANDIDATES = ['feats_path']  # colonna con path embedding audio (Teacher)\n",
    "\n",
    "class MouthDS(Dataset):\n",
    "    def __init__(self,csv,L=32,augment=False,use_teacher=False):\n",
    "        df = pd.read_csv(csv).query('mouth_path.notna()').reset_index(drop=True)\n",
    "        self.df, self.L = df, L\n",
    "        self.l2i         = {l:i for i,l in enumerate(LANGS)}\n",
    "        self.spec        = SpecAug3D(OUT_H,OUT_W) if augment else None\n",
    "        self.randomerase = RandomErasing3D()      if augment else None\n",
    "        self.use_teacher = use_teacher\n",
    "        self.audio_col = None\n",
    "        for c in AUDIO_EMB_CANDIDATES:\n",
    "            if c in self.df.columns:\n",
    "                self.audio_col = c; break\n",
    "        if self.use_teacher and self.audio_col is None:\n",
    "            raise ValueError(f\"Nessuna colonna embedding audio trovata. Attese una tra: {AUDIO_EMB_CANDIDATES}.\")\n",
    "\n",
    "    def _align(self,a):\n",
    "        T0 = a.shape[0]\n",
    "        if T0>=self.L: idx = np.linspace(0,T0-1,self.L).astype(int)\n",
    "        else:          idx = np.concatenate([np.arange(T0), np.full(self.L-T0, T0-1)])\n",
    "        return a[idx]\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        r = self.df.iloc[i]\n",
    "        a = np.load(r.mouth_path,allow_pickle=True).astype('float32')/255.\n",
    "        if a.ndim==4 and a.shape[-1]==3: a = a.mean(-1)\n",
    "        a = self._align(a)\n",
    "        v = torch.from_numpy(a)  # [T,H,W] float32 in [0,1]\n",
    "        if self.spec:        v = self.spec(v)\n",
    "        if self.randomerase: v = self.randomerase(v)\n",
    "        v3 = v.unsqueeze(0).unsqueeze(0)  # [1,1,T,H,W]\n",
    "        v3 = F.interpolate(v3, size=(L,OUT_H,OUT_W), mode='trilinear', align_corners=False).squeeze(0)\n",
    "        x  = (v3 - 0.5)/0.5  # [-1,1]\n",
    "        y  = torch.tensor(self.l2i[str(r.label).lower()],dtype=torch.long)\n",
    "\n",
    "        if not self.use_teacher: return x, y\n",
    "\n",
    "        path_emb = str(r[self.audio_col])\n",
    "        if not (isinstance(path_emb, str) and os.path.exists(path_emb)):\n",
    "            raise FileNotFoundError(f\"Embedding audio mancante o path non valido: {path_emb}\")\n",
    "        z_a = np.load(path_emb, allow_pickle=True).astype('float32')\n",
    "        z_a = np.squeeze(z_a)\n",
    "        if z_a.ndim != 1:\n",
    "            z_a = z_a.reshape(-1, z_a.shape[-1]).mean(axis=0).astype('float32')\n",
    "        t_emb = torch.from_numpy(z_a)  # [d_a]\n",
    "        return x, y, t_emb\n",
    "\n",
    "# ───────────── Model ─────────────\n",
    "class Student(nn.Module):\n",
    "    def __init__(self, proj_dim=PROJ_DIM):\n",
    "        super().__init__()\n",
    "        self.backbone = r3d_18(weights=R3D_18_Weights.DEFAULT)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.mixstyle   = MixStyle(p=0.3, α=0.1)\n",
    "        self.proj_v     = nn.Sequential(nn.LayerNorm(512), nn.Linear(512, proj_dim))\n",
    "        self.head       = nn.Sequential(nn.LayerNorm(512), nn.Linear(512,256), nn.GELU(), nn.Dropout(0.1),\n",
    "                                        nn.Linear(256,len(LANGS)))\n",
    "    def forward(self, x):\n",
    "        x = x.repeat(1,3,1,1,1)\n",
    "        f = self.backbone(x)      # [B,512]\n",
    "        f = self.mixstyle(f)\n",
    "        logits = self.head(f)\n",
    "        z_v = self.proj_v(f)      # [B,d]\n",
    "        return logits, f, z_v\n",
    "\n",
    "# ───────────── Helpers EMB-KD ─────────────\n",
    "IDX2LANG = {i:l for i,l in enumerate(LANGS)}\n",
    "\n",
    "def build_audio_prototypes(train_csv):\n",
    "    df = pd.read_csv(train_csv).query('mouth_path.notna()')\n",
    "    audio_col = None\n",
    "    for c in AUDIO_EMB_CANDIDATES:\n",
    "        if c in df.columns: audio_col = c; break\n",
    "    if audio_col is None: raise ValueError(f\"Colonna embedding audio non trovata in {train_csv}.\")\n",
    "    acc = {l: [] for l in LANGS}\n",
    "    for _,r in df.iterrows():\n",
    "        lp = str(r['label']).lower()\n",
    "        if lp not in acc: continue\n",
    "        p = str(r[audio_col])\n",
    "        if not (isinstance(p,str) and os.path.exists(p)): continue\n",
    "        z = np.load(p, allow_pickle=True).astype('float32'); z = np.squeeze(z)\n",
    "        if z.ndim != 1: z = z.reshape(-1, z.shape[-1]).mean(axis=0).astype('float32')\n",
    "        acc[lp].append(z)\n",
    "    protos = {}; d_a = None\n",
    "    for l, vecs in acc.items():\n",
    "        if len(vecs)==0: continue\n",
    "        M = np.stack(vecs, axis=0).mean(axis=0).astype('float32')\n",
    "        d_a = M.shape[0]; protos[l] = torch.tensor(M, dtype=torch.float32)\n",
    "    if len(protos)==0: raise ValueError(\"Impossibile costruire prototipi audio: nessun embedding letto.\")\n",
    "    return protos, d_a\n",
    "\n",
    "def gate_with_prototypes(t_emb, y, protos, conf_th_emb_per, soft=False, temp=0.05):\n",
    "    B = t_emb.size(0); langs = LANGS\n",
    "    P = torch.stack([protos[l].to(t_emb.device) for l in langs], dim=0)  # [K,d_a]\n",
    "    z = F.normalize(t_emb, dim=1); Pn = F.normalize(P, dim=1)\n",
    "    sim = torch.matmul(z, Pn.t())  # [B,K]\n",
    "    true_sim = sim[torch.arange(B, device=z.device), y]\n",
    "    sim_clone = sim.clone(); sim_clone[torch.arange(B, device=z.device), y] = -1e9\n",
    "    max_other = sim_clone.max(dim=1).values\n",
    "    margin = true_sim - max_other  # [B]\n",
    "    th_vec = torch.tensor([conf_th_emb_per[IDX2LANG[int(yi)]] for yi in y.tolist()],\n",
    "                          device=z.device, dtype=torch.float32)\n",
    "    if not soft:\n",
    "        gate = (margin >= th_vec).float()\n",
    "    else:\n",
    "        gate = torch.sigmoid( (margin - th_vec) / max(1e-6, temp) )  # [0,1]\n",
    "    return gate, margin\n",
    "\n",
    "# ───────────── Sampler ─────────────\n",
    "def make_sampler(df):\n",
    "    cnt = df['label'].astype(str).str.lower().value_counts().reindex(LANGS,fill_value=0).to_dict()\n",
    "    w   = df['label'].astype(str).str.lower().map(lambda l:1.0/(cnt[l]+1e-6)).tolist()\n",
    "    return WeightedRandomSampler(w, num_samples=len(w), replacement=True)\n",
    "\n",
    "# ───────────── Train/Eval ausiliarie ─────────────\n",
    "def build_loaders(train_csv, val_csv, use_teacher=True):\n",
    "    df_tr = pd.read_csv(train_csv)\n",
    "    dl_tr = DataLoader(MouthDS(train_csv, L, augment=True,  use_teacher=use_teacher),\n",
    "                       batch_size=BATCH_SIZE, sampler=make_sampler(df_tr),\n",
    "                       num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "    dl_va = DataLoader(MouthDS(val_csv,   L, augment=False, use_teacher=False),\n",
    "                       batch_size=BATCH_SIZE, shuffle=False,\n",
    "                       num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "    return dl_tr, dl_va\n",
    "\n",
    "def evaluate_manifest(csv_path, ckpt_path, title=\"\"):\n",
    "    model = Student().to(DEVICE)\n",
    "    state = torch.load(ckpt_path, map_location=DEVICE)\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    for m in model.backbone.modules():\n",
    "        if isinstance(m, nn.BatchNorm3d):\n",
    "            m.eval(); m.weight.requires_grad_(False); m.bias.requires_grad_(False)\n",
    "    model.eval()\n",
    "\n",
    "    dl = DataLoader(MouthDS(csv_path, L, augment=False, use_teacher=False),\n",
    "                    batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=PIN_MEMORY)\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for x,y in dl:\n",
    "            x = x.to(DEVICE); y = y.to(DEVICE)\n",
    "            logits, _, _ = model(x)\n",
    "            y_true += y.cpu().tolist()\n",
    "            y_pred += logits.argmax(1).cpu().tolist()\n",
    "    y_true = np.array(y_true); y_pred = np.array(y_pred)\n",
    "    all_labels = list(range(len(LANGS)))\n",
    "    acc = accuracy_score(y_true, y_pred) if len(y_true) else 0.0\n",
    "    mf1 = f1_score(y_true, y_pred, average=\"macro\") if len(y_true) else 0.0\n",
    "    cm  = confusion_matrix(y_true, y_pred, labels=all_labels) if len(y_true) else np.zeros((len(LANGS),len(LANGS)), dtype=int)\n",
    "    print(f\"\\n[{title}] N={len(y_true)}  Acc={acc:.3f}  Macro-F1={mf1:.3f}\")\n",
    "    print(pd.DataFrame(cm, index=LANGS, columns=LANGS))\n",
    "    return mf1, acc\n",
    "\n",
    "def split_emodb_L1_L2(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['label'] = df['label'].astype(str).str.lower()\n",
    "    l2 = df[df['label']=='en']\n",
    "    l1 = df[df['label'].isin(['it','es'])]\n",
    "    p_all = csv_path\n",
    "    p_l1  = os.path.splitext(csv_path)[0] + \"__L1_it_es.csv\"\n",
    "    p_l2  = os.path.splitext(csv_path)[0] + \"__L2_en.csv\"\n",
    "    l1[['mouth_path','label']].to_csv(p_l1, index=False)\n",
    "    l2[['mouth_path','label']].to_csv(p_l2, index=False)\n",
    "    return p_all, p_l1, p_l2\n",
    "\n",
    "def build_enL1_from_babele(train_csv, val_csv, out_csv=\"reports/EN_L1_from_BABELE.csv\"):\n",
    "    os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
    "    dft = pd.read_csv(train_csv); dfv = pd.read_csv(val_csv)\n",
    "    df  = pd.concat([dft, dfv], ignore_index=True)\n",
    "    df  = df[df['label'].astype(str).str.lower()=='en'][['mouth_path','label']].reset_index(drop=True)\n",
    "    if len(df)==0: raise ValueError(\"Nessuna riga 'en' trovata in BABELE train+val.\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    return out_csv\n",
    "\n",
    "def _collect_en_scores(csv_path, ckpt_path, run_dir=None, tag=\"\"):\n",
    "    model = Student().to(DEVICE)\n",
    "    state = torch.load(ckpt_path, map_location=DEVICE)\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    for m in model.backbone.modules():\n",
    "        if isinstance(m, nn.BatchNorm3d):\n",
    "            m.eval(); m.weight.requires_grad_(False); m.bias.requires_grad_(False)\n",
    "    model.eval()\n",
    "\n",
    "    dl = DataLoader(MouthDS(csv_path, L, augment=False, use_teacher=False),\n",
    "                    batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=PIN_MEMORY)\n",
    "    en_idx = LANGS.index('en')\n",
    "    probs, margins, preds, paths = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x,y in dl:\n",
    "            x = x.to(DEVICE)\n",
    "            logits,_,_ = model(x)\n",
    "            pr = F.softmax(logits,1)\n",
    "            p_en = pr[:, en_idx]\n",
    "            logit_en = logits[:, en_idx]\n",
    "            others = torch.stack([logits[:, LANGS.index('it')], logits[:, LANGS.index('es')]], dim=1)\n",
    "            margin = logit_en - others.max(dim=1).values\n",
    "            pred = pr.argmax(1)\n",
    "            probs.append(p_en.cpu().numpy()); margins.append(margin.cpu().numpy())\n",
    "            preds.extend((pred.cpu()==en_idx).tolist())\n",
    "            paths.extend(dl.dataset.df['mouth_path'].iloc[len(paths):len(paths)+len(p_en)].tolist())\n",
    "    probs = np.concatenate(probs) if probs else np.array([])\n",
    "    margins = np.concatenate(margins) if margins else np.array([])\n",
    "    acc_en = float(np.mean(preds)) if len(preds) else 0.0\n",
    "    if run_dir is not None:\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "        pd.DataFrame({'path':paths,'p_en':probs,'margin':margins,'pred_is_en':preds}).to_csv(\n",
    "            os.path.join(run_dir, f\"{tag}__per_sample.csv\"), index=False)\n",
    "    return dict(N=len(probs), acc_en=acc_en, p_en=probs, margin=margins)\n",
    "\n",
    "def eval_enL1_vs_enL2(enL1_csv, enL2_csv, ckpt_path, run_dir=None):\n",
    "    sL1 = _collect_en_scores(enL1_csv, ckpt_path, run_dir, tag=\"EN_L1\")\n",
    "    sL2 = _collect_en_scores(enL2_csv, ckpt_path, run_dir, tag=\"EN_L2\")\n",
    "    y  = np.concatenate([np.ones(sL1['N']), np.zeros(sL2['N'])]) if (sL1['N'] and sL2['N']) else np.array([0,1])\n",
    "    sp = np.concatenate([sL1['p_en'], sL2['p_en']]) if (sL1['N'] and sL2['N']) else np.array([0.5,0.5])\n",
    "    sm = np.concatenate([sL1['margin'], sL2['margin']]) if (sL1['N'] and sL2['N']) else np.array([0.0,0.0])\n",
    "    auc_p = roc_auc_score(y, sp) if len(np.unique(y))>1 else float('nan')\n",
    "    auc_m = roc_auc_score(y, sm) if len(np.unique(y))>1 else float('nan')\n",
    "    print(\"\\n=== EN L1 (BABELE train+val) vs EN L2 (EMODB) ===\")\n",
    "    print(f\"EN_L1: N={sL1['N']}  Acc(en)={sL1['acc_en']:.3f}  p(en) mean={np.mean(sL1['p_en']):.3f}  margin mean={np.mean(sL1['margin']):.3f}\")\n",
    "    print(f\"EN_L2: N={sL2['N']}  Acc(en)={sL2['acc_en']:.3f}  p(en) mean={np.mean(sL2['p_en']):.3f}  margin mean={np.mean(sL2['margin']):.3f}\")\n",
    "    print(f\"AUC p(en)={auc_p:.3f}   AUC margin={auc_m:.3f}\")\n",
    "    return {'Acc_en_L1': sL1['acc_en'], 'Acc_en_L2': sL2['acc_en'], 'AUC_p_en': float(auc_p),\n",
    "            'AUC_margin': float(auc_m), 'N_en_L1': sL1['N'], 'N_en_L2': sL2['N']}\n",
    "\n",
    "# ───────────── Training di UNA RUN ─────────────\n",
    "def train_one_run(run_cfg):\n",
    "    RUN_ID         = run_cfg['run_id']\n",
    "    emb_kd_on      = run_cfg.get('emb_kd_on', True)\n",
    "    CONF_TH_PER    = run_cfg.get('CONF_TH_EMB_PER', CONF_TH_EMB_PER).copy()\n",
    "    lam_per        = run_cfg.get('LAMBDA_EMB_PER', LAMBDA_EMB_PER).copy()\n",
    "    MU             = run_cfg.get('MU_EMB', MU_EMB)\n",
    "    LOSS_TYP       = run_cfg.get('EMB_LOSS_TYPE', EMB_LOSS_TYPE)\n",
    "    feat_mode      = run_cfg.get('feature_kd_mode', FEATURE_KD_MODE)\n",
    "    use_contr      = run_cfg.get('USE_CONTRASTIVE', USE_CONTRASTIVE)\n",
    "    mu_contr       = run_cfg.get('MU_CONTR', MU_CONTR)\n",
    "    tau_contr      = run_cfg.get('TAU_INFO_NCE', TAU_INFO_NCE)\n",
    "    soft_gate      = run_cfg.get('SOFT_GATE', SOFT_GATE)\n",
    "    soft_temp      = run_cfg.get('SOFT_TEMP', SOFT_TEMP)\n",
    "\n",
    "    assert feat_mode in (\"clean\",\"mix\")\n",
    "    print(f\"\\n===== TRAIN {RUN_ID} | EMB_KD_ON={emb_kd_on}  mode={feat_mode}  conf={CONF_TH_PER}  λ={lam_per}  μ={MU}  loss={LOSS_TYP}  contrastive={use_contr} (μ={mu_contr}, τ={tau_contr})  soft_gate={soft_gate} (T={soft_temp}) =====\")\n",
    "\n",
    "    dl_tr, dl_va = build_loaders(TRAIN_CSV, VAL_CSV, use_teacher=True)\n",
    "    protos, emb_dim = build_audio_prototypes(TRAIN_CSV)\n",
    "\n",
    "    model = Student().to(DEVICE)\n",
    "    proj_a = nn.Linear(emb_dim, PROJ_DIM).to(DEVICE)\n",
    "\n",
    "    for m in model.backbone.modules():\n",
    "        if isinstance(m, nn.BatchNorm3d):\n",
    "            m.eval(); m.weight.requires_grad_(False); m.bias.requires_grad_(False)\n",
    "\n",
    "    ema = copy.deepcopy(model)\n",
    "    for p in ema.parameters(): p.requires_grad_(False)\n",
    "\n",
    "    opt    = AdamW(list(model.parameters()) + list(proj_a.parameters()), lr=LR, weight_decay=WD)\n",
    "    total  = EPOCHS * len(dl_tr)\n",
    "    sched  = OneCycleLR(opt, max_lr=MAX_LR, total_steps=total, pct_start=0.3, div_factor=DIV_FACTOR,\n",
    "                        final_div_factor=FINAL_DIV, anneal_strategy='cos')\n",
    "    crit   = SoftFocalLoss()\n",
    "\n",
    "    run_name = (f\"{RUN_ID}__embkd{int(emb_kd_on)}__mode{feat_mode}__mu{MU:g}\"\n",
    "                f\"__th_en{CONF_TH_PER['en']:.3f}_it{CONF_TH_PER['it']:.3f}_es{CONF_TH_PER['es']:.3f}\"\n",
    "                f\"__lam_en{lam_per['en']:.3f}_it{lam_per['it']:.3f}_es{lam_per['es']:.3f}__loss{LOSS_TYP}\"\n",
    "                f\"__contr{int(use_contr)}__soft{int(soft_gate)}\")\n",
    "    ckpt_dir = os.path.join(\"ckpts\", run_name); os.makedirs(ckpt_dir, exist_ok=True)\n",
    "    best_path_student = os.path.join(ckpt_dir, \"best_student.pt\")\n",
    "    best_path_proja   = os.path.join(ckpt_dir, \"best_proj_a.pt\")\n",
    "    last_path_student = os.path.join(ckpt_dir, \"last_student.pt\")\n",
    "    last_path_proja   = os.path.join(ckpt_dir, \"last_proj_a.pt\")\n",
    "\n",
    "    # logging per-epoca\n",
    "    run_dir = os.path.join(\"reports\", run_name); os.makedirs(run_dir, exist_ok=True)\n",
    "    epoch_logs = []\n",
    "\n",
    "    best_f1, patience = 0.0, 0\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train(); proj_a.train()\n",
    "        gate_cnt = {l: 0 for l in LANGS}; seen_cnt = {l: 0 for l in LANGS}\n",
    "        sup_loss_sum = 0.0; emb_loss_num = 0.0; emb_w_sum = 0.0\n",
    "        cos_all_sum = 0.0; cos_all_cnt = 0\n",
    "        cos_g_sum = 0.0; cos_g_cnt = 0\n",
    "\n",
    "        for batch in dl_tr:\n",
    "            if not (isinstance(batch,(list,tuple)) and len(batch)==3):\n",
    "                raise RuntimeError(\"Atteso batch (x,y,t_emb) in train con use_teacher=True.\")\n",
    "            x_clean, y, t_emb = batch\n",
    "            x_clean = x_clean.to(DEVICE); y = y.to(DEVICE); t_emb = t_emb.to(DEVICE)\n",
    "\n",
    "            # supervised (mixup)\n",
    "            y_onehot = F.one_hot(y, len(LANGS)).float()\n",
    "            x_m, y_m, lam, idx = mixup_return_params(x_clean, y_onehot)\n",
    "\n",
    "            with torch.amp.autocast(device_type=DEVICE.type, enabled=AMP_ENABLED):\n",
    "                logits_m, _, z_v_m = model(x_m)\n",
    "                loss_sup = crit(logits_m, y_m)\n",
    "\n",
    "                loss_emb = torch.tensor(0.0, device=DEVICE)\n",
    "                loss_contr = torch.tensor(0.0, device=DEVICE)\n",
    "\n",
    "                if emb_kd_on:\n",
    "                    gate_orig, margin = gate_with_prototypes(t_emb, y, protos, CONF_TH_PER,\n",
    "                                                             soft=soft_gate, temp=soft_temp)\n",
    "                    for yi, gi in zip(y.tolist(), gate_orig.detach().cpu().tolist()):\n",
    "                        lang = IDX2LANG[int(yi)]; seen_cnt[lang] += 1\n",
    "                        if gi >= 0.5: gate_cnt[lang] += 1\n",
    "\n",
    "                    z_a_clean = proj_a(t_emb)  # [B,d]\n",
    "\n",
    "                    if feat_mode == \"clean\":\n",
    "                        _, _, z_v_clean = model(x_clean)\n",
    "                        loss_per = emb_loss(z_v_clean, z_a_clean, typ=LOSS_TYP)  # [B]\n",
    "                        lam_vec = torch.tensor([lam_per[IDX2LANG[int(yi)]] for yi in y.tolist()],\n",
    "                                               device=DEVICE, dtype=torch.float32)\n",
    "                        emb_w = lam_vec * gate_orig  # hard o soft\n",
    "                        if emb_w.sum() > 0:\n",
    "                            loss_emb = (loss_per * emb_w).sum() / emb_w.sum()\n",
    "\n",
    "                        # logging cosine\n",
    "                        with torch.no_grad():\n",
    "                            cv = F.normalize(z_v_clean, dim=1); ca = F.normalize(z_a_clean, dim=1)\n",
    "                            coss = (cv*ca).sum(1)\n",
    "                            cos_all_sum += coss.sum().item(); cos_all_cnt += coss.numel()\n",
    "                            if emb_w.ndim==1:\n",
    "                                msk = (emb_w>0) if not soft_gate else (emb_w>1e-6)\n",
    "                                if msk.any():\n",
    "                                    cos_g_sum += coss[msk].sum().item(); cos_g_cnt += int(msk.sum().item())\n",
    "\n",
    "                        if use_contr:\n",
    "                            loss_contr_raw = info_nce_loss(z_v_clean, z_a_clean, tau=tau_contr)\n",
    "                            gmean = gate_orig.mean()\n",
    "                            if gmean > 0: loss_contr = loss_contr_raw * gmean\n",
    "\n",
    "                    else:  # feat_mode == \"mix\"\n",
    "                        t_emb_mix = lam * t_emb + (1-lam) * t_emb[idx]\n",
    "                        z_a_mix   = proj_a(t_emb_mix)\n",
    "                        lam_vec_hard = torch.tensor([lam_per[IDX2LANG[int(yi)]] for yi in y.tolist()],\n",
    "                                                    device=DEVICE, dtype=torch.float32)\n",
    "                        lam_vec_mix = lam*lam_vec_hard + (1-lam)*lam_vec_hard[idx]\n",
    "                        gate_mix = lam*gate_orig + (1-lam)*gate_orig[idx]\n",
    "                        loss_per = emb_loss(z_v_m, z_a_mix, typ=LOSS_TYP)  # [B]\n",
    "                        emb_w = lam_vec_mix * gate_mix\n",
    "                        if emb_w.sum() > 0:\n",
    "                            loss_emb = (loss_per * emb_w).sum() / emb_w.sum()\n",
    "                        with torch.no_grad():\n",
    "                            cv = F.normalize(z_v_m, dim=1); ca = F.normalize(z_a_mix, dim=1)\n",
    "                            coss = (cv*ca).sum(1)\n",
    "                            cos_all_sum += coss.sum().item(); cos_all_cnt += coss.numel()\n",
    "                            msk = (emb_w>0) if not soft_gate else (emb_w>1e-6)\n",
    "                            if msk.any():\n",
    "                                cos_g_sum += coss[msk].sum().item(); cos_g_cnt += int(msk.sum().item())\n",
    "                        if use_contr:\n",
    "                            loss_contr_raw = info_nce_loss(z_v_m, z_a_mix, tau=tau_contr)\n",
    "                            gmean = gate_mix.mean()\n",
    "                            if gmean > 0: loss_contr = loss_contr_raw * gmean\n",
    "\n",
    "                loss = loss_sup + MU * loss_emb + (mu_contr * loss_contr if use_contr else 0.0)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(list(model.parameters())+list(proj_a.parameters()), 5.0)\n",
    "            opt.step(); opt.zero_grad()\n",
    "            sched.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                sup_loss_sum += loss_sup.item()\n",
    "                if emb_kd_on:\n",
    "                    # per avere una media pesata coerente\n",
    "                    if 'emb_w' in locals():\n",
    "                        emb_loss_num += (loss_per * emb_w).sum().item()\n",
    "                        emb_w_sum    += emb_w.sum().item()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for m,e in zip(model.parameters(), ema.parameters()):\n",
    "                    e.mul_(0.999).add_(m, alpha=0.001)\n",
    "\n",
    "        # ── Validation in-domain ───────────────────────────\n",
    "        model.eval()\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for x,y in DataLoader(MouthDS(VAL_CSV, L, augment=False, use_teacher=False),\n",
    "                                  batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=PIN_MEMORY):\n",
    "                x = x.to(DEVICE); y = y.to(DEVICE)\n",
    "                logits,_,_ = model(x)\n",
    "                preds += logits.argmax(1).cpu().tolist()\n",
    "                gts   += y.cpu().tolist()\n",
    "        f1 = macro_f1(gts, preds)\n",
    "        cm = confusion_matrix(gts, preds, labels=list(range(len(LANGS))))\n",
    "        print(f\"Epoch {ep:02d}  Val-F1={f1:.3f}\")\n",
    "        print(pd.DataFrame(cm, index=LANGS, columns=LANGS))\n",
    "\n",
    "        total_seen = sum(seen_cnt.values()); total_gated= sum(gate_cnt.values())\n",
    "        rates = {l: (gate_cnt[l] / max(1, seen_cnt[l])) for l in LANGS}\n",
    "        gate_rate_total = (total_gated/max(1,total_seen))*100.0\n",
    "        print(f\"[EMB-KD] gate_rate_total={gate_rate_total:.2f}%  by_lang={rates}\")\n",
    "\n",
    "        # log per-epoca\n",
    "        loss_sup_mean = sup_loss_sum / max(1, len(dl_tr))\n",
    "        loss_emb_mean = (emb_loss_num / max(1e-8, emb_w_sum)) if emb_w_sum>0 else 0.0\n",
    "        cos_mean      = (cos_all_sum / max(1, cos_all_cnt)) if cos_all_cnt>0 else 0.0\n",
    "        cos_g_mean    = (cos_g_sum / max(1, cos_g_cnt)) if cos_g_cnt>0 else 0.0\n",
    "        epoch_logs.append(dict(epoch=ep, val_f1=float(f1),\n",
    "                               loss_sup_mean=loss_sup_mean,\n",
    "                               loss_emb_mean=loss_emb_mean,\n",
    "                               gate_rate_total=gate_rate_total,\n",
    "                               gate_en=rates['en']*100, gate_it=rates['it']*100, gate_es=rates['es']*100,\n",
    "                               cos_align_mean=cos_mean,\n",
    "                               cos_align_gated_mean=cos_g_mean))\n",
    "        pd.DataFrame(epoch_logs).to_csv(os.path.join(run_dir, \"epoch_log.csv\"), index=False)\n",
    "\n",
    "        # anti-dominanza su 'en'\n",
    "        en_r = rates.get('en', 0.0); others = [r for l,r in rates.items() if l!='en']\n",
    "        mean_others = sum(others)/max(1, len(others))\n",
    "        if emb_kd_on and en_r > 2.0*max(1e-6, mean_others) + 0.05:\n",
    "            old_th  = CONF_TH_PER['en']; old_lam = lam_per['en']\n",
    "            CONF_TH_PER['en']  = min(0.50, CONF_TH_PER['en'] + 0.02)\n",
    "            lam_per['en']      = max(0.2*old_lam, old_lam*0.8)\n",
    "            print(f\"[EMB-KD][anti-dom] en troppo dominante → th_en {old_th:.3f}->{CONF_TH_PER['en']:.3f}, λ_en {old_lam:.4f}->{lam_per['en']:.4f}\")\n",
    "\n",
    "        # early stopping + save\n",
    "        if f1>best_f1:\n",
    "            best_f1, patience = f1, 0\n",
    "            torch.save(model.state_dict(), best_path_student)\n",
    "            torch.save(proj_a.state_dict(), best_path_proja)\n",
    "            print(f\"  → New best: Val-F1={f1:.3f}  saved: {best_path_student} (+proj_a)\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= PATIENCE:\n",
    "                print(\"Early stopping\"); break\n",
    "\n",
    "    torch.save(model.state_dict(), last_path_student)\n",
    "    torch.save(proj_a.state_dict(), last_path_proja)\n",
    "    print(f\"Best Val-F1 (VAL) = {best_f1:.3f}\")\n",
    "    return best_path_student, best_path_proja, run_name\n",
    "\n",
    "# ───────────── RUN SUITE + REPORT ─────────────\n",
    "def run_suite():\n",
    "    # suite: baseline, KD forzata (soglie -1), KD intermedia, KD rigorosa, controllo (MU=0)\n",
    "    EXPERIMENTS = [\n",
    "        dict(run_id=\"E0_baseline\",\n",
    "             emb_kd_on=False, feature_kd_mode=\"clean\",\n",
    "             CONF_TH_EMB_PER={'en':0.05,'it':0.05,'es':0.05},\n",
    "             LAMBDA_EMB_PER={'en':0.00,'it':0.00,'es':0.00},\n",
    "             MU_EMB=0.0, EMB_LOSS_TYPE='mse',\n",
    "             USE_CONTRASTIVE=False, SOFT_GATE=False),\n",
    "\n",
    "        dict(run_id=\"E1_KD_forced\",\n",
    "             emb_kd_on=True, feature_kd_mode=\"mix\",\n",
    "             CONF_TH_EMB_PER={'en':-1.0,'it':-1.0,'es':-1.0},   # gate ~ 100%\n",
    "             LAMBDA_EMB_PER={'en':0.015,'it':0.05,'es':0.05},\n",
    "             MU_EMB=0.15, EMB_LOSS_TYPE='mse',\n",
    "             USE_CONTRASTIVE=False, SOFT_GATE=False),\n",
    "\n",
    "        dict(run_id=\"E2_KD_intermediate\",\n",
    "             emb_kd_on=True, feature_kd_mode=\"clean\",\n",
    "             CONF_TH_EMB_PER={'en':0.05,'it':0.05,'es':0.05},\n",
    "             LAMBDA_EMB_PER={'en':0.012,'it':0.05,'es':0.05},\n",
    "             MU_EMB=0.15, EMB_LOSS_TYPE='mse',\n",
    "             USE_CONTRASTIVE=False, SOFT_GATE=True, SOFT_TEMP=0.05),\n",
    "\n",
    "        dict(run_id=\"E3_KD_strict\",\n",
    "             emb_kd_on=True, feature_kd_mode=\"clean\",\n",
    "             CONF_TH_EMB_PER={'en':0.10,'it':0.08,'es':0.08},\n",
    "             LAMBDA_EMB_PER={'en':0.010,'it':0.040,'es':0.040},\n",
    "             MU_EMB=0.12, EMB_LOSS_TYPE='cos',\n",
    "             USE_CONTRASTIVE=True, MU_CONTR=0.05, TAU_INFO_NCE=0.07,\n",
    "             SOFT_GATE=True, SOFT_TEMP=0.05),\n",
    "\n",
    "        dict(run_id=\"E4_control_MU0\",\n",
    "             emb_kd_on=True, feature_kd_mode=\"clean\",\n",
    "             CONF_TH_EMB_PER={'en':0.05,'it':0.05,'es':0.05},\n",
    "             LAMBDA_EMB_PER={'en':0.012,'it':0.05,'es':0.05},\n",
    "             MU_EMB=0.0, EMB_LOSS_TYPE='mse',\n",
    "             USE_CONTRASTIVE=False, SOFT_GATE=False),\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    emodb_all, emodb_L1, emodb_L2 = split_emodb_L1_L2(CROSS_CSV)\n",
    "    enL1_csv = build_enL1_from_babele(TRAIN_CSV, VAL_CSV, out_csv=\"reports/EN_L1_from_BABELE.csv\")\n",
    "\n",
    "    for cfg in EXPERIMENTS:\n",
    "        best_ckpt, best_proja, run_name = train_one_run(cfg)\n",
    "\n",
    "        # Eval IN-domain (VAL)\n",
    "        f1_in, acc_in = evaluate_manifest(VAL_CSV, best_ckpt, title=f\"{cfg['run_id']}__IN_VAL\")\n",
    "\n",
    "        # Eval CROSS EMODB (all, L1, L2)\n",
    "        f1_x_all, acc_x_all = evaluate_manifest(emodb_all, best_ckpt, title=f\"{cfg['run_id']}__CROSS_EMODB_all\")\n",
    "        f1_x_L1,  acc_x_L1  = evaluate_manifest(emodb_L1,  best_ckpt, title=f\"{cfg['run_id']}__CROSS_EMODB_L1_it_es\")\n",
    "        f1_x_L2,  acc_x_L2  = evaluate_manifest(emodb_L2,  best_ckpt, title=f\"{cfg['run_id']}__CROSS_EMODB_L2_en\")\n",
    "\n",
    "        # EN L1 (TRAIN+VAL) vs EN L2 (EMODB)\n",
    "        run_dir = os.path.join(\"reports\", run_name)\n",
    "        en_stats = eval_enL1_vs_enL2(enL1_csv, emodb_L2, best_ckpt, run_dir=run_dir)\n",
    "\n",
    "        results.append({\n",
    "            \"run\": cfg['run_id'],\n",
    "            \"EMB_KD_ON\": cfg['emb_kd_on'],\n",
    "            \"mode\": cfg['feature_kd_mode'],\n",
    "            \"conf_th_emb_en\": cfg['CONF_TH_EMB_PER']['en'],\n",
    "            \"conf_th_emb_it\": cfg['CONF_TH_EMB_PER']['it'],\n",
    "            \"conf_th_emb_es\": cfg['CONF_TH_EMB_PER']['es'],\n",
    "            \"lambda_emb_en\": cfg['LAMBDA_EMB_PER']['en'],\n",
    "            \"lambda_emb_it\": cfg['LAMBDA_EMB_PER']['it'],\n",
    "            \"lambda_emb_es\": cfg['LAMBDA_EMB_PER']['es'],\n",
    "            \"MU_EMB\": cfg['MU_EMB'],\n",
    "            \"EMB_LOSS\": cfg['EMB_LOSS_TYPE'],\n",
    "            \"contrastive\": int(cfg.get('USE_CONTRASTIVE', False)),\n",
    "            \"soft_gate\": int(cfg.get('SOFT_GATE', False)),\n",
    "            \"F1_in\":  float(f1_in),\n",
    "            \"F1_x_all\": float(f1_x_all),\n",
    "            \"F1_x_L1\": float(f1_x_L1),\n",
    "            \"F1_x_L2\": float(f1_x_L2),\n",
    "            \"Acc_en_L1\": en_stats['Acc_en_L1'],\n",
    "            \"Acc_en_L2\": en_stats['Acc_en_L2'],\n",
    "            \"AUC_p_en\":  en_stats['AUC_p_en'],\n",
    "            \"AUC_margin\": en_stats['AUC_margin'],\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    base = df.iloc[0]\n",
    "    df[\"ΔF1_in_vs_baseline\"]   = df[\"F1_in\"]    - base[\"F1_in\"]\n",
    "    df[\"ΔF1_x_vs_baseline\"]    = df[\"F1_x_all\"] - base[\"F1_x_all\"]\n",
    "    df[\"ΔAcc_en_L1_vs_base\"]   = df[\"Acc_en_L1\"] - base[\"Acc_en_L1\"]\n",
    "    df[\"ΔAcc_en_L2_vs_base\"]   = df[\"Acc_en_L2\"] - base[\"Acc_en_L2\"]\n",
    "    print(\"\\n================ ALL RUNS SUMMARY ================\")\n",
    "    print(df.to_string(index=False))\n",
    "    os.makedirs(\"reports\", exist_ok=True)\n",
    "    out_csv = \"reports/emb_kd_feature_strict_summary.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"\\nSaved: {out_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_suite()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2de4a9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TRAIN B0_noKD | USE_L2_ML=False  top=0.0 mid=0.0  p=0.0  sched=const =====\n",
      "Epoch 01  Val-F1=0.725\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   8  20   0\n",
      "es  15   0  13\n",
      "  → New best: Val-F1=0.725  saved: ckpts/B0_noKD__L20__top0__mid0__p0__schedconst/best_student.pt\n",
      "Epoch 02  Val-F1=0.823\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   6   2  20\n",
      "  → New best: Val-F1=0.823  saved: ckpts/B0_noKD__L20__top0__mid0__p0__schedconst/best_student.pt\n",
      "Epoch 03  Val-F1=0.914\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   2  21   5\n",
      "es   0   0  28\n",
      "  → New best: Val-F1=0.914  saved: ckpts/B0_noKD__L20__top0__mid0__p0__schedconst/best_student.pt\n",
      "Epoch 04  Val-F1=0.901\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   4  21   3\n",
      "es   0   1  27\n",
      "Epoch 05  Val-F1=0.914\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   6  21   1\n",
      "es   0   0  28\n",
      "  → New best: Val-F1=0.914  saved: ckpts/B0_noKD__L20__top0__mid0__p0__schedconst/best_student.pt\n",
      "Epoch 06  Val-F1=0.877\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  18  10\n",
      "es   0   0  28\n",
      "Epoch 07  Val-F1=0.786\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   4  12  12\n",
      "es   0   0  28\n",
      "Epoch 08  Val-F1=0.718\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   5  23   0\n",
      "es   1  16  11\n",
      "Epoch 09  Val-F1=0.892\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   0   2  26\n",
      "Epoch 10  Val-F1=0.584\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   6  17   5\n",
      "Epoch 11  Val-F1=0.916\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   1  27   0\n",
      "es   0   6  22\n",
      "  → New best: Val-F1=0.916  saved: ckpts/B0_noKD__L20__top0__mid0__p0__schedconst/best_student.pt\n",
      "Epoch 12  Val-F1=0.988\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   1   0  27\n",
      "  → New best: Val-F1=0.988  saved: ckpts/B0_noKD__L20__top0__mid0__p0__schedconst/best_student.pt\n",
      "Epoch 13  Val-F1=0.940\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   4  24   0\n",
      "es   0   1  27\n",
      "Epoch 14  Val-F1=0.630\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   5  23   0\n",
      "es   2  20   6\n",
      "Epoch 15  Val-F1=1.000\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   0  28\n",
      "  → New best: Val-F1=1.000  saved: ckpts/B0_noKD__L20__top0__mid0__p0__schedconst/best_student.pt\n",
      "Epoch 16  Val-F1=0.708\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   5  11  12\n",
      "Epoch 17  Val-F1=0.904\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   5  23   0\n",
      "es   0   3  25\n",
      "Epoch 18  Val-F1=0.854\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   2  26   0\n",
      "es   0  10  18\n",
      "Epoch 19  Val-F1=0.755\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   0  13  15\n",
      "Epoch 20  Val-F1=0.556\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0  28   0\n",
      "Epoch 21  Val-F1=0.596\n",
      "    en  it  es\n",
      "en  26   0   2\n",
      "it   5  23   0\n",
      "es   0  23   5\n",
      "Epoch 22  Val-F1=0.778\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   5  23   0\n",
      "es   0  13  15\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 1.000\n",
      "\n",
      "[B0_noKD__IN_VAL] N=84  Acc=1.000  Macro-F1=1.000\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   0  28\n",
      "\n",
      "[B0_noKD__CROSS_all] N=29  Acc=0.310  Macro-F1=0.313\n",
      "    en  it  es\n",
      "en   3   2   4\n",
      "it   4   3   3\n",
      "es   5   2   3\n",
      "\n",
      "[B0_noKD__CROSS_L1_it_es] N=20  Acc=0.300  Macro-F1=0.258\n",
      "    en  it  es\n",
      "en   0   0   0\n",
      "it   4   3   3\n",
      "es   5   2   3\n",
      "\n",
      "[B0_noKD__CROSS_L2_en] N=9  Acc=0.333  Macro-F1=0.167\n",
      "    en  it  es\n",
      "en   3   2   4\n",
      "it   0   0   0\n",
      "es   0   0   0\n",
      "\n",
      "=== EN L1 (Train+Val) vs EN L2 (Dominio dedicato) ===\n",
      "EN_L1: N=98  Acc(en)=1.000  p(en) mean=0.934  margin mean=2.946\n",
      "EN_L2: N=7  Acc(en)=0.143  p(en) mean=0.222  margin mean=-1.337\n",
      "AUC p(en)=1.000   AUC margin=1.000\n",
      "\n",
      "===== TRAIN B1_L2_both | USE_L2_ML=True  top=1.0 mid=0.5  p=1.0  sched=const =====\n",
      "Epoch 01  Val-F1=0.767\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   5   7  16\n",
      "  → New best: Val-F1=0.767  saved: ckpts/B1_L2_both__L21__top1__mid0.5__p1__schedconst/best_student.pt\n",
      "Epoch 02  Val-F1=0.842\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   3  25   0\n",
      "es   0  10  18\n",
      "  → New best: Val-F1=0.842  saved: ckpts/B1_L2_both__L21__top1__mid0.5__p1__schedconst/best_student.pt\n",
      "Epoch 03  Val-F1=0.826\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   3  25   0\n",
      "es   3   8  17\n",
      "Epoch 04  Val-F1=0.940\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   5  23\n",
      "  → New best: Val-F1=0.940  saved: ckpts/B1_L2_both__L21__top1__mid0.5__p1__schedconst/best_student.pt\n",
      "Epoch 05  Val-F1=0.730\n",
      "    en  it  es\n",
      "en  26   0   2\n",
      "it   6  22   0\n",
      "es   0  14  14\n",
      "Epoch 06  Val-F1=0.928\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   4  24   0\n",
      "es   0   2  26\n",
      "Epoch 07  Val-F1=0.892\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   5  23   0\n",
      "es   0   4  24\n",
      "Epoch 08  Val-F1=0.790\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   1  15  12\n",
      "Epoch 09  Val-F1=0.890\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   9  19\n",
      "Epoch 10  Val-F1=0.900\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   3   5  20\n",
      "Epoch 11  Val-F1=0.928\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   5  23   0\n",
      "es   0   1  27\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.940\n",
      "\n",
      "[B1_L2_both__IN_VAL] N=84  Acc=0.940  Macro-F1=0.940\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   5  23\n",
      "\n",
      "[B1_L2_both__CROSS_all] N=29  Acc=0.379  Macro-F1=0.351\n",
      "    en  it  es\n",
      "en   1   3   5\n",
      "it   0   5   5\n",
      "es   3   2   5\n",
      "\n",
      "[B1_L2_both__CROSS_L1_it_es] N=20  Acc=0.500  Macro-F1=0.363\n",
      "    en  it  es\n",
      "en   0   0   0\n",
      "it   0   5   5\n",
      "es   3   2   5\n",
      "\n",
      "[B1_L2_both__CROSS_L2_en] N=9  Acc=0.111  Macro-F1=0.067\n",
      "    en  it  es\n",
      "en   1   3   5\n",
      "it   0   0   0\n",
      "es   0   0   0\n",
      "\n",
      "=== EN L1 (Train+Val) vs EN L2 (Dominio dedicato) ===\n",
      "EN_L1: N=98  Acc(en)=1.000  p(en) mean=0.896  margin mean=2.618\n",
      "EN_L2: N=7  Acc(en)=0.143  p(en) mean=0.284  margin mean=-0.928\n",
      "AUC p(en)=1.000   AUC margin=0.999\n",
      "\n",
      "===== TRAIN B2_L2_top_only | USE_L2_ML=True  top=1.0 mid=0.0  p=1.0  sched=const =====\n",
      "Epoch 01  Val-F1=0.869\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   1   3  24\n",
      "  → New best: Val-F1=0.869  saved: ckpts/B2_L2_top_only__L21__top1__mid0__p1__schedconst/best_student.pt\n",
      "Epoch 02  Val-F1=0.915\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   0   0  28\n",
      "  → New best: Val-F1=0.915  saved: ckpts/B2_L2_top_only__L21__top1__mid0__p1__schedconst/best_student.pt\n",
      "Epoch 03  Val-F1=0.880\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   0   3  25\n",
      "Epoch 04  Val-F1=0.880\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   6  22   0\n",
      "es   0   4  24\n",
      "Epoch 05  Val-F1=0.913\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   4  21   3\n",
      "es   0   0  28\n",
      "Epoch 06  Val-F1=0.917\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   4  24   0\n",
      "es   1   2  25\n",
      "  → New best: Val-F1=0.917  saved: ckpts/B2_L2_top_only__L21__top1__mid0__p1__schedconst/best_student.pt\n",
      "Epoch 07  Val-F1=0.891\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   1  27   0\n",
      "es   0   8  20\n",
      "Epoch 08  Val-F1=0.916\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   6  22   0\n",
      "es   0   1  27\n",
      "Epoch 09  Val-F1=0.576\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   2  26   0\n",
      "es   3  23   2\n",
      "Epoch 10  Val-F1=0.762\n",
      "    en  it  es\n",
      "en  23   0   5\n",
      "it   7  21   0\n",
      "es   2   6  20\n",
      "Epoch 11  Val-F1=0.726\n",
      "    en  it  es\n",
      "en  11   0  17\n",
      "it   1  23   4\n",
      "es   0   0  28\n",
      "Epoch 12  Val-F1=0.628\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0  25   3\n",
      "Epoch 13  Val-F1=0.531\n",
      "    en  it  es\n",
      "en   3  25   0\n",
      "it   0  28   0\n",
      "es   0  10  18\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.917\n",
      "\n",
      "[B2_L2_top_only__IN_VAL] N=84  Acc=0.917  Macro-F1=0.917\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   4  24   0\n",
      "es   1   2  25\n",
      "\n",
      "[B2_L2_top_only__CROSS_all] N=29  Acc=0.310  Macro-F1=0.307\n",
      "    en  it  es\n",
      "en   1   2   6\n",
      "it   2   4   4\n",
      "es   5   1   4\n",
      "\n",
      "[B2_L2_top_only__CROSS_L1_it_es] N=20  Acc=0.400  Macro-F1=0.326\n",
      "    en  it  es\n",
      "en   0   0   0\n",
      "it   2   4   4\n",
      "es   5   1   4\n",
      "\n",
      "[B2_L2_top_only__CROSS_L2_en] N=9  Acc=0.111  Macro-F1=0.067\n",
      "    en  it  es\n",
      "en   1   2   6\n",
      "it   0   0   0\n",
      "es   0   0   0\n",
      "\n",
      "=== EN L1 (Train+Val) vs EN L2 (Dominio dedicato) ===\n",
      "EN_L1: N=98  Acc(en)=1.000  p(en) mean=0.890  margin mean=2.510\n",
      "EN_L2: N=7  Acc(en)=0.429  p(en) mean=0.357  margin mean=-0.423\n",
      "AUC p(en)=0.996   AUC margin=0.978\n",
      "\n",
      "===== TRAIN B3_L2_mid_only | USE_L2_ML=True  top=0.0 mid=0.5  p=1.0  sched=const =====\n",
      "Epoch 01  Val-F1=0.916\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   6  22   0\n",
      "es   0   1  27\n",
      "  → New best: Val-F1=0.916  saved: ckpts/B3_L2_mid_only__L21__top0__mid0.5__p1__schedconst/best_student.pt\n",
      "Epoch 02  Val-F1=0.915\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   0   0  28\n",
      "Epoch 03  Val-F1=0.868\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   6  22   0\n",
      "es   0   5  23\n",
      "Epoch 04  Val-F1=0.892\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   0   2  26\n",
      "Epoch 05  Val-F1=0.832\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   1   6  21\n",
      "Epoch 06  Val-F1=0.741\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   0  14  14\n",
      "Epoch 07  Val-F1=0.725\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   1  14  13\n",
      "Epoch 08  Val-F1=0.794\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   0  10  18\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.916\n",
      "\n",
      "[B3_L2_mid_only__IN_VAL] N=84  Acc=0.917  Macro-F1=0.916\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   6  22   0\n",
      "es   0   1  27\n",
      "\n",
      "[B3_L2_mid_only__CROSS_all] N=29  Acc=0.241  Macro-F1=0.252\n",
      "    en  it  es\n",
      "en   2   1   6\n",
      "it   3   3   4\n",
      "es   6   2   2\n",
      "\n",
      "[B3_L2_mid_only__CROSS_L1_it_es] N=20  Acc=0.250  Macro-F1=0.217\n",
      "    en  it  es\n",
      "en   0   0   0\n",
      "it   3   3   4\n",
      "es   6   2   2\n",
      "\n",
      "[B3_L2_mid_only__CROSS_L2_en] N=9  Acc=0.222  Macro-F1=0.121\n",
      "    en  it  es\n",
      "en   2   1   6\n",
      "it   0   0   0\n",
      "es   0   0   0\n",
      "\n",
      "=== EN L1 (Train+Val) vs EN L2 (Dominio dedicato) ===\n",
      "EN_L1: N=98  Acc(en)=1.000  p(en) mean=0.747  margin mean=1.684\n",
      "EN_L2: N=7  Acc(en)=0.286  p(en) mean=0.313  margin mean=-0.300\n",
      "AUC p(en)=0.999   AUC margin=0.999\n",
      "\n",
      "===== TRAIN B4_L2_both_light | USE_L2_ML=True  top=0.5 mid=0.25  p=0.3  sched=warmup =====\n",
      "Epoch 01  Val-F1=0.881\n",
      "    en  it  es\n",
      "en  26   0   2\n",
      "it   2  23   3\n",
      "es   1   2  25\n",
      "  → New best: Val-F1=0.881  saved: ckpts/B4_L2_both_light__L21__top0.5__mid0.25__p0.3__schedwarmup/best_student.pt\n",
      "Epoch 02  Val-F1=0.904\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   0   1  27\n",
      "  → New best: Val-F1=0.904  saved: ckpts/B4_L2_both_light__L21__top0.5__mid0.25__p0.3__schedwarmup/best_student.pt\n",
      "Epoch 03  Val-F1=0.913\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   3  21   4\n",
      "es   0   0  28\n",
      "  → New best: Val-F1=0.913  saved: ckpts/B4_L2_both_light__L21__top0.5__mid0.25__p0.3__schedwarmup/best_student.pt\n",
      "Epoch 04  Val-F1=0.845\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   4  21   3\n",
      "es   6   0  22\n",
      "Epoch 05  Val-F1=0.894\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   2   0  26\n",
      "Epoch 06  Val-F1=0.844\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   6  22   0\n",
      "es   0   7  21\n",
      "Epoch 07  Val-F1=0.781\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   1  10  17\n",
      "Epoch 08  Val-F1=0.904\n",
      "    en  it  es\n",
      "en  27   0   1\n",
      "it   3  23   2\n",
      "es   0   2  26\n",
      "Epoch 09  Val-F1=0.928\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  22   6\n",
      "es   0   0  28\n",
      "  → New best: Val-F1=0.928  saved: ckpts/B4_L2_both_light__L21__top0.5__mid0.25__p0.3__schedwarmup/best_student.pt\n",
      "Epoch 10  Val-F1=0.915\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  21   7\n",
      "es   0   0  28\n",
      "Epoch 11  Val-F1=0.808\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0  15  13\n",
      "Epoch 12  Val-F1=0.713\n",
      "    en  it  es\n",
      "en  25   0   3\n",
      "it   0  28   0\n",
      "es   0  19   9\n",
      "Epoch 13  Val-F1=0.671\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0  23   5\n",
      "Epoch 14  Val-F1=0.831\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  18  10\n",
      "es   0   4  24\n",
      "Epoch 15  Val-F1=0.952\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  27   1\n",
      "es   0   3  25\n",
      "  → New best: Val-F1=0.952  saved: ckpts/B4_L2_both_light__L21__top0.5__mid0.25__p0.3__schedwarmup/best_student.pt\n",
      "Epoch 16  Val-F1=0.964\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   3  25\n",
      "  → New best: Val-F1=0.964  saved: ckpts/B4_L2_both_light__L21__top0.5__mid0.25__p0.3__schedwarmup/best_student.pt\n",
      "Epoch 17  Val-F1=0.952\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   1  27   0\n",
      "es   2   1  25\n",
      "Epoch 18  Val-F1=0.864\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0  11  17\n",
      "Epoch 19  Val-F1=0.856\n",
      "    en  it  es\n",
      "en  23   0   5\n",
      "it   7  21   0\n",
      "es   0   0  28\n",
      "Epoch 20  Val-F1=1.000\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   0  28\n",
      "  → New best: Val-F1=1.000  saved: ckpts/B4_L2_both_light__L21__top0.5__mid0.25__p0.3__schedwarmup/best_student.pt\n",
      "Epoch 21  Val-F1=0.928\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   4  24   0\n",
      "es   0   2  26\n",
      "Epoch 22  Val-F1=0.915\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   0   0  28\n",
      "Epoch 23  Val-F1=0.755\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   0  13  15\n",
      "Epoch 24  Val-F1=0.877\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0  10  18\n",
      "Epoch 25  Val-F1=0.850\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0  12  16\n",
      "Epoch 26  Val-F1=0.741\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   7  21   0\n",
      "es   0  14  14\n",
      "Epoch 27  Val-F1=0.964\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   3  25\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 1.000\n",
      "\n",
      "[B4_L2_both_light__IN_VAL] N=84  Acc=1.000  Macro-F1=1.000\n",
      "    en  it  es\n",
      "en  28   0   0\n",
      "it   0  28   0\n",
      "es   0   0  28\n",
      "\n",
      "[B4_L2_both_light__CROSS_all] N=29  Acc=0.414  Macro-F1=0.390\n",
      "    en  it  es\n",
      "en   1   4   4\n",
      "it   4   4   2\n",
      "es   3   0   7\n",
      "\n",
      "[B4_L2_both_light__CROSS_L1_it_es] N=20  Acc=0.550  Macro-F1=0.436\n",
      "    en  it  es\n",
      "en   0   0   0\n",
      "it   4   4   2\n",
      "es   3   0   7\n",
      "\n",
      "[B4_L2_both_light__CROSS_L2_en] N=9  Acc=0.111  Macro-F1=0.067\n",
      "    en  it  es\n",
      "en   1   4   4\n",
      "it   0   0   0\n",
      "es   0   0   0\n",
      "\n",
      "=== EN L1 (Train+Val) vs EN L2 (Dominio dedicato) ===\n",
      "EN_L1: N=98  Acc(en)=1.000  p(en) mean=0.860  margin mean=1.981\n",
      "EN_L2: N=7  Acc(en)=0.000  p(en) mean=0.170  margin mean=-2.030\n",
      "AUC p(en)=1.000   AUC margin=1.000\n",
      "\n",
      "================ L2-ONLY ABLATION SUMMARY ================\n",
      "             run  USE_L2_ML  L2_top  L2_mid  L2_apply_prob L2_schedule    F1_in  F1_x_all  F1_x_L1  F1_x_L2  Acc_en_L1  Acc_en_L2  AUC_p_en  AUC_margin  ΔF1_in_vs_baseline  ΔF1_x_vs_baseline  ΔAcc_en_L1_vs_base  ΔAcc_en_L2_vs_base\n",
      "         B0_noKD          0     0.0    0.00            0.0       const 1.000000  0.312885 0.258333 0.166667        1.0   0.142857  1.000000    1.000000            0.000000           0.000000                 0.0            0.000000\n",
      "      B1_L2_both          1     1.0    0.50            1.0       const 0.939998  0.351282 0.362745 0.066667        1.0   0.142857  1.000000    0.998542           -0.060002           0.038397                 0.0            0.000000\n",
      "  B2_L2_top_only          1     1.0    0.00            1.0       const 0.916773  0.307190 0.325926 0.066667        1.0   0.428571  0.995627    0.978134           -0.083227          -0.005696                 0.0            0.285714\n",
      "  B3_L2_mid_only          1     0.0    0.50            1.0       const 0.915930  0.252273 0.216667 0.121212        1.0   0.285714  0.998542    0.998542           -0.084070          -0.060612                 0.0            0.142857\n",
      "B4_L2_both_light          1     0.5    0.25            0.3      warmup 1.000000  0.390262 0.436090 0.066667        1.0   0.000000  1.000000    1.000000            0.000000           0.077377                 0.0           -0.142857\n",
      "\n",
      "Saved: reports/kd_l2_only_ablation__crossA_enL2B.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "L2-only KD (multi-livello) – Confronto pulito:\n",
    "- Baseline: NO KD\n",
    "- L2 (top/mid/both) + variante \"light\" (warm-up + applicazione stocastica)\n",
    "\n",
    "Valutazioni:\n",
    "  • In-domain (VAL)\n",
    "  • Cross-domain su un dominio (tutto / L1 it+es / L2 en)\n",
    "  • EN L1 (train+val) vs EN L2 (su un secondo dominio diverso dal cross-domain)\n",
    "\n",
    "NOTE IMPORTANTI\n",
    "- Richiede nel CSV di train le colonne:\n",
    "    mouth_path, label, layer10_mean_path, layer11_mean_path\n",
    "  (le ultime due possono mancare su alcune righe: verranno mascherate)\n",
    "- Fix OneCycleLR: tutti i parametri (inclusi adattatori L10/L11) sono\n",
    "  creati PRIMA dell'optimizer/scheduler\n",
    "\"\"\"\n",
    "\n",
    "import os, random, contextlib\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.video import r3d_18, R3D_18_Weights\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "# ───────────── Config base ─────────────\n",
    "SEED = 42\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 8\n",
    "LR, WD = 3e-4, 1e-3\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "LANGS = ['en','it','es']\n",
    "OUT_H, OUT_W, L = 64, 64, 32\n",
    "MIXUP_ALPHA = 0.30\n",
    "PATIENCE = 7\n",
    "MAX_LR = 3e-4\n",
    "DIV_FACTOR = 10\n",
    "FINAL_DIV = 100\n",
    "\n",
    "# Datasets (train/val)\n",
    "TRAIN_CSV = \"NEWEMODB/manifest_train.csv\"\n",
    "VAL_CSV   = \"NEWEMODB/manifest_test.csv\"\n",
    "\n",
    "# === DOMINI DI TEST =========================================\n",
    "# Cross-domain (tutto/L1/L2) – dominio A\n",
    "CROSS_DOMAIN_CSV = \"BABELE/manifest_test.csv\"\n",
    "\n",
    "# L1 vs L2: EN_L2 viene da questo dominio B (DIVERSO da cross-domain),\n",
    "# EN_L1 viene da TRAIN+VAL del dominio di training\n",
    "L1L2_DOMAIN_CSV  = \"EMODB/manifest_test.csv\"\n",
    "# ============================================================\n",
    "\n",
    "# Device & AMP\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "AMP_ENABLED = (DEVICE.type == 'cuda')\n",
    "PIN_MEMORY = (DEVICE.type == 'cuda')\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ───────────── Utility ─────────────\n",
    "def macro_f1(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average=\"macro\") if len(y_true) else 0.0\n",
    "\n",
    "# ───────────── Augmentazioni ─────────────\n",
    "class SpecAug3D:\n",
    "    def __init__(self, H, W, T_mask=4, S_mask=4):\n",
    "        self.tf = T.Compose([\n",
    "            T.ToPILImage(),\n",
    "            T.RandomResizedCrop((H,W), scale=(0.95,1.0), ratio=(1.0,1.0)),\n",
    "            T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),\n",
    "            T.RandomHorizontalFlip(0.5),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "        self.T_mask, self.S_mask = T_mask, S_mask\n",
    "    def __call__(self, vid):\n",
    "        frames = []\n",
    "        for f in vid:\n",
    "            img = (f*255).byte()\n",
    "            t   = self.tf(img).squeeze(0)\n",
    "            frames.append(t)\n",
    "        vid = torch.stack(frames)\n",
    "        L_,H,W = vid.shape\n",
    "        if L_ > self.T_mask:\n",
    "            t0 = random.randrange(0, L_-self.T_mask+1)\n",
    "            vid[t0:t0+self.T_mask] = 0\n",
    "        if H>self.S_mask and W>self.S_mask:\n",
    "            fi = random.randrange(0, L_)\n",
    "            h0 = random.randrange(0, H-self.S_mask+1)\n",
    "            w0 = random.randrange(0, W-self.S_mask+1)\n",
    "            vid[fi,h0:h0+self.S_mask,w0:w0+self.S_mask] = 0\n",
    "        return vid\n",
    "\n",
    "class RandomErasing3D:\n",
    "    def __init__(self, p=0.3, size=(8,8,8)):\n",
    "        self.p = p; self.d, self.h, self.w = size\n",
    "    def __call__(self, vid):\n",
    "        if random.random()>self.p: return vid\n",
    "        L_,H,W = vid.shape\n",
    "        sd = random.randint(0, max(0, L_-self.d))\n",
    "        sh = random.randint(0, max(0, H-self.h))\n",
    "        sw = random.randint(0, max(0, W-self.w))\n",
    "        vid[sd:sd+self.d, sh:sh+self.h, sw:sw+self.w] = 0\n",
    "        return vid\n",
    "\n",
    "def mixup_return_params(x, y_onehot, alpha=MIXUP_ALPHA):\n",
    "    if alpha <= 0:\n",
    "        B = x.size(0); idx = torch.arange(B, device=x.device); lam = 1.0\n",
    "        return x, y_onehot, lam, idx\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    idx = torch.randperm(x.size(0), device=x.device)\n",
    "    x_m = lam*x + (1-lam)*x[idx]\n",
    "    y_m = lam*y_onehot + (1-lam)*y_onehot[idx]\n",
    "    return x_m, y_m, float(lam), idx\n",
    "\n",
    "# ───────────── Loss ─────────────\n",
    "class SoftFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__(); self.alpha, self.gamma = alpha, gamma\n",
    "    def forward(self, logits, y_soft):\n",
    "        logp = F.log_softmax(logits,1)\n",
    "        p    = logp.exp()\n",
    "        ce   = -(y_soft * logp).sum(1)\n",
    "        pt   = (y_soft * p).sum(1)\n",
    "        return ( self.alpha * (1-pt)**self.gamma * ce ).mean()\n",
    "\n",
    "# ───────────── MixStyle ─────────────\n",
    "class MixStyle(nn.Module):\n",
    "    def __init__(self, p=0.3, α=0.1):\n",
    "        super().__init__(); self.p, self.α = p, α\n",
    "    def forward(self, x):\n",
    "        if not self.training or random.random()>self.p:\n",
    "            return x\n",
    "        B,C = x.shape\n",
    "        mu  = x.mean(1,keepdim=True)\n",
    "        sig = (x.var(1,keepdim=True)+1e-6).sqrt()\n",
    "        lm  = np.random.beta(self.α, self.α)\n",
    "        perm= torch.randperm(B,device=x.device)\n",
    "        mu2, sig2 = mu[perm], sig[perm]\n",
    "        x_norm = (x-mu)/sig\n",
    "        return x_norm*(lm*sig + (1-lm)*sig2) + (lm*mu + (1-lm)*mu2)\n",
    "\n",
    "# ───────────── Dataset ─────────────\n",
    "TEACHER_L10_COL = \"layer10_mean_path\"\n",
    "TEACHER_L11_COL = \"layer11_mean_path\"\n",
    "\n",
    "class MouthDS(Dataset):\n",
    "    def __init__(self,csv,L=32,augment=False,need_teacher=False):\n",
    "        df = pd.read_csv(csv).query('mouth_path.notna()').reset_index(drop=True)\n",
    "        self.df, self.L = df, L\n",
    "        self.l2i         = {l:i for i,l in enumerate(LANGS)}\n",
    "        self.spec        = SpecAug3D(OUT_H,OUT_W) if augment else None\n",
    "        self.randomerase = RandomErasing3D()      if augment else None\n",
    "        self.need_teacher = need_teacher\n",
    "\n",
    "        if self.need_teacher:\n",
    "            if TEACHER_L10_COL not in self.df.columns or TEACHER_L11_COL not in self.df.columns:\n",
    "                raise ValueError(\"Per KD L2 servono le colonne teacher: \"\n",
    "                                 f\"'{TEACHER_L10_COL}', '{TEACHER_L11_COL}' nel CSV.\")\n",
    "\n",
    "    def _align(self,a):\n",
    "        T0 = a.shape[0]\n",
    "        if T0>=self.L: idx = np.linspace(0,T0-1,self.L).astype(int)\n",
    "        else:          idx = np.concatenate([np.arange(T0), np.full(self.L-T0, T0-1)])\n",
    "        return a[idx]\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        r = self.df.iloc[i]\n",
    "        # ROI bocca\n",
    "        a = np.load(r.mouth_path,allow_pickle=True).astype('float32')/255.\n",
    "        if a.ndim==4 and a.shape[-1]==3: a = a.mean(-1)\n",
    "        a = self._align(a)\n",
    "        v = torch.from_numpy(a)\n",
    "        if self.spec:        v = self.spec(v)\n",
    "        if self.randomerase: v = self.randomerase(v)\n",
    "        v5 = v.unsqueeze(0).unsqueeze(0)\n",
    "        v5 = F.interpolate(v5, size=(self.L,OUT_H,OUT_W), mode='trilinear', align_corners=False)\n",
    "        x  = (v5 - 0.5)/0.5\n",
    "        x  = x.squeeze(0)                     # [1, L, H, W]\n",
    "        y  = torch.tensor(self.l2i[str(r.label).lower()],dtype=torch.long)\n",
    "\n",
    "        if not self.need_teacher:\n",
    "            return x, y\n",
    "\n",
    "        # teacher features (possono mancare → None)\n",
    "        l10 = l11 = None\n",
    "        p10 = r.get(TEACHER_L10_COL, None)\n",
    "        p11 = r.get(TEACHER_L11_COL, None)\n",
    "        if isinstance(p10,str) and os.path.exists(p10):\n",
    "            l10 = torch.from_numpy(np.load(p10)).float()\n",
    "        if isinstance(p11,str) and os.path.exists(p11):\n",
    "            l11 = torch.from_numpy(np.load(p11)).float()\n",
    "        return x, y, l10, l11\n",
    "\n",
    "def collate_with_optional_teacher(batch):\n",
    "    \"\"\"Restituisce (x,y,l10_list,l11_list) con elementi None mantenuti come placeholder.\"\"\"\n",
    "    xs, ys, l10s, l11s = [], [], [], []\n",
    "    for item in batch:\n",
    "        if len(item)==4:\n",
    "            x,y,l10,l11 = item\n",
    "        else:\n",
    "            x,y = item; l10=l11=None\n",
    "        xs.append(x); ys.append(y); l10s.append(l10); l11s.append(l11)\n",
    "    x = torch.stack(xs,0)\n",
    "    y = torch.stack(ys,0)\n",
    "    return x, y, l10s, l11s\n",
    "\n",
    "# ───────────── Model ─────────────\n",
    "class Student(nn.Module):\n",
    "    def __init__(self, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.backbone = r3d_18(weights=R3D_18_Weights.DEFAULT)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.mixstyle   = MixStyle(p=0.3, α=0.1)\n",
    "        self.proj_v     = nn.Sequential(nn.LayerNorm(512), nn.Linear(512, proj_dim))\n",
    "        self.head       = nn.Sequential(nn.LayerNorm(512), nn.Linear(512,256), nn.GELU(), nn.Dropout(0.1),\n",
    "                                        nn.Linear(256,len(LANGS)))\n",
    "    def forward(self, x):\n",
    "        x = x.repeat(1,3,1,1,1)\n",
    "        f = self.backbone(x)      # [B,512]\n",
    "        f = self.mixstyle(f)\n",
    "        logits = self.head(f)\n",
    "        z_v = self.proj_v(f)      # [B,proj]\n",
    "        return logits, f, z_v\n",
    "\n",
    "# ───────────── Sampler ─────────────\n",
    "def make_sampler(df):\n",
    "    cnt = df['label'].astype(str).str.lower().value_counts().reindex(LANGS,fill_value=0).to_dict()\n",
    "    w   = df['label'].astype(str).str.lower().map(lambda l:1.0/(cnt[l]+1e-6)).tolist()\n",
    "    return WeightedRandomSampler(w, num_samples=len(w), replacement=True)\n",
    "\n",
    "# ───────────── Loader builder ─────────────\n",
    "def build_loaders(train_csv, val_csv, need_teacher):\n",
    "    df_tr = pd.read_csv(train_csv)\n",
    "    dl_tr = DataLoader(MouthDS(train_csv, L, augment=True,  need_teacher=need_teacher),\n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       sampler=make_sampler(df_tr),\n",
    "                       num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
    "                       collate_fn=collate_with_optional_teacher)\n",
    "    dl_va = DataLoader(MouthDS(val_csv,   L, augment=False, need_teacher=False),\n",
    "                       batch_size=BATCH_SIZE, shuffle=False,\n",
    "                       num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "    return dl_tr, dl_va\n",
    "\n",
    "# ───────────── Eval helpers ─────────────\n",
    "def evaluate_manifest(csv_path, ckpt_path, title=\"\"):\n",
    "    model = Student().to(DEVICE)\n",
    "    state = torch.load(ckpt_path, map_location=DEVICE)\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    for m in model.backbone.modules():\n",
    "        if isinstance(m, nn.BatchNorm3d):\n",
    "            m.eval(); m.weight.requires_grad_(False); m.bias.requires_grad_(False)\n",
    "    model.eval()\n",
    "\n",
    "    dl = DataLoader(MouthDS(csv_path, L, augment=False, need_teacher=False),\n",
    "                    batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=PIN_MEMORY)\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for x,y in dl:\n",
    "            x = x.to(DEVICE); y = y.to(DEVICE)\n",
    "            logits, _, _ = model(x)\n",
    "            y_true += y.cpu().tolist()\n",
    "            y_pred += logits.argmax(1).cpu().tolist()\n",
    "    all_labels = list(range(len(LANGS)))\n",
    "    acc = accuracy_score(y_true, y_pred) if len(y_true) else 0.0\n",
    "    mf1 = macro_f1(y_true, y_pred)\n",
    "    cm  = confusion_matrix(y_true, y_pred, labels=all_labels) if len(y_true) else np.zeros((len(LANGS),len(LANGS)), dtype=int)\n",
    "    print(f\"\\n[{title}] N={len(y_true)}  Acc={acc:.3f}  Macro-F1={mf1:.3f}\")\n",
    "    print(pd.DataFrame(cm, index=LANGS, columns=LANGS))\n",
    "    return mf1, acc\n",
    "\n",
    "def split_domain_L1_L2(csv_path):\n",
    "    \"\"\"Genera split L1=it+es, L2=en per un dominio generico.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['label'] = df['label'].astype(str).str.lower()\n",
    "    l2 = df[df['label']=='en']\n",
    "    l1 = df[df['label'].isin(['it','es'])]\n",
    "    p_all = csv_path\n",
    "    p_l1  = os.path.splitext(csv_path)[0] + \"__L1_it_es.csv\"\n",
    "    p_l2  = os.path.splitext(csv_path)[0] + \"__L2_en.csv\"\n",
    "    l1[['mouth_path','label']].to_csv(p_l1, index=False)\n",
    "    l2[['mouth_path','label']].to_csv(p_l2, index=False)\n",
    "    return p_all, p_l1, p_l2\n",
    "\n",
    "def build_enL1_from_trainval(train_csv, val_csv, out_csv=\"reports/EN_L1_from_TRAINVAL.csv\"):\n",
    "    os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
    "    dft = pd.read_csv(train_csv); dfv = pd.read_csv(val_csv)\n",
    "    df  = pd.concat([dft, dfv], ignore_index=True)\n",
    "    df  = df[df['label'].astype(str).str.lower()=='en'][['mouth_path','label']].reset_index(drop=True)\n",
    "    if len(df)==0: raise ValueError(\"Nessuna riga 'en' trovata in TRAIN+VAL.\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    return out_csv\n",
    "\n",
    "def build_en_from_domain(csv_path, out_csv):\n",
    "    os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df[df['label'].astype(str).str.lower()=='en'][['mouth_path','label']].reset_index(drop=True)\n",
    "    if len(df)==0: raise ValueError(f\"Nessuna riga 'en' in {csv_path}\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    return out_csv\n",
    "\n",
    "def _collect_en_scores(csv_path, ckpt_path, run_dir=None, tag=\"\"):\n",
    "    model = Student().to(DEVICE)\n",
    "    state = torch.load(ckpt_path, map_location=DEVICE)\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    for m in model.backbone.modules():\n",
    "        if isinstance(m, nn.BatchNorm3d):\n",
    "            m.eval(); m.weight.requires_grad_(False); m.bias.requires_grad_(False)\n",
    "    model.eval()\n",
    "\n",
    "    dl = DataLoader(MouthDS(csv_path, L, augment=False, need_teacher=False),\n",
    "                    batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=PIN_MEMORY)\n",
    "    en_idx = LANGS.index('en')\n",
    "    probs, margins, preds, paths = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x,y in dl:\n",
    "            x = x.to(DEVICE)\n",
    "            logits,_,_ = model(x)\n",
    "            pr = F.softmax(logits,1)\n",
    "            p_en = pr[:, en_idx]\n",
    "            logit_en = logits[:, en_idx]\n",
    "            others = torch.stack([logits[:, LANGS.index('it')], logits[:, LANGS.index('es')]], dim=1)\n",
    "            margin = logit_en - others.max(dim=1).values\n",
    "            pred = pr.argmax(1)\n",
    "            probs.append(p_en.cpu().numpy()); margins.append(margin.cpu().numpy())\n",
    "            preds.extend((pred.cpu()==en_idx).tolist())\n",
    "            # (solo per export opzionale)\n",
    "    probs = np.concatenate(probs) if probs else np.array([])\n",
    "    margins = np.concatenate(margins) if margins else np.array([])\n",
    "    acc_en = float(np.mean(preds)) if len(preds) else 0.0\n",
    "    if run_dir is not None:\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "        pd.DataFrame({'p_en':probs,'margin':margins,'pred_is_en':preds}).to_csv(\n",
    "            os.path.join(run_dir, f\"{tag}__per_sample.csv\"), index=False)\n",
    "    return dict(N=len(probs), acc_en=acc_en, p_en=probs, margin=margins)\n",
    "\n",
    "def eval_enL1_vs_enL2(enL1_csv, enL2_csv, ckpt_path, run_dir=None):\n",
    "    sL1 = _collect_en_scores(enL1_csv, ckpt_path, run_dir, tag=\"EN_L1\")\n",
    "    sL2 = _collect_en_scores(enL2_csv, ckpt_path, run_dir, tag=\"EN_L2\")\n",
    "    if sL1['N'] and sL2['N']:\n",
    "        y  = np.concatenate([np.ones(sL1['N']), np.zeros(sL2['N'])])\n",
    "        sp = np.concatenate([sL1['p_en'], sL2['p_en']])\n",
    "        sm = np.concatenate([sL1['margin'], sL2['margin']])\n",
    "        auc_p = roc_auc_score(y, sp)\n",
    "        auc_m = roc_auc_score(y, sm)\n",
    "    else:\n",
    "        auc_p = float('nan'); auc_m = float('nan')\n",
    "    print(\"\\n=== EN L1 (Train+Val) vs EN L2 (Dominio dedicato) ===\")\n",
    "    print(f\"EN_L1: N={sL1['N']}  Acc(en)={sL1['acc_en']:.3f}  p(en) mean={np.mean(sL1['p_en']) if sL1['N'] else float('nan'):.3f}  margin mean={np.mean(sL1['margin']) if sL1['N'] else float('nan'):.3f}\")\n",
    "    print(f\"EN_L2: N={sL2['N']}  Acc(en)={sL2['acc_en']:.3f}  p(en) mean={np.mean(sL2['p_en']) if sL2['N'] else float('nan'):.3f}  margin mean={np.mean(sL2['margin']) if sL2['N'] else float('nan'):.3f}\")\n",
    "    print(f\"AUC p(en)={auc_p:.3f}   AUC margin={auc_m:.3f}\")\n",
    "    return {'Acc_en_L1': sL1['acc_en'], 'Acc_en_L2': sL2['acc_en'], 'AUC_p_en': float(auc_p),\n",
    "            'AUC_margin': float(auc_m), 'N_en_L1': sL1['N'], 'N_en_L2': sL2['N']}\n",
    "\n",
    "# ───────────── Utility: infer dims teacher una volta ─────────────\n",
    "def infer_teacher_dims(csv_path):\n",
    "    ds = MouthDS(csv_path, L, augment=False, need_teacher=True)\n",
    "    for i in range(len(ds)):\n",
    "        _, _, l10, l11 = ds[i]\n",
    "        if (isinstance(l10, torch.Tensor)) and (isinstance(l11, torch.Tensor)):\n",
    "            return int(l10.shape[0]), int(l11.shape[0])\n",
    "    return 512, 512  # fallback prudente\n",
    "\n",
    "# ───────────── Training di UNA RUN ─────────────\n",
    "def train_one_run(run_cfg):\n",
    "    RUN_ID         = run_cfg['run_id']\n",
    "\n",
    "    # L2 controls\n",
    "    USE_L2_ML      = run_cfg.get('USE_L2_ML', False)\n",
    "    LAMBDA_L2_TOP  = float(run_cfg.get('LAMBDA_L2_TOP', 0.0))\n",
    "    LAMBDA_L2_MID  = float(run_cfg.get('LAMBDA_L2_MID', 0.0))\n",
    "    L2_APPLY_PROB  = float(run_cfg.get('L2_APPLY_PROB', 1.0))   # p con cui applichi L2 per-sample\n",
    "    L2_SCHEDULE    = run_cfg.get('L2_SCHEDULE', 'const')        # 'const' | 'warmup'\n",
    "    L2_WARMUP_E    = int(run_cfg.get('L2_WARMUP_EPOCHS', 5))    # epoche warm-up\n",
    "    PROJ_DIM       = int(run_cfg.get('PROJ_DIM', 128))\n",
    "\n",
    "    need_teacher = USE_L2_ML\n",
    "    dl_tr, dl_va = build_loaders(TRAIN_CSV, VAL_CSV, need_teacher=need_teacher)\n",
    "\n",
    "    model = Student(proj_dim=PROJ_DIM).to(DEVICE)\n",
    "    # teste L2 (student side)\n",
    "    proj_l11_top = nn.Linear(512, PROJ_DIM).to(DEVICE)  # teacher top (→512 via adapter) → proj_dim\n",
    "    proj_l10_mid = nn.Linear(512, 512).to(DEVICE)       # teacher mid (→512 via adapter) → 512\n",
    "\n",
    "    # FREEZE BN\n",
    "    for m in model.backbone.modules():\n",
    "        if isinstance(m, nn.BatchNorm3d):\n",
    "            m.eval(); m.weight.requires_grad_(False); m.bias.requires_grad_(False)\n",
    "\n",
    "    # PRE-INIT ADAPTERS PRIMA dell'optimizer/scheduler\n",
    "    if USE_L2_ML:\n",
    "        d10, d11 = infer_teacher_dims(TRAIN_CSV)   # es. 768,768\n",
    "        mid_adapter = (nn.Identity().to(DEVICE) if d10 == 512 else nn.Linear(d10, 512).to(DEVICE))\n",
    "        top_adapter = (nn.Identity().to(DEVICE) if d11 == 512 else nn.Linear(d11, 512).to(DEVICE))\n",
    "    else:\n",
    "        mid_adapter = nn.Identity().to(DEVICE)\n",
    "        top_adapter = nn.Identity().to(DEVICE)\n",
    "\n",
    "    # Optimizer con TUTTI i param dentro (fix OneCycleLR)\n",
    "    params = list(model.parameters()) \\\n",
    "           + list(proj_l11_top.parameters()) \\\n",
    "           + list(proj_l10_mid.parameters())\n",
    "    if isinstance(top_adapter, nn.Linear): params += list(top_adapter.parameters())\n",
    "    if isinstance(mid_adapter, nn.Linear): params += list(mid_adapter.parameters())\n",
    "    opt   = AdamW(params, lr=LR, weight_decay=WD)\n",
    "\n",
    "    total = EPOCHS * len(dl_tr)\n",
    "    sched = OneCycleLR(opt, max_lr=MAX_LR, total_steps=total, pct_start=0.3,\n",
    "                       div_factor=DIV_FACTOR, final_div_factor=FINAL_DIV, anneal_strategy='cos')\n",
    "    crit  = SoftFocalLoss()\n",
    "\n",
    "    run_name = (f\"{RUN_ID}__L2{int(USE_L2_ML)}\"\n",
    "                f\"__top{LAMBDA_L2_TOP:g}__mid{LAMBDA_L2_MID:g}\"\n",
    "                f\"__p{L2_APPLY_PROB:g}__sched{L2_SCHEDULE}\")\n",
    "    ckpt_dir = os.path.join(\"ckpts\", run_name); os.makedirs(ckpt_dir, exist_ok=True)\n",
    "    best_path_student = os.path.join(ckpt_dir, \"best_student.pt\")\n",
    "    best_path_proj_l11 = os.path.join(ckpt_dir, \"best_proj_l11_top.pt\")\n",
    "    best_path_proj_l10 = os.path.join(ckpt_dir, \"best_proj_l10_mid.pt\")\n",
    "\n",
    "    last_path_student = os.path.join(ckpt_dir, \"last_student.pt\")\n",
    "    last_path_proj_l11 = os.path.join(ckpt_dir, \"last_proj_l11_top.pt\")\n",
    "    last_path_proj_l10 = os.path.join(ckpt_dir, \"last_proj_l10_mid.pt\")\n",
    "\n",
    "    run_dir = os.path.join(\"reports\", run_name); os.makedirs(run_dir, exist_ok=True)\n",
    "    epoch_logs = []\n",
    "    best_f1, patience = 0.0, 0\n",
    "\n",
    "    print(f\"\\n===== TRAIN {RUN_ID} | USE_L2_ML={USE_L2_ML}  top={LAMBDA_L2_TOP} mid={LAMBDA_L2_MID}  p={L2_APPLY_PROB}  sched={L2_SCHEDULE} =====\")\n",
    "\n",
    "    # helper per schedule\n",
    "    def eff_lambda(base, ep):\n",
    "        if L2_SCHEDULE == 'warmup' and L2_WARMUP_E>0:\n",
    "            return float(base) * min(1.0, ep / L2_WARMUP_E)\n",
    "        return float(base)\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train(); proj_l11_top.train(); proj_l10_mid.train()\n",
    "        if isinstance(top_adapter, nn.Module): top_adapter.train()\n",
    "        if isinstance(mid_adapter, nn.Module): mid_adapter.train()\n",
    "\n",
    "        sup_loss_sum = 0.0\n",
    "        l2_top_sum = 0.0\n",
    "        l2_mid_sum = 0.0\n",
    "        cover_cnt = 0\n",
    "        seen_cnt  = 0\n",
    "\n",
    "        for x, y, l10_list, l11_list in dl_tr:\n",
    "            x = x.to(DEVICE); y = y.to(DEVICE)\n",
    "\n",
    "            # mixup\n",
    "            y_onehot = F.one_hot(y, len(LANGS)).float()\n",
    "            x_m, y_m, lam, idx = mixup_return_params(x, y_onehot)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            amp_ctx = torch.cuda.amp.autocast if AMP_ENABLED else contextlib.nullcontext\n",
    "\n",
    "            with amp_ctx():\n",
    "                logits_m, f_m, z_v_m = model(x_m)\n",
    "                loss_sup = crit(logits_m, y_m)\n",
    "\n",
    "                # L2 losses\n",
    "                l2_top = torch.tensor(0.0, device=DEVICE)\n",
    "                l2_mid = torch.tensor(0.0, device=DEVICE)\n",
    "\n",
    "                if USE_L2_ML:\n",
    "                    logits_c, f_c, z_v_c = model(x)\n",
    "\n",
    "                    B = x.size(0)\n",
    "                    have = torch.tensor([ (isinstance(l10_list[i], torch.Tensor)) and (isinstance(l11_list[i], torch.Tensor))\n",
    "                                          for i in range(B) ],\n",
    "                                        device=DEVICE, dtype=torch.bool)\n",
    "                    seen_cnt += int(B); cover_cnt += int(have.sum().item())\n",
    "\n",
    "                    if have.any():\n",
    "                        idx_keep = torch.nonzero(have).squeeze(1).tolist()\n",
    "                        l10_t = torch.stack([l10_list[i2].to(DEVICE) for i2 in idx_keep], dim=0)  # [M, d10]\n",
    "                        l11_t = torch.stack([l11_list[i2].to(DEVICE) for i2 in idx_keep], dim=0)  # [M, d11]\n",
    "\n",
    "                        # adattatori verso 512\n",
    "                        l10_512 = mid_adapter(l10_t)  # [M,512]\n",
    "                        l11_512 = top_adapter(l11_t)  # [M,512]\n",
    "\n",
    "                        f_sel  = f_c[have]            # [M,512]\n",
    "                        z_sel  = z_v_c[have]          # [M,proj]\n",
    "                        pt     = proj_l11_top(l11_512)  # [M,proj]\n",
    "                        pm     = proj_l10_mid(l10_512)  # [M,512]\n",
    "\n",
    "                        # applicazione stocastica \"light\"\n",
    "                        if L2_APPLY_PROB < 1.0:\n",
    "                            keep = (torch.rand(f_sel.size(0), device=DEVICE) < L2_APPLY_PROB)\n",
    "                        else:\n",
    "                            keep = torch.ones(f_sel.size(0), device=DEVICE, dtype=torch.bool)\n",
    "\n",
    "                        if keep.any():\n",
    "                            z_n  = F.normalize(z_sel[keep], dim=1)\n",
    "                            pt_n = F.normalize(pt[keep],   dim=1)\n",
    "                            f_n  = F.normalize(f_sel[keep], dim=1)\n",
    "                            pm_n = F.normalize(pm[keep],    dim=1)\n",
    "\n",
    "                            lam_top = eff_lambda(LAMBDA_L2_TOP, ep)\n",
    "                            lam_mid = eff_lambda(LAMBDA_L2_MID, ep)\n",
    "\n",
    "                            l2_top = F.mse_loss(z_n, pt_n) if lam_top>0 else torch.tensor(0.0, device=DEVICE)\n",
    "                            l2_mid = F.mse_loss(f_n, pm_n) if lam_mid>0 else torch.tensor(0.0, device=DEVICE)\n",
    "\n",
    "                            loss_sup = loss_sup + lam_top * l2_top + lam_mid * l2_mid\n",
    "\n",
    "                loss = loss_sup\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_( list(model.parameters())\n",
    "                                           + list(proj_l11_top.parameters())\n",
    "                                           + list(proj_l10_mid.parameters())\n",
    "                                           + (list(top_adapter.parameters()) if isinstance(top_adapter, nn.Linear) else [])\n",
    "                                           + (list(mid_adapter.parameters()) if isinstance(mid_adapter, nn.Linear) else []),\n",
    "                                           1.0)\n",
    "            opt.step(); opt.zero_grad()\n",
    "            sched.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                sup_loss_sum += float(loss_sup.item())\n",
    "                l2_top_sum   += float(l2_top.item()) if isinstance(l2_top, torch.Tensor) else float(l2_top)\n",
    "                l2_mid_sum   += float(l2_mid.item()) if isinstance(l2_mid, torch.Tensor) else float(l2_mid)\n",
    "\n",
    "        # ── Validation ───────────────────────────\n",
    "        model.eval()\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for x,y in DataLoader(MouthDS(VAL_CSV, L, augment=False, need_teacher=False),\n",
    "                                  batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=PIN_MEMORY):\n",
    "                x = x.to(DEVICE); y = y.to(DEVICE)\n",
    "                logits,_,_ = model(x)\n",
    "                preds += logits.argmax(1).cpu().tolist()\n",
    "                gts   += y.cpu().tolist()\n",
    "        f1 = macro_f1(gts, preds)\n",
    "        cm = confusion_matrix(gts, preds, labels=list(range(len(LANGS))))\n",
    "        print(f\"Epoch {ep:02d}  Val-F1={f1:.3f}\")\n",
    "        print(pd.DataFrame(cm, index=LANGS, columns=LANGS))\n",
    "\n",
    "        # log per-epoca\n",
    "        loss_sup_mean = sup_loss_sum / max(1, len(dl_tr))\n",
    "        l2_top_mean   = l2_top_sum / max(1, len(dl_tr))\n",
    "        l2_mid_mean   = l2_mid_sum / max(1, len(dl_tr))\n",
    "        cover_rate    = (cover_cnt / max(1, seen_cnt)) * 100.0\n",
    "        epoch_logs.append(dict(epoch=ep, val_f1=float(f1),\n",
    "                               loss_sup_mean=loss_sup_mean,\n",
    "                               loss_l2_top_mean=l2_top_mean,\n",
    "                               loss_l2_mid_mean=l2_mid_mean,\n",
    "                               teacher_cover_pct=cover_rate))\n",
    "        pd.DataFrame(epoch_logs).to_csv(os.path.join(run_dir, \"epoch_log.csv\"), index=False)\n",
    "\n",
    "        # early stopping\n",
    "        if f1>best_f1:\n",
    "            best_f1, patience = f1, 0\n",
    "            torch.save(model.state_dict(), best_path_student)\n",
    "            torch.save(proj_l11_top.state_dict(), best_path_proj_l11)\n",
    "            torch.save(proj_l10_mid.state_dict(), best_path_proj_l10)\n",
    "            print(f\"  → New best: Val-F1={f1:.3f}  saved: {best_path_student}\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= PATIENCE:\n",
    "                print(\"Early stopping\"); break\n",
    "\n",
    "    # save last\n",
    "    torch.save(model.state_dict(), last_path_student)\n",
    "    torch.save(proj_l11_top.state_dict(), last_path_proj_l11)\n",
    "    torch.save(proj_l10_mid.state_dict(), last_path_proj_l10)\n",
    "\n",
    "    print(f\"Best Val-F1 (VAL) = {best_f1:.3f}\")\n",
    "    return best_path_student, run_name\n",
    "\n",
    "# ───────────── RUN SUITE + REPORT ─────────────\n",
    "def run_suite():\n",
    "    # Esperimenti focalizzati su L2 (nessuna EMB-KD/InfoNCE)\n",
    "    EXPERIMENTS = [\n",
    "        # Baseline — no KD\n",
    "        dict(run_id=\"B0_noKD\",\n",
    "             USE_L2_ML=False, LAMBDA_L2_TOP=0.0, LAMBDA_L2_MID=0.0,\n",
    "             L2_APPLY_PROB=0.0, L2_SCHEDULE='const'),\n",
    "\n",
    "        # L2 both (top+mid) — strong\n",
    "        dict(run_id=\"B1_L2_both\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=1.0, LAMBDA_L2_MID=0.5,\n",
    "             L2_APPLY_PROB=1.0, L2_SCHEDULE='const'),\n",
    "\n",
    "        # Solo top\n",
    "        dict(run_id=\"B2_L2_top_only\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=1.0, LAMBDA_L2_MID=0.0,\n",
    "             L2_APPLY_PROB=1.0, L2_SCHEDULE='const'),\n",
    "\n",
    "        # Solo mid\n",
    "        dict(run_id=\"B3_L2_mid_only\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=0.0, LAMBDA_L2_MID=0.5,\n",
    "             L2_APPLY_PROB=1.0, L2_SCHEDULE='const'),\n",
    "\n",
    "        # L2 “light” (warm-up + probabilità 0.3)\n",
    "        dict(run_id=\"B4_L2_both_light\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=0.5, LAMBDA_L2_MID=0.25,\n",
    "             L2_APPLY_PROB=0.3, L2_SCHEDULE='warmup', L2_WARMUP_EPOCHS=5),\n",
    "    ]\n",
    "\n",
    "    # ---- domini di test\n",
    "    # cross-domain su CROSS_DOMAIN_CSV\n",
    "    cross_all, cross_L1, cross_L2 = split_domain_L1_L2(CROSS_DOMAIN_CSV)\n",
    "\n",
    "    # EN_L1: EN da TRAIN+VAL (proxy madrelingua/L1)\n",
    "    enL1_csv = build_enL1_from_trainval(TRAIN_CSV, VAL_CSV,\n",
    "                                        out_csv=\"reports/EN_L1_from_TRAINVAL.csv\")\n",
    "    # EN_L2: EN dal dominio dedicato a L1/L2 (DIVERSO dal cross)\n",
    "    enL2_csv = build_en_from_domain(L1L2_DOMAIN_CSV,\n",
    "                                    out_csv=\"reports/EN_L2_from_L1L2DOMAIN.csv\")\n",
    "\n",
    "    if os.path.abspath(L1L2_DOMAIN_CSV) == os.path.abspath(CROSS_DOMAIN_CSV):\n",
    "        print(\"[ATTENZIONE] L1L2_DOMAIN_CSV coincide con CROSS_DOMAIN_CSV. \"\n",
    "              \"Per avere test separati, usa domini diversi.\")\n",
    "\n",
    "    results = []\n",
    "    for cfg in EXPERIMENTS:\n",
    "        best_ckpt, run_name = train_one_run(cfg)\n",
    "\n",
    "        # Eval IN-domain (VAL)\n",
    "        f1_in, acc_in = evaluate_manifest(VAL_CSV, best_ckpt, title=f\"{cfg['run_id']}__IN_VAL\")\n",
    "\n",
    "        # Eval CROSS (tutto, L1, L2) — dominio di cross scelto\n",
    "        f1_x_all, acc_x_all = evaluate_manifest(cross_all, best_ckpt, title=f\"{cfg['run_id']}__CROSS_all\")\n",
    "        f1_x_L1,  acc_x_L1  = evaluate_manifest(cross_L1,  best_ckpt, title=f\"{cfg['run_id']}__CROSS_L1_it_es\")\n",
    "        f1_x_L2,  acc_x_L2  = evaluate_manifest(cross_L2,  best_ckpt, title=f\"{cfg['run_id']}__CROSS_L2_en\")\n",
    "\n",
    "        # EN L1 (TRAIN+VAL) vs EN L2 (L1L2_DOMAIN_CSV)\n",
    "        run_dir = os.path.join(\"reports\", run_name)\n",
    "        en_stats = eval_enL1_vs_enL2(enL1_csv, enL2_csv, best_ckpt, run_dir=run_dir)\n",
    "\n",
    "        results.append({\n",
    "            \"run\": cfg['run_id'],\n",
    "            \"USE_L2_ML\": int(cfg['USE_L2_ML']),\n",
    "            \"L2_top\": cfg['LAMBDA_L2_TOP'],\n",
    "            \"L2_mid\": cfg['LAMBDA_L2_MID'],\n",
    "            \"L2_apply_prob\": cfg.get('L2_APPLY_PROB', 1.0),\n",
    "            \"L2_schedule\": cfg.get('L2_SCHEDULE', 'const'),\n",
    "            \"F1_in\":  float(f1_in),\n",
    "            \"F1_x_all\": float(f1_x_all),\n",
    "            \"F1_x_L1\": float(f1_x_L1),\n",
    "            \"F1_x_L2\": float(f1_x_L2),\n",
    "            \"Acc_en_L1\": en_stats['Acc_en_L1'],\n",
    "            \"Acc_en_L2\": en_stats['Acc_en_L2'],\n",
    "            \"AUC_p_en\":  en_stats['AUC_p_en'],\n",
    "            \"AUC_margin\": en_stats['AUC_margin'],\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    base = df.iloc[0]\n",
    "    df[\"ΔF1_in_vs_baseline\"]   = df[\"F1_in\"]    - base[\"F1_in\"]\n",
    "    df[\"ΔF1_x_vs_baseline\"]    = df[\"F1_x_all\"] - base[\"F1_x_all\"]\n",
    "    df[\"ΔAcc_en_L1_vs_base\"]   = df[\"Acc_en_L1\"] - base[\"Acc_en_L1\"]\n",
    "    df[\"ΔAcc_en_L2_vs_base\"]   = df[\"Acc_en_L2\"] - base[\"Acc_en_L2\"]\n",
    "\n",
    "    print(\"\\n================ L2-ONLY ABLATION SUMMARY ================\")\n",
    "    print(df.to_string(index=False))\n",
    "    os.makedirs(\"reports\", exist_ok=True)\n",
    "    out_csv = \"reports/kd_l2_only_ablation__crossA_enL2B.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"\\nSaved: {out_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_suite()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
