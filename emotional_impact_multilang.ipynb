{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420b14de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Session2 tot: 822  | con mouth_path già presente: 195\n",
      "[INFO] Mancano mouth_path per 627 video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estrazione fallback .npy: 100%|██████████| 627/627 [24:37<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] mouth_path disponibili: 822 / 822\n",
      "[SAVED] NEWEMODB/distillation_dataset_session2_merged_mouth.csv\n",
      "subject_id  order_in_subject         video_basename lang3 lang  emotion_id emotion_name                                     mouth_path\n",
      "       002                 0 002_m_022_0_0_EN_2.mp4    EN   en           0       neutro NEWEMODB/video_path/002_m_022_0_0_EN_2.mp4.npy\n",
      "       002                 1 002_m_022_0_0_IT_2.mp4    IT   it           0       neutro NEWEMODB/video_path/002_m_022_0_0_IT_2.mp4.npy\n",
      "       002                 2 002_m_022_0_1_EN_2.mp4    EN   en           1       rabbia NEWEMODB/video_path/002_m_022_0_1_EN_2.mp4.npy\n",
      "       002                 3 002_m_022_0_1_IT_2.mp4    IT   it           1       rabbia NEWEMODB/video_path/002_m_022_0_1_IT_2.mp4.npy\n",
      "       002                 4 002_m_022_0_2_EN_2.mp4    EN   en           2     disgusto NEWEMODB/video_path/002_m_022_0_2_EN_2.mp4.npy\n",
      "       002                 5 002_m_022_0_2_IT_2.mp4    IT   it           2     disgusto NEWEMODB/video_path/002_m_022_0_2_IT_2.mp4.npy\n",
      "       002                 6 002_m_022_0_3_EN_2.mp4    EN   en           3        paura NEWEMODB/video_path/002_m_022_0_3_EN_2.mp4.npy\n",
      "       002                 7 002_m_022_0_3_IT_2.mp4    IT   it           3        paura NEWEMODB/video_path/002_m_022_0_3_IT_2.mp4.npy\n",
      "       002                 8 002_m_022_0_4_EN_2.mp4    EN   en           4        gioia NEWEMODB/video_path/002_m_022_0_4_EN_2.mp4.npy\n",
      "       002                 9 002_m_022_0_4_IT_2.mp4    IT   it           4        gioia NEWEMODB/video_path/002_m_022_0_4_IT_2.mp4.npy\n",
      "       002                10 002_m_022_0_5_EN_2.mp4    EN   en           5    tristezza NEWEMODB/video_path/002_m_022_0_5_EN_2.mp4.npy\n",
      "       002                11 002_m_022_0_5_IT_2.mp4    IT   it           5    tristezza NEWEMODB/video_path/002_m_022_0_5_IT_2.mp4.npy\n",
      "       002                12 002_m_022_0_6_EN_2.mp4    EN   en           6     sorpresa NEWEMODB/video_path/002_m_022_0_6_EN_2.mp4.npy\n",
      "       002                13 002_m_022_0_6_IT_2.mp4    IT   it           6     sorpresa NEWEMODB/video_path/002_m_022_0_6_IT_2.mp4.npy\n",
      "       003                 0 003_f_021_0_0_EN_2.mp4    EN   en           0       neutro NEWEMODB/video_path/003_f_021_0_0_EN_2.mp4.npy\n",
      "       003                 1 003_f_021_0_0_IT_2.mp4    IT   it           0       neutro NEWEMODB/video_path/003_f_021_0_0_IT_2.mp4.npy\n",
      "       003                 2 003_f_021_0_1_EN_2.mp4    EN   en           1       rabbia NEWEMODB/video_path/003_f_021_0_1_EN_2.mp4.npy\n",
      "       003                 3 003_f_021_0_1_IT_2.mp4    IT   it           1       rabbia NEWEMODB/video_path/003_f_021_0_1_IT_2.mp4.npy\n",
      "       003                 4 003_f_021_0_2_EN_2.mp4    EN   en           2     disgusto NEWEMODB/video_path/003_f_021_0_2_EN_2.mp4.npy\n",
      "       003                 5 003_f_021_0_2_IT_2.mp4    IT   it           2     disgusto NEWEMODB/video_path/003_f_021_0_2_IT_2.mp4.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prendere distillation_dataset_session2 per tutti i video session 2\n",
    "# mettere emozioni come nuova colonna (ordinare per soggetto e fare hardlabeling delle emozioni)\n",
    "# merge con distillation_dataset_filtrato per prnedere i mouthpath di ita e sp\n",
    "# fare i mouth path dei restanti video inglesi\n",
    "\n",
    "# %% [markdown]\n",
    "# Pipeline di merge + estrazione mouth_path per EMODB Session 2\n",
    "# - Ordina i video per soggetto (XXX)\n",
    "# - Parsing di lingua (EN/IT/SP) ed emozione (0..6) dal filename\n",
    "# - Merge con distillation_dataset_filtrato per portare mouth_path\n",
    "# - Estrazione .npy per i rimanenti senza mouth_path (fallback semplice)\n",
    "# - Salva CSV finale con colonne aggiuntive\n",
    "\n",
    "# %%\n",
    "import os, re, sys, json, math, shutil, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import cv2\n",
    "except Exception:\n",
    "    cv2 = None\n",
    "    warnings.warn(\"OpenCV non disponibile: l'estrazione fallback verrà saltata.\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIG ===\n",
    "SESSION2_CSV   = \"NEWEMODB/distillation_dataset_session2.csv\"\n",
    "FILTRATO_CSV   = \"NEWEMODB/distillation_dataset_filtrato.csv\"\n",
    "OUT_CSV        = \"NEWEMODB/distillation_dataset_session2_merged_mouth.csv\"\n",
    "\n",
    "# Dove salvare i .npy per i video senza mouth_path\n",
    "MOUTH_BASE_DIR = Path(\"NEWEMODB/video_path\")   # segue lo schema del tuo filtrato\n",
    "MOUTH_BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Eseguire davvero l'estrazione dei mancanti (True/False)\n",
    "RUN_EXTRACTION = True\n",
    "\n",
    "# Parametri di estrazione fallback (se non usi il tuo extractor)\n",
    "FRAME_SIZE = 112        # lato (crop/rescale)\n",
    "MAX_FRAMES = None       # None = tutti i frame; oppure limita (es. 64)\n",
    "\n",
    "\n",
    "# === MAPPE ===\n",
    "EMOTION_MAP = {\n",
    "    0: \"neutro\",\n",
    "    1: \"rabbia\",\n",
    "    2: \"disgusto\",\n",
    "    3: \"paura\",\n",
    "    4: \"gioia\",\n",
    "    5: \"tristezza\",\n",
    "    6: \"sorpresa\",\n",
    "}\n",
    "\n",
    "LANG_MAP_3TO2 = {\"EN\": \"en\", \"IT\": \"it\", \"SP\": \"es\"}  # SP -> es\n",
    "\n",
    "\n",
    "# === HELPERS ===\n",
    "def parse_from_filename(path_str):\n",
    "    \"\"\"\n",
    "    Estrae:\n",
    "      - subject_id: prime 3 cifre del basename (es. 035)\n",
    "      - emotion_id: la cifra immediatamente prima della lingua (0..6)\n",
    "      - lang3: EN/IT/SP\n",
    "    Esempio: 035_m_022_0_3_EN_2.mp4  -> subject=035, emotion=3, lang3=EN\n",
    "             035_m_022_0_3_IT_2.mp4  -> subject=035, emotion=3, lang3=IT\n",
    "    \"\"\"\n",
    "    name = os.path.basename(path_str)\n",
    "    # subject_id: 3 cifre iniziali prima di \"_\"\n",
    "    m_subj = re.match(r\"^(\\d{3})_\", name)\n",
    "    subject_id = m_subj.group(1) if m_subj else \"UNK\"\n",
    "\n",
    "    # ..._(digit)_(EN|IT|SP)(_|\\.mp4)\n",
    "    m_e = re.search(r\"_(\\d)_(EN|IT|SP)(?:_|\\.|$)\", name)\n",
    "    if not m_e:\n",
    "        # backup: prova a trovare la coppia (EN|IT|SP) e prendere numero precedente\n",
    "        m_lang = re.search(r\"_(EN|IT|SP)(?:_|\\.|$)\", name)\n",
    "        emotion_id = None\n",
    "        lang3 = m_lang.group(1) if m_lang else \"UNK\"\n",
    "        # prova un'altra regex più permissiva\n",
    "        m_e2 = re.search(r\"_([0-6])_([A-Z]{2})(?:_|\\.|$)\", name)\n",
    "        if m_e2:\n",
    "            emotion_id = int(m_e2.group(1))\n",
    "            lang3 = m_e2.group(2)\n",
    "    else:\n",
    "        emotion_id = int(m_e.group(1))\n",
    "        lang3 = m_e.group(2)\n",
    "\n",
    "    lang2 = LANG_MAP_3TO2.get(lang3, \"unk\")\n",
    "    emotion_name = EMOTION_MAP.get(emotion_id, \"sconosciuta\")\n",
    "    return subject_id, emotion_id, emotion_name, lang3, lang2\n",
    "\n",
    "\n",
    "def subject_key(path_str):\n",
    "    \"\"\"Chiave soggetto per ordinamento e grouping (prime 3 cifre).\"\"\"\n",
    "    name = os.path.basename(path_str)\n",
    "    m = re.match(r\"^(\\d{3})_\", name)\n",
    "    return m.group(1) if m else \"UNK\"\n",
    "\n",
    "\n",
    "def video_sort_key(path_str):\n",
    "    \"\"\"Ordina in modo consistente i video per soggetto (basename alfabetico).\"\"\"\n",
    "    return os.path.basename(path_str)\n",
    "\n",
    "\n",
    "def ensure_parent_dir(p: Path):\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def extract_mouth_npy_fallback(video_path: str, out_npy: Path,\n",
    "                               frame_size: int = 112,\n",
    "                               max_frames: int | None = None) -> bool:\n",
    "    \"\"\"\n",
    "    Estrattore fallback *semplice*:\n",
    "      - Legge tutti i frame del video\n",
    "      - Center-crop quadrato + resize a (frame_size, frame_size)\n",
    "      - Concatena in array (T, H, W) in grayscale\n",
    "      - Salva .npy (float32 in [0,1])\n",
    "    Sostituiscilo con il tuo extractor (ROI bocca) se disponibile.\n",
    "    \"\"\"\n",
    "    if cv2 is None:\n",
    "        return False\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return False\n",
    "\n",
    "    frames = []\n",
    "    count = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        # BGR -> Gray\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        h, w = gray.shape\n",
    "        # center-crop quadrato\n",
    "        side = min(h, w)\n",
    "        y0 = (h - side) // 2\n",
    "        x0 = (w - side) // 2\n",
    "        crop = gray[y0:y0+side, x0:x0+side]\n",
    "        # resize\n",
    "        crop = cv2.resize(crop, (frame_size, frame_size), interpolation=cv2.INTER_AREA)\n",
    "        frames.append(crop)\n",
    "        count += 1\n",
    "        if max_frames is not None and count >= max_frames:\n",
    "            break\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        return False\n",
    "\n",
    "    arr = np.stack(frames, axis=0).astype(np.float32) / 255.0  # (T,H,W)\n",
    "    ensure_parent_dir(out_npy)\n",
    "    np.save(str(out_npy), arr)\n",
    "    return True\n",
    "\n",
    "\n",
    "# === LOAD ===\n",
    "df_s2 = pd.read_csv(SESSION2_CSV)\n",
    "df_f  = pd.read_csv(FILTRATO_CSV)\n",
    "\n",
    "# Normalizza chiave di merge: basename del video\n",
    "df_s2[\"video_basename\"] = df_s2[\"video_path\"].apply(os.path.basename)\n",
    "df_f[\"video_basename\"]  = df_f[\"video_path\"].apply(os.path.basename)\n",
    "\n",
    "# Parsing subject/emotion/lang da filename (session2)\n",
    "parsed = df_s2[\"video_path\"].apply(parse_from_filename)\n",
    "df_s2[[\"subject_id\",\"emotion_id\",\"emotion_name\",\"lang3\",\"lang\"]] = pd.DataFrame(parsed.tolist(), index=df_s2.index)\n",
    "\n",
    "# Ordina per soggetto e poi per basename\n",
    "df_s2 = df_s2.sort_values(by=[\"subject_id\", \"video_basename\"]).reset_index(drop=True)\n",
    "# Crea indice d'ordine per soggetto\n",
    "df_s2[\"order_in_subject\"] = df_s2.groupby(\"subject_id\").cumcount()\n",
    "\n",
    "# === MERGE con filtrato (per portare mouth_path dove c'è già) ===\n",
    "keep_cols_f = [\"video_basename\", \"mouth_path\"]\n",
    "df_f_keep = df_f[keep_cols_f].copy()\n",
    "\n",
    "df_merged = df_s2.merge(df_f_keep, on=\"video_basename\", how=\"left\")\n",
    "\n",
    "print(f\"[INFO] Session2 tot: {len(df_s2)}  | con mouth_path già presente: {df_merged['mouth_path'].notna().sum()}\")\n",
    "\n",
    "# === ESTRARRE i MANCANTI ===\n",
    "missing = df_merged[df_merged[\"mouth_path\"].isna()].copy()\n",
    "print(f\"[INFO] Mancano mouth_path per {len(missing)} video.\")\n",
    "\n",
    "if RUN_EXTRACTION and len(missing) > 0:\n",
    "    if cv2 is None:\n",
    "        print(\"[WARN] OpenCV non disponibile, salto estrazione fallback.\")\n",
    "    else:\n",
    "        for i, row in tqdm(missing.iterrows(), total=len(missing), desc=\"Estrazione fallback .npy\"):\n",
    "            vpath = row[\"video_path\"]\n",
    "            out_npy = MOUTH_BASE_DIR / f\"{os.path.basename(vpath)}.npy\"\n",
    "            ok = extract_mouth_npy_fallback(vpath, out_npy,\n",
    "                                            frame_size=FRAME_SIZE,\n",
    "                                            max_frames=MAX_FRAMES)\n",
    "            if ok:\n",
    "                df_merged.loc[row.name, \"mouth_path\"] = str(out_npy)\n",
    "            else:\n",
    "                df_merged.loc[row.name, \"mouth_path\"] = np.nan  # lascia NaN se fallito\n",
    "\n",
    "# Report finale\n",
    "have_mouth = df_merged[\"mouth_path\"].notna().sum()\n",
    "print(f\"[DONE] mouth_path disponibili: {have_mouth} / {len(df_merged)}\")\n",
    "\n",
    "# Salva CSV finale\n",
    "df_merged.to_csv(OUT_CSV, index=False)\n",
    "print(f\"[SAVED] {OUT_CSV}\")\n",
    "\n",
    "# Anteprima per verifica\n",
    "display_cols = [\"subject_id\",\"order_in_subject\",\"video_basename\",\"lang3\",\"lang\",\"emotion_id\",\"emotion_name\",\"mouth_path\"]\n",
    "print(df_merged[display_cols].head(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3fc193e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESUME] Recuperati 267 mouth_path da OUT_CSV.\n",
      "[PRECHECK] Riconosciuti 0 mouth_path già presenti su disco.\n",
      "[INFO] IT ready=98 | SP ready=97 | EN ready=72, EN missing=359 | N_target=97\n",
      "[SELECT] EN da estrarre: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estrazione EN selezionati: 100%|██████████| 25/25 [36:15<00:00, 87.02s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] NEWEMODB/distillation_dataset_session2_merged_mouth.csv\n",
      "[INFO] N_final (bilanciato) = 97\n",
      "[SAVED] NEWEMODB/distillation_dataset_session2_balanced.csv  (IT=97, SP=97, EN=97)\n",
      "lang3\n",
      "EN    97\n",
      "IT    97\n",
      "SP    97\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os, re, json, warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "SESSION2_CSV    = \"NEWEMODB/distillation_dataset_session2.csv\"\n",
    "FILTRATO_CSV    = \"NEWEMODB/distillation_dataset_filtrato.csv\"\n",
    "OUT_CSV         = \"NEWEMODB/distillation_dataset_session2_merged_mouth.csv\"\n",
    "OUT_BALANCED    = \"NEWEMODB/distillation_dataset_session2_balanced.csv\"\n",
    "\n",
    "MOUTH_BASE_DIR  = Path(\"NEWEMODB/video_mouth\")\n",
    "MOUTH_BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RUN_EXTRACTION      = True\n",
    "RNG_SEED            = 1337\n",
    "\n",
    "# Resume & checkpoint\n",
    "RESUME_FROM_OUTCSV  = True          # se OUT_CSV esiste, riusa mouth_path già calcolati\n",
    "PRECHECK_FILESYSTEM = True          # se esiste già l'NPY previsto, lo prende\n",
    "CHECKPOINT_EVERY    = 1             # salva OUT_CSV ogni N video elaborati (1 = ogni video)\n",
    "\n",
    "# Estrazione ROI veloce\n",
    "ROI_SIZE            = 96\n",
    "DETECT_MAX_WIDTH    = 512\n",
    "REDETECT_EVERY      = 10\n",
    "TRACKER_TYPE        = \"MOSSE\"\n",
    "MAX_MISSES_BEFORE_REDETECT = 3\n",
    "DEVICE              = \"cpu\"         # \"cuda\" se disponibile\n",
    "\n",
    "# Fallback center-crop\n",
    "FALLBACK_FRAME_SIZE = 96\n",
    "FALLBACK_MAX_FRAMES = None\n",
    "\n",
    "# =========================\n",
    "# MAPPE\n",
    "# =========================\n",
    "EMOTION_MAP = {0:\"neutro\",1:\"rabbia\",2:\"disgusto\",3:\"paura\",4:\"gioia\",5:\"tristezza\",6:\"sorpresa\"}\n",
    "LANG_MAP_3TO2 = {\"EN\":\"en\",\"IT\":\"it\",\"SP\":\"es\"}\n",
    "\n",
    "# =========================\n",
    "# OPENCV / FACE_ALIGNMENT (opzionali)\n",
    "# =========================\n",
    "try:\n",
    "    import cv2\n",
    "except Exception:\n",
    "    cv2 = None\n",
    "    warnings.warn(\"OpenCV non disponibile: estrazione ROI e fallback disabilitate.\")\n",
    "\n",
    "try:\n",
    "    import face_alignment\n",
    "    from face_alignment import FaceAlignment\n",
    "    FA_AVAILABLE = True\n",
    "except Exception:\n",
    "    face_alignment = None\n",
    "    FaceAlignment = None\n",
    "    FA_AVAILABLE = False\n",
    "\n",
    "# =========================\n",
    "# HELPER: parse filename\n",
    "# =========================\n",
    "def parse_from_filename(path_str):\n",
    "    name = os.path.basename(path_str)\n",
    "    m_subj = re.match(r\"^(\\d{3})_\", name)\n",
    "    subject_id = m_subj.group(1) if m_subj else \"UNK\"\n",
    "\n",
    "    m_e = re.search(r\"_(\\d)_(EN|IT|SP)(?:_|\\.|$)\", name)\n",
    "    emotion_id = int(m_e.group(1)) if m_e else None\n",
    "    lang3 = m_e.group(2) if m_e else (re.search(r\"_(EN|IT|SP)(?:_|\\.|$)\", name).group(1) if re.search(r\"_(EN|IT|SP)(?:_|\\.|$)\", name) else \"UNK\")\n",
    "\n",
    "    lang2 = LANG_MAP_3TO2.get(lang3, \"unk\")\n",
    "    emotion_name = EMOTION_MAP.get(emotion_id, \"sconosciuta\")\n",
    "    return subject_id, emotion_id, emotion_name, lang3, lang2\n",
    "\n",
    "def ensure_parent_dir(p: Path):\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def atomic_save_csv(df: pd.DataFrame, path: str):\n",
    "    tmp = f\"{path}.tmp\"\n",
    "    df.to_csv(tmp, index=False)\n",
    "    os.replace(tmp, path)\n",
    "\n",
    "# =========================\n",
    "# ROI veloce (FA + tracker)\n",
    "# =========================\n",
    "def create_tracker(tracker_type=\"MOSSE\"):\n",
    "    if cv2 is None: return None\n",
    "    try:\n",
    "        t = tracker_type.upper()\n",
    "        if t == \"MOSSE\":\n",
    "            if hasattr(cv2, \"legacy\") and hasattr(cv2.legacy, \"TrackerMOSSE_create\"): return cv2.legacy.TrackerMOSSE_create()\n",
    "            if hasattr(cv2, \"TrackerMOSSE_create\"): return cv2.TrackerMOSSE_create()\n",
    "        if t == \"KCF\":\n",
    "            if hasattr(cv2, \"legacy\") and hasattr(cv2.legacy, \"TrackerKCF_create\"): return cv2.legacy.TrackerKCF_create()\n",
    "            if hasattr(cv2, \"TrackerKCF_create\"): return cv2.TrackerKCF_create()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def clip_bbox(b, w_frame, h_frame):\n",
    "    x, y, w, h = b\n",
    "    x1 = max(0, int(round(x))); y1 = max(0, int(round(y)))\n",
    "    x2 = min(w_frame, int(round(x + w))); y2 = min(h_frame, int(round(y + h)))\n",
    "    if x2 <= x1 or y2 <= y1: return None\n",
    "    return [x1, y1, x2 - x1, y2 - y1]\n",
    "\n",
    "def crop_and_resize_rgb(frame_rgb, bbox, size=ROI_SIZE):\n",
    "    H, W = frame_rgb.shape[:2]\n",
    "    cb = clip_bbox(bbox, W, H)\n",
    "    if cb is None: return None\n",
    "    x, y, w, h = cb\n",
    "    crop = frame_rgb[y:y+h, x:x+w]\n",
    "    if crop.size == 0: return None\n",
    "    return cv2.resize(crop, (size, size), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def landmarks_mouth_bbox(landmarks, scale=1.4):\n",
    "    pts = landmarks[48:68]; cx, cy = pts.mean(axis=0)\n",
    "    w = max(np.ptp(pts[:,0]), np.ptp(pts[:,1])) * scale\n",
    "    return [float(cx - w/2), float(cy - w/2), float(w), float(w)]\n",
    "\n",
    "def detect_landmarks_fast(fa, frame_rgb, max_width=DETECT_MAX_WIDTH):\n",
    "    if max_width and frame_rgb.shape[1] > max_width:\n",
    "        scale = max_width / frame_rgb.shape[1]\n",
    "        small = cv2.resize(frame_rgb, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "        lm = fa.get_landmarks(small)\n",
    "        if lm is None or len(lm) == 0: return None\n",
    "        return lm[0] / scale\n",
    "    lm = fa.get_landmarks(frame_rgb)\n",
    "    if lm is None or len(lm) == 0: return None\n",
    "    return lm[0]\n",
    "\n",
    "def extract_mouth_roi_fast(vpath, segments, out_npy_path, fa):\n",
    "    if cv2 is None: return False\n",
    "    cap = cv2.VideoCapture(vpath)\n",
    "    if not cap.isOpened(): return False\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 25\n",
    "    rois, tracker, misses, last_bbox = [], None, 0, None\n",
    "\n",
    "    for (start_s, end_s) in segments:\n",
    "        start_f = max(0, int(start_s * fps)); end_f = max(start_f, int(end_s * fps))\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_f); frame_idx = 0\n",
    "        while True:\n",
    "            pos = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "            if pos >= end_f: break\n",
    "            ok, frame_bgr = cap.read()\n",
    "            if not ok: break\n",
    "            frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            need_redetect = ((frame_idx % REDETECT_EVERY == 0) or (tracker is None) or (misses >= MAX_MISSES_BEFORE_REDETECT))\n",
    "            bbox = None\n",
    "            if not need_redetect and tracker is not None:\n",
    "                ok_track, tracked = tracker.update(frame_rgb)\n",
    "                if ok_track: bbox = list(tracked); last_bbox = bbox; misses = 0\n",
    "                else: misses += 1\n",
    "\n",
    "            if bbox is None:\n",
    "                lm = detect_landmarks_fast(fa, frame_rgb, DETECT_MAX_WIDTH)\n",
    "                if lm is not None:\n",
    "                    bbox = landmarks_mouth_bbox(lm, 1.4); last_bbox = bbox; misses = 0\n",
    "                    tracker = create_tracker(TRACKER_TYPE)\n",
    "                    if tracker is not None:\n",
    "                        cb = clip_bbox(bbox, frame_rgb.shape[1], frame_rgb.shape[0])\n",
    "                        if cb is not None:\n",
    "                            x, y, w, h = cb; tracker.init(frame_rgb, (x, y, w, h))\n",
    "                else:\n",
    "                    if last_bbox is not None: bbox = last_bbox; misses += 1\n",
    "                    else: frame_idx += 1; continue\n",
    "\n",
    "            roi = crop_and_resize_rgb(frame_rgb, bbox, ROI_SIZE)\n",
    "            if roi is not None: rois.append(roi)\n",
    "            frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    if not rois: return False\n",
    "    arr = np.stack(rois, axis=0).astype(np.uint8)\n",
    "    ensure_parent_dir(Path(out_npy_path)); np.save(out_npy_path, arr)\n",
    "    return True\n",
    "\n",
    "# =========================\n",
    "# FALLBACK center-crop\n",
    "# =========================\n",
    "def extract_center_crop(vpath, out_npy_path, frame_size=FALLBACK_FRAME_SIZE, max_frames=FALLBACK_MAX_FRAMES):\n",
    "    if cv2 is None: return False\n",
    "    cap = cv2.VideoCapture(vpath)\n",
    "    if not cap.isOpened(): return False\n",
    "    rois, count = [], 0\n",
    "    while True:\n",
    "        ok, frame_bgr = cap.read()\n",
    "        if not ok: break\n",
    "        h, w = frame_bgr.shape[:2]; side = min(h, w)\n",
    "        y0 = (h - side)//2; x0 = (w - side)//2\n",
    "        crop = frame_bgr[y0:y0+side, x0:x0+side]\n",
    "        crop = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "        crop = cv2.resize(crop, (frame_size, frame_size), interpolation=cv2.INTER_AREA)\n",
    "        rois.append(crop); count += 1\n",
    "        if max_frames is not None and count >= max_frames: break\n",
    "    cap.release()\n",
    "    if not rois: return False\n",
    "    arr = np.stack(rois, axis=0).astype(np.uint8)\n",
    "    ensure_parent_dir(Path(out_npy_path)); np.save(out_npy_path, arr)\n",
    "    return True\n",
    "\n",
    "# =========================\n",
    "# SELEZIONE EN: metà 0xx, metà 1xx (fallback)\n",
    "# =========================\n",
    "def select_en_for_needed(df_en_missing, n_needed, seed=RNG_SEED):\n",
    "    if n_needed <= 0 or df_en_missing.empty:\n",
    "        return df_en_missing.iloc[0:0]\n",
    "    sids = df_en_missing[\"subject_id\"].astype(str).fillna(\"\")\n",
    "    g0 = df_en_missing[sids.str.startswith(\"0\")]\n",
    "    g1 = df_en_missing[sids.str.startswith(\"1\")]\n",
    "    others = df_en_missing[~(sids.str.startswith(\"0\") | sids.str.startswith(\"1\"))]\n",
    "\n",
    "    n0 = n_needed // 2\n",
    "    n1 = n_needed - n0\n",
    "\n",
    "    sel0 = g0.sample(n=min(n0, len(g0)), random_state=seed) if len(g0)>0 else g0.iloc[0:0]\n",
    "    rem = n_needed - len(sel0)\n",
    "    sel1 = g1.sample(n=min(rem, len(g1)), random_state=seed+1) if len(g1)>0 else g1.iloc[0:0]\n",
    "    rem = n_needed - len(sel0) - len(sel1)\n",
    "    selO = others.sample(n=min(rem, len(others)), random_state=seed+2) if rem>0 and len(others)>0 else others.iloc[0:0]\n",
    "\n",
    "    return pd.concat([sel0, sel1, selO], axis=0)\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "def main():\n",
    "    # Load\n",
    "    df_s2 = pd.read_csv(SESSION2_CSV)\n",
    "    df_f  = pd.read_csv(FILTRATO_CSV)\n",
    "\n",
    "    # Chiave comune: basename\n",
    "    df_s2[\"video_basename\"] = df_s2[\"video_path\"].apply(os.path.basename)\n",
    "    df_f[\"video_basename\"]  = df_f[\"video_path\"].apply(os.path.basename)\n",
    "\n",
    "    # Parse (hardlabel)\n",
    "    parsed_s2 = df_s2[\"video_path\"].apply(parse_from_filename)\n",
    "    df_s2[[\"subject_id\",\"emotion_id\",\"emotion_name\",\"lang3\",\"lang\"]] = pd.DataFrame(parsed_s2.tolist(), index=df_s2.index)\n",
    "\n",
    "    # Ordina e indice\n",
    "    df_s2 = df_s2.sort_values(by=[\"subject_id\",\"video_basename\"]).reset_index(drop=True)\n",
    "    df_s2[\"order_in_subject\"] = df_s2.groupby(\"subject_id\").cumcount()\n",
    "\n",
    "    # Importa mouth_path da filtrato SOLO per IT/SP\n",
    "    parsed_f = df_f[\"video_path\"].apply(parse_from_filename)\n",
    "    df_f[[\"f_subject_id\",\"f_emotion_id\",\"f_emotion_name\",\"f_lang3\",\"f_lang\"]] = pd.DataFrame(parsed_f.tolist(), index=df_f.index)\n",
    "    df_f_keep = df_f[df_f[\"f_lang\"].isin([\"it\",\"es\"])][[\"video_basename\",\"mouth_path\"]].copy()\n",
    "\n",
    "    # Merge\n",
    "    df_merged = df_s2.merge(df_f_keep, on=\"video_basename\", how=\"left\")\n",
    "\n",
    "    # ==== RESUME: unisci mouth_path già salvati in OUT_CSV, se presenti ====\n",
    "    if RESUME_FROM_OUTCSV and os.path.exists(OUT_CSV):\n",
    "        try:\n",
    "            prev = pd.read_csv(OUT_CSV, usecols=[\"video_basename\",\"mouth_path\"])\n",
    "            prev = prev.dropna(subset=[\"mouth_path\"])\n",
    "            df_merged = df_merged.merge(prev, on=\"video_basename\", how=\"left\", suffixes=(\"\", \"_prev\"))\n",
    "            df_merged[\"mouth_path\"] = df_merged[\"mouth_path\"].combine_first(df_merged[\"mouth_path_prev\"])\n",
    "            df_merged.drop(columns=[c for c in df_merged.columns if c.endswith(\"_prev\")], inplace=True)\n",
    "            print(f\"[RESUME] Recuperati {prev['mouth_path'].notna().sum()} mouth_path da OUT_CSV.\")\n",
    "        except Exception as e:\n",
    "            print(f\"[RESUME] OUT_CSV presente ma non leggibile per resume: {e}\")\n",
    "\n",
    "    # ==== PRECHECK: se il file NPY atteso esiste già, usalo ====\n",
    "    if PRECHECK_FILESYSTEM:\n",
    "        miss_idx = df_merged[\"mouth_path\"].isna()\n",
    "        if miss_idx.any():\n",
    "            exp_paths = MOUTH_BASE_DIR / (df_merged.loc[miss_idx, \"subject_id\"].astype(str) + \"_\" + df_merged.loc[miss_idx, \"video_basename\"] + \".npy\")\n",
    "            exists = exp_paths.apply(lambda p: p if os.path.exists(p) else None)\n",
    "            filled = exists.notna().sum()\n",
    "            df_merged.loc[miss_idx, \"mouth_path\"] = df_merged.loc[miss_idx].apply(\n",
    "                lambda r: str(MOUTH_BASE_DIR / f\"{r['subject_id']}_{r['video_basename']}.npy\")\n",
    "                if os.path.exists(MOUTH_BASE_DIR / f\"{r['subject_id']}_{r['video_basename']}.npy\") else np.nan,\n",
    "                axis=1\n",
    "            )\n",
    "            print(f\"[PRECHECK] Riconosciuti {filled} mouth_path già presenti su disco.\")\n",
    "\n",
    "    # Conteggi disponibili IT/SP (già con mouth_path importati)\n",
    "    it_ready = df_merged[(df_merged[\"lang3\"]==\"IT\") & (df_merged[\"mouth_path\"].notna())]\n",
    "    sp_ready = df_merged[(df_merged[\"lang3\"]==\"SP\") & (df_merged[\"mouth_path\"].notna())]\n",
    "    n_it = len(it_ready); n_sp = len(sp_ready)\n",
    "\n",
    "    # EN pronti e mancanti\n",
    "    en_ready   = df_merged[(df_merged[\"lang3\"]==\"EN\") & (df_merged[\"mouth_path\"].notna())]\n",
    "    en_missing = df_merged[(df_merged[\"lang3\"]==\"EN\") & (df_merged[\"mouth_path\"].isna())]\n",
    "    n_en_ready = len(en_ready); n_en_missing = len(en_missing)\n",
    "\n",
    "    # Capacità EN (pronti + estraibili)\n",
    "    en_capacity = n_en_ready + n_en_missing\n",
    "\n",
    "    # Target per lingua\n",
    "    N_target = min(n_it, n_sp, en_capacity)\n",
    "    print(f\"[INFO] IT ready={n_it} | SP ready={n_sp} | EN ready={n_en_ready}, EN missing={n_en_missing} | N_target={N_target}\")\n",
    "\n",
    "    # Quanti EN servono ancora\n",
    "    en_needed = max(0, N_target - n_en_ready)\n",
    "\n",
    "    # Selezione EN mancanti (split 0xx/1xx)\n",
    "    sel_en_to_extract = select_en_for_needed(en_missing, en_needed, seed=RNG_SEED)\n",
    "    print(f\"[SELECT] EN da estrarre: {len(sel_en_to_extract)}\")\n",
    "\n",
    "    # Init FaceAlignment se serve\n",
    "    fa = None\n",
    "    if RUN_EXTRACTION and len(sel_en_to_extract)>0 and FA_AVAILABLE and cv2 is not None:\n",
    "        fa = FaceAlignment(face_alignment.LandmarksType.TWO_D, device=DEVICE)\n",
    "\n",
    "    # Estrazione con checkpointing\n",
    "    processed_since_save = 0\n",
    "    if RUN_EXTRACTION and len(sel_en_to_extract)>0 and cv2 is not None:\n",
    "        for idx, row in tqdm(sel_en_to_extract.iterrows(), total=len(sel_en_to_extract), desc=\"Estrazione EN selezionati\"):\n",
    "            vpath = row[\"video_path\"]\n",
    "            out_npy = MOUTH_BASE_DIR / f\"{row['subject_id']}_{os.path.basename(vpath)}.npy\"\n",
    "\n",
    "            # segments (se presenti)\n",
    "            segments = []\n",
    "            seg_str = row.get(\"segments\", None)\n",
    "            if isinstance(seg_str, str) and seg_str.strip():\n",
    "                try:\n",
    "                    segments = json.loads(seg_str)\n",
    "                except Exception:\n",
    "                    segments = []\n",
    "\n",
    "            ok = False\n",
    "            if fa is not None and segments:\n",
    "                ok = extract_mouth_roi_fast(vpath, segments, str(out_npy), fa)\n",
    "            elif fa is not None and not segments:\n",
    "                ok = extract_mouth_roi_fast(vpath, [(0, 1e9)], str(out_npy), fa)\n",
    "            else:\n",
    "                ok = extract_center_crop(vpath, str(out_npy),\n",
    "                                         frame_size=FALLBACK_FRAME_SIZE,\n",
    "                                         max_frames=FALLBACK_MAX_FRAMES)\n",
    "            if ok:\n",
    "                df_merged.loc[row.name, \"mouth_path\"] = str(out_npy)\n",
    "\n",
    "            # checkpoint\n",
    "            processed_since_save += 1\n",
    "            if processed_since_save >= CHECKPOINT_EVERY:\n",
    "                atomic_save_csv(df_merged, OUT_CSV)\n",
    "                processed_since_save = 0\n",
    "\n",
    "    # Salvataggio finale completo (OUT_CSV)\n",
    "    atomic_save_csv(df_merged, OUT_CSV)\n",
    "    print(f\"[SAVED] {OUT_CSV}\")\n",
    "\n",
    "    # Aggiorna pronti dopo eventuale estrazione\n",
    "    it_ready = df_merged[(df_merged[\"lang3\"]==\"IT\") & (df_merged[\"mouth_path\"].notna())]\n",
    "    sp_ready = df_merged[(df_merged[\"lang3\"]==\"SP\") & (df_merged[\"mouth_path\"].notna())]\n",
    "    en_ready = df_merged[(df_merged[\"lang3\"]==\"EN\") & (df_merged[\"mouth_path\"].notna())]\n",
    "\n",
    "    # N_final bilanciato\n",
    "    N_final = min(len(it_ready), len(sp_ready), len(en_ready))\n",
    "    print(f\"[INFO] N_final (bilanciato) = {N_final}\")\n",
    "\n",
    "    # Sottoinsieme bilanciato\n",
    "    cols_front = [\"subject_id\",\"order_in_subject\",\"video_basename\",\"lang3\",\"lang\",\"emotion_id\",\"emotion_name\",\"mouth_path\",\"video_path\"]\n",
    "    other_cols = [c for c in df_merged.columns if c not in cols_front]\n",
    "\n",
    "    it_bal = it_ready.sample(n=N_final, random_state=RNG_SEED) if len(it_ready)>N_final else it_ready.copy()\n",
    "    sp_bal = sp_ready.sample(n=N_final, random_state=RNG_SEED+1) if len(sp_ready)>N_final else sp_ready.copy()\n",
    "    en_bal = en_ready.sample(n=N_final, random_state=RNG_SEED+2) if len(en_ready)>N_final else en_ready.copy()\n",
    "\n",
    "    df_balanced = pd.concat([it_bal, sp_bal, en_bal], axis=0).copy()\n",
    "    atomic_save_csv(df_balanced[cols_front + other_cols], OUT_BALANCED)\n",
    "    print(f\"[SAVED] {OUT_BALANCED}  (IT={len(it_bal)}, SP={len(sp_bal)}, EN={len(en_bal)})\")\n",
    "\n",
    "    # Anteprima\n",
    "    print(df_balanced.groupby(\"lang3\").size().rename(\"count\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "040bc777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Totale clip: 291\n",
      "lang  emotion    group\n",
      "en    disgusto   UNK      10\n",
      "      gioia      UNK      15\n",
      "      neutro     UNK      13\n",
      "      paura      UNK      12\n",
      "      rabbia     UNK      18\n",
      "      sorpresa   UNK      17\n",
      "      tristezza  UNK      12\n",
      "es    disgusto   UNK      14\n",
      "      gioia      UNK      14\n",
      "      neutro     UNK      14\n",
      "      paura      UNK      13\n",
      "      rabbia     UNK      14\n",
      "      sorpresa   UNK      14\n",
      "      tristezza  UNK      14\n",
      "it    disgusto   UNK      13\n",
      "      gioia      UNK      14\n",
      "      neutro     UNK      14\n",
      "      paura      UNK      14\n",
      "      rabbia     UNK      14\n",
      "      sorpresa   UNK      14\n",
      "      tristezza  UNK      14\n",
      "\n",
      "[TRAIN] n=184 | subjects=36\n",
      "lang  emotion    group\n",
      "en    disgusto   UNK       5\n",
      "      gioia      UNK       8\n",
      "      neutro     UNK       9\n",
      "      paura      UNK       6\n",
      "      rabbia     UNK      12\n",
      "      sorpresa   UNK      12\n",
      "      tristezza  UNK       7\n",
      "es    disgusto   UNK      10\n",
      "      gioia      UNK      10\n",
      "      neutro     UNK      10\n",
      "      paura      UNK       9\n",
      "      rabbia     UNK      10\n",
      "      sorpresa   UNK      10\n",
      "      tristezza  UNK      10\n",
      "it    disgusto   UNK       8\n",
      "      gioia      UNK       8\n",
      "      neutro     UNK       8\n",
      "      paura      UNK       8\n",
      "      rabbia     UNK       8\n",
      "      sorpresa   UNK       8\n",
      "      tristezza  UNK       8\n",
      "\n",
      "[VAL] n=58 | subjects=9\n",
      "lang  emotion    group\n",
      "en    disgusto   UNK      1\n",
      "      gioia      UNK      3\n",
      "      neutro     UNK      1\n",
      "      paura      UNK      1\n",
      "      rabbia     UNK      5\n",
      "      sorpresa   UNK      3\n",
      "      tristezza  UNK      3\n",
      "es    disgusto   UNK      3\n",
      "      gioia      UNK      3\n",
      "      neutro     UNK      3\n",
      "      paura      UNK      3\n",
      "      rabbia     UNK      3\n",
      "      sorpresa   UNK      3\n",
      "      tristezza  UNK      3\n",
      "it    disgusto   UNK      2\n",
      "      gioia      UNK      3\n",
      "      neutro     UNK      3\n",
      "      paura      UNK      3\n",
      "      rabbia     UNK      3\n",
      "      sorpresa   UNK      3\n",
      "      tristezza  UNK      3\n",
      "\n",
      "[TEST] n=49 | subjects=12\n",
      "lang  emotion    group\n",
      "en    disgusto   UNK      4\n",
      "      gioia      UNK      4\n",
      "      neutro     UNK      3\n",
      "      paura      UNK      5\n",
      "      rabbia     UNK      1\n",
      "      sorpresa   UNK      2\n",
      "      tristezza  UNK      2\n",
      "es    disgusto   UNK      1\n",
      "      gioia      UNK      1\n",
      "      neutro     UNK      1\n",
      "      paura      UNK      1\n",
      "      rabbia     UNK      1\n",
      "      sorpresa   UNK      1\n",
      "      tristezza  UNK      1\n",
      "it    disgusto   UNK      3\n",
      "      gioia      UNK      3\n",
      "      neutro     UNK      3\n",
      "      paura      UNK      3\n",
      "      rabbia     UNK      3\n",
      "      sorpresa   UNK      3\n",
      "      tristezza  UNK      3\n",
      "\n",
      "[SAVED] Full-Emotion splits in: splits_session2/full_F0\n",
      "\n",
      "[NEUTRAL-TRAIN] n=27 | subjects=22\n",
      "lang  emotion  group\n",
      "en    neutro   UNK       9\n",
      "es    neutro   UNK      10\n",
      "it    neutro   UNK       8\n",
      "\n",
      "[NEUTRAL-VAL] n=7 | subjects=6\n",
      "lang  emotion  group\n",
      "en    neutro   UNK      1\n",
      "es    neutro   UNK      3\n",
      "it    neutro   UNK      3\n",
      "\n",
      "[NEUTRAL-TEST] n=49 | subjects=12\n",
      "lang  emotion    group\n",
      "en    disgusto   UNK      4\n",
      "      gioia      UNK      4\n",
      "      neutro     UNK      3\n",
      "      paura      UNK      5\n",
      "      rabbia     UNK      1\n",
      "      sorpresa   UNK      2\n",
      "      tristezza  UNK      2\n",
      "es    disgusto   UNK      1\n",
      "      gioia      UNK      1\n",
      "      neutro     UNK      1\n",
      "      paura      UNK      1\n",
      "      rabbia     UNK      1\n",
      "      sorpresa   UNK      1\n",
      "      tristezza  UNK      1\n",
      "it    disgusto   UNK      3\n",
      "      gioia      UNK      3\n",
      "      neutro     UNK      3\n",
      "      paura      UNK      3\n",
      "      rabbia     UNK      3\n",
      "      sorpresa   UNK      3\n",
      "      tristezza  UNK      3\n",
      "\n",
      "[SAVED] Neutral-Only splits in: splits_session2/neutral_only_F0\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# === STEP 1: Split subject-disjoint (Full-Emotion + Neutral-Only) ===\n",
    "\n",
    "import os, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "# ====== CONFIG ======\n",
    "DATASET_CSV = \"NEWEMODB/distillation_dataset_session2_balanced.csv\"  # cambia se il nome è diverso\n",
    "OUT_DIR = Path(\"splits_session2\")\n",
    "N_SPLITS = 5\n",
    "FOLD = 0     # puoi scegliere 0..N_SPLITS-1\n",
    "VAL_RATIO = 0.2  # percentuale del train che va a val (sempre subject-disjoint)\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# colonne attese: video_path, audio_path, lang, emotion (o emotion_id), subject_id, group, mouth_path\n",
    "df = pd.read_csv(DATASET_CSV)\n",
    "\n",
    "# Sanity check minimi\n",
    "need_cols = [\"video_path\",\"audio_path\",\"lang\",\"subject_id\"]\n",
    "for c in need_cols:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Colonna mancante nel CSV: {c}\")\n",
    "\n",
    "# Normalizza colonne emotion\n",
    "if \"emotion\" not in df.columns and \"emotion_id\" in df.columns:\n",
    "    df[\"emotion\"] = df[\"emotion_id\"].map({\n",
    "        0:\"neutro\",1:\"rabbia\",2:\"disgusto\",3:\"paura\",4:\"gioia\",5:\"tristezza\",6:\"sorpresa\"\n",
    "    })\n",
    "elif \"emotion\" in df.columns and \"emotion_id\" not in df.columns:\n",
    "    EMO2ID = {\"neutro\":0,\"rabbia\":1,\"disgusto\":2,\"paura\":3,\"gioia\":4,\"tristezza\":5,\"sorpresa\":6}\n",
    "    df[\"emotion_id\"] = df[\"emotion\"].map(EMO2ID)\n",
    "\n",
    "# normalizza lang a {en,it,es}\n",
    "df[\"lang\"] = df[\"lang\"].str.lower().replace({\"sp\":\"es\",\"es\":\"es\",\"it\":\"it\",\"en\":\"en\"})\n",
    "\n",
    "# normalizza group se presente\n",
    "if \"group\" not in df.columns:\n",
    "    df[\"group\"] = \"UNK\"\n",
    "df[\"group\"] = df[\"group\"].astype(str)\n",
    "\n",
    "# Chiave di stratificazione (lingua × emozione × gruppo)\n",
    "df[\"cell\"] = df[\"lang\"] + \"__\" + df[\"emotion\"].astype(str) + \"__\" + df[\"group\"]\n",
    "\n",
    "# Svuota righe con info critiche mancanti\n",
    "df = df.dropna(subset=[\"subject_id\",\"lang\",\"emotion\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"[INFO] Totale clip:\", len(df))\n",
    "print(df[[\"lang\",\"emotion\",\"group\"]].value_counts().sort_index().to_string())\n",
    "\n",
    "# ====== SPLIT PER SOGGETTO (subject-disjoint) ======\n",
    "sgkf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "splits = list(sgkf.split(df, y=df[\"cell\"], groups=df[\"subject_id\"]))\n",
    "train_idx, test_idx = splits[FOLD]\n",
    "train_df, test_df = df.iloc[train_idx].copy(), df.iloc[test_idx].copy()\n",
    "\n",
    "# Dal train ricaviamo una VAL per soggetto\n",
    "# (prendiamo una quota di soggetti dal train per fare val)\n",
    "train_subjects = train_df[\"subject_id\"].unique()\n",
    "n_val_subj = max(1, int(round(len(train_subjects)*VAL_RATIO)))\n",
    "rng = np.random.RandomState(123)\n",
    "val_subjects = set(rng.choice(train_subjects, size=n_val_subj, replace=False))\n",
    "val_mask = train_df[\"subject_id\"].isin(val_subjects)\n",
    "val_df = train_df[val_mask].copy()\n",
    "train_df = train_df[~val_mask].copy()\n",
    "\n",
    "def summarize(tag, ddf):\n",
    "    print(f\"\\n[{tag}] n={len(ddf)} | subjects={ddf.subject_id.nunique()}\")\n",
    "    print(ddf[[\"lang\",\"emotion\",\"group\"]].value_counts().sort_index().to_string())\n",
    "\n",
    "summarize(\"TRAIN\", train_df)\n",
    "summarize(\"VAL\",   val_df)\n",
    "summarize(\"TEST\",  test_df)\n",
    "\n",
    "# Salva Full-Emotion\n",
    "full_dir = OUT_DIR / f\"full_F{FOLD}\"\n",
    "full_dir.mkdir(parents=True, exist_ok=True)\n",
    "train_df.to_csv(full_dir/\"train.csv\", index=False)\n",
    "val_df.to_csv(full_dir/\"val.csv\", index=False)\n",
    "test_df.to_csv(full_dir/\"test.csv\", index=False)\n",
    "print(\"\\n[SAVED] Full-Emotion splits in:\", full_dir)\n",
    "\n",
    "# ====== VISTA NEUTRAL-ONLY ======\n",
    "neutral_train = train_df[train_df[\"emotion_id\"]==0].copy()\n",
    "neutral_val   = val_df[val_df[\"emotion_id\"]==0].copy()\n",
    "neutral_test  = test_df.copy()   # test rimane misto: serve per 'cross-emotion'\n",
    "\n",
    "summarize(\"NEUTRAL-TRAIN\", neutral_train)\n",
    "summarize(\"NEUTRAL-VAL\",   neutral_val)\n",
    "summarize(\"NEUTRAL-TEST\",  neutral_test)\n",
    "\n",
    "neutral_dir = OUT_DIR / f\"neutral_only_F{FOLD}\"\n",
    "neutral_dir.mkdir(parents=True, exist_ok=True)\n",
    "neutral_train.to_csv(neutral_dir/\"train.csv\", index=False)\n",
    "neutral_val.to_csv(neutral_dir/\"val.csv\", index=False)\n",
    "neutral_test.to_csv(neutral_dir/\"test.csv\", index=False)\n",
    "print(\"\\n[SAVED] Neutral-Only splits in:\", neutral_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8d26d307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= FIND/OR-TRAIN + DIAGNOSE on split = neutral_only_F0 =======\n",
      "[INFO] Non trovata/valida 'E0_noKD' per split neutral_only_F0. Avvio training...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'splits_session2/neutral_only_F0/train_midtop.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 253\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# 1) baseline\u001b[39;00m\n\u001b[1;32m    252\u001b[0m BASELINE_CFG \u001b[38;5;241m=\u001b[39m EXPS[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 253\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m get_or_train(tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE0_noKD\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39msplit, cfg_if_missing\u001b[38;5;241m=\u001b[39mBASELINE_CFG)\n\u001b[1;32m    254\u001b[0m base_sum \u001b[38;5;241m=\u001b[39m _load_summary_from_report(base_dir)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# raccogli righe summary per questo split\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[60], line 65\u001b[0m, in \u001b[0;36mget_or_train\u001b[0;34m(tag, split, cfg_if_missing)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReport per tag=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m split=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m non trovata o incompleta e nessuna cfg fornita per riallenare.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Non trovata/valida \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m per split \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Avvio training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _train_run_and_get_dir(cfg_if_missing, split)\n",
      "Cell \u001b[0;32mIn[60], line 38\u001b[0m, in \u001b[0;36m_train_run_and_get_dir\u001b[0;34m(cfg, split)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train_run_and_get_dir\u001b[39m(cfg: \u001b[38;5;28mdict\u001b[39m, split: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Allena una run e ritorna la cartella report corrispondente.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     best_ckpt, run_name, summary \u001b[38;5;241m=\u001b[39m train_one_run_emotion(cfg, split_key\u001b[38;5;241m=\u001b[39msplit)\n\u001b[1;32m     39\u001b[0m     run_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreports\u001b[39m\u001b[38;5;124m\"\u001b[39m, run_name)\n\u001b[1;32m     40\u001b[0m     _ensure_test_files(run_dir)\n",
      "Cell \u001b[0;32mIn[21], line 392\u001b[0m, in \u001b[0;36mtrain_one_run_emotion\u001b[0;34m(run_cfg, split_key)\u001b[0m\n\u001b[1;32m    389\u001b[0m EMO_WEIGHTS_MODE   \u001b[38;5;241m=\u001b[39m run_cfg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEMO_WEIGHTS_MODE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 'default' | 'none'\u001b[39;00m\n\u001b[1;32m    391\u001b[0m need_teacher \u001b[38;5;241m=\u001b[39m USE_L2_ML\n\u001b[0;32m--> 392\u001b[0m dl_tr, dl_va \u001b[38;5;241m=\u001b[39m build_loaders(TRAIN_CSV, VAL_CSV, need_teacher\u001b[38;5;241m=\u001b[39mneed_teacher)\n\u001b[1;32m    394\u001b[0m model \u001b[38;5;241m=\u001b[39m Student(proj_dim\u001b[38;5;241m=\u001b[39mPROJ_DIM)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# Projection heads\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[21], line 284\u001b[0m, in \u001b[0;36mbuild_loaders\u001b[0;34m(train_csv, val_csv, need_teacher)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_loaders\u001b[39m(train_csv, val_csv, need_teacher):\n\u001b[0;32m--> 284\u001b[0m     df_tr \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(train_csv)\n\u001b[1;32m    285\u001b[0m     dl_tr \u001b[38;5;241m=\u001b[39m DataLoader(MouthDSEmotion(train_csv, L, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  need_teacher\u001b[38;5;241m=\u001b[39mneed_teacher),\n\u001b[1;32m    286\u001b[0m                        batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m    287\u001b[0m                        sampler\u001b[38;5;241m=\u001b[39mmake_sampler(df_tr),\n\u001b[1;32m    288\u001b[0m                        num_workers\u001b[38;5;241m=\u001b[39mNUM_WORKERS,\n\u001b[1;32m    289\u001b[0m                        pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    290\u001b[0m                        collate_fn\u001b[38;5;241m=\u001b[39mcollate_with_optional_teacher)\n\u001b[1;32m    291\u001b[0m     dl_va \u001b[38;5;241m=\u001b[39m DataLoader(MouthDSEmotion(val_csv,   L, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, need_teacher\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    292\u001b[0m                        batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    293\u001b[0m                        num_workers\u001b[38;5;241m=\u001b[39mNUM_WORKERS, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    294\u001b[0m                        collate_fn\u001b[38;5;241m=\u001b[39mcollate_with_optional_teacher)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'splits_session2/neutral_only_F0/train_midtop.csv'"
     ]
    }
   ],
   "source": [
    "# === FIND-OR-TRAIN baseline + diagnosi per-emozione (no gate) + McNemar + summary Δ ===\n",
    "# Richiede che 'train_one_run_emotion' sia già definita nel notebook.\n",
    "\n",
    "import os, glob, json, math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "REPORTS_DIR = Path(\"reports2\")\n",
    "REPORTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --------- Utility: find / check / train ---------\n",
    "def _find_latest_report_dir(tag: str, split: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Cerca l'ultima cartella report che matcha tag e split.\n",
    "    Esempio: reports/E0_noKD__full_F0__...__gatenone__emonone/\n",
    "    \"\"\"\n",
    "    pats = [f\"{REPORTS_DIR}/*{tag}*__{split}\", f\"{REPORTS_DIR}/**/*{tag}*__{split}\"]\n",
    "    cands = []\n",
    "    for p in pats:\n",
    "        cands += glob.glob(p, recursive=True)\n",
    "    if not cands:\n",
    "        return None\n",
    "    cands.sort(key=lambda p: os.path.getmtime(p))\n",
    "    return cands[-1]\n",
    "\n",
    "def _ensure_test_files(run_dir: str):\n",
    "    \"\"\"Verifica che i file minimi del test esistano nella cartella di report.\"\"\"\n",
    "    req = [\"TEST__per_emotion.csv\", \"TEST__preds.csv\"]\n",
    "    miss = [f for f in req if not os.path.exists(os.path.join(run_dir, f))]\n",
    "    if miss:\n",
    "        raise FileNotFoundError(f\"Mancano file {miss} in {run_dir}.\")\n",
    "\n",
    "def _train_run_and_get_dir(cfg: dict, split: str) -> str:\n",
    "    \"\"\"Allena una run e ritorna la cartella report corrispondente.\"\"\"\n",
    "    best_ckpt, run_name, summary = train_one_run_emotion(cfg, split_key=split)\n",
    "    run_dir = os.path.join(\"reports\", run_name)\n",
    "    _ensure_test_files(run_dir)\n",
    "    return run_dir\n",
    "\n",
    "def get_or_train(tag: str, split: str, cfg_if_missing: dict | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Prova a trovare la run 'tag' per 'split' in reports/.\n",
    "    - Se esiste e ha i file TEST* richiesti -> ritorna la cartella.\n",
    "    - Se NON esiste (o mancano i file) e hai passato cfg_if_missing -> allena e ritorna.\n",
    "    - Se NON esiste (o mancano i file) e NON hai cfg -> lancia un errore esplicito.\n",
    "    \"\"\"\n",
    "    run_dir = _find_latest_report_dir(tag, split)\n",
    "    if run_dir is not None:\n",
    "        try:\n",
    "            _ensure_test_files(run_dir)\n",
    "            print(f\"[OK] Trovata run {tag} per split {split}: {run_dir}\")\n",
    "            return run_dir\n",
    "        except FileNotFoundError:\n",
    "            print(f\"[WARN] Run trovata ma incompleta: {run_dir}\")\n",
    "\n",
    "    if cfg_if_missing is None:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Report per tag='{tag}' split='{split}' non trovata o incompleta e nessuna cfg fornita per riallenare.\"\n",
    "        )\n",
    "\n",
    "    print(f\"[INFO] Non trovata/valida '{tag}' per split {split}. Avvio training...\")\n",
    "    return _train_run_and_get_dir(cfg_if_missing, split)\n",
    "\n",
    "# --------- Letture e summary fallback ---------\n",
    "def _load_summary_from_report(run_dir: str) -> dict:\n",
    "    \"\"\"\n",
    "    Prova a leggere summary.json; se manca, lo ricostruisce da TEST__preds.csv e TEST__per_emotion.csv.\n",
    "    \"\"\"\n",
    "    summ_path = os.path.join(run_dir, \"summary.json\")\n",
    "    if os.path.exists(summ_path):\n",
    "        with open(summ_path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    preds_csv  = os.path.join(run_dir, \"TEST__preds.csv\")\n",
    "    peremo_csv = os.path.join(run_dir, \"TEST__per_emotion.csv\")\n",
    "    if not (os.path.exists(preds_csv) and os.path.exists(peremo_csv)):\n",
    "        raise FileNotFoundError(f\"Mancano file per ricostruire il summary in {run_dir}\")\n",
    "\n",
    "    dfp = pd.read_csv(preds_csv)\n",
    "    y_true = dfp[\"y\"].values\n",
    "    y_pred = dfp[\"yhat\"].values\n",
    "    acc  = float(accuracy_score(y_true, y_pred))\n",
    "    mf1  = float(f1_score(y_true, y_pred, average=\"macro\"))\n",
    "\n",
    "    pe = pd.read_csv(peremo_csv)\n",
    "    esi = float(pe[\"macro_f1\"].std()) if \"macro_f1\" in pe.columns else float(\"nan\")\n",
    "    worst_acc = float(pe[\"acc\"].min()) if \"acc\" in pe.columns else float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"best_val_macro_f1\": float(\"nan\"),\n",
    "        \"test_macro_f1\": mf1,\n",
    "        \"test_acc\": acc,\n",
    "        \"test_esi\": esi,\n",
    "        \"test_worst_emotion_acc\": worst_acc,\n",
    "    }\n",
    "\n",
    "# --------- McNemar (exact) + FDR ---------\n",
    "def _mcnemar_exact_p(b: int, c: int) -> float:\n",
    "    \"\"\"\n",
    "    Test di McNemar (binomiale esatto, two-sided) sui discordanti b (base giusta, kd sbaglia) e c (base sbaglia, kd giusta).\n",
    "    \"\"\"\n",
    "    n = b + c\n",
    "    if n == 0:\n",
    "        return float(\"nan\")\n",
    "    from math import comb\n",
    "    k = min(b, c)\n",
    "    tail = sum(comb(n, i) for i in range(0, k + 1))\n",
    "    p = 2.0 * tail * (0.5 ** n)\n",
    "    return float(min(p, 1.0))\n",
    "\n",
    "def _fdr_bh(pvals, alpha=0.05):\n",
    "    pv = np.array([np.nan if (p is None) else p for p in pvals], dtype=float)\n",
    "    m = np.sum(~np.isnan(pv))\n",
    "    if m == 0:\n",
    "        return np.array([False] * len(pv))\n",
    "    order = np.argsort(pv)\n",
    "    rank = np.empty_like(order); rank[order] = np.arange(1, len(pv) + 1)\n",
    "    thresh = alpha * rank / m\n",
    "    sig = pv <= thresh\n",
    "    max_k = np.where(sig)[0].max() if sig.any() else -1\n",
    "    if max_k >= 0:\n",
    "        sig = np.zeros_like(sig, dtype=bool); sig[order[:max_k+1]] = True\n",
    "    return sig\n",
    "\n",
    "def _read_preds_df(run_dir: str) -> pd.DataFrame:\n",
    "    p = os.path.join(run_dir, \"TEST__preds.csv\")\n",
    "    df = pd.read_csv(p)\n",
    "    req = [\"y\", \"yhat\", \"emotion\", \"prob_en\", \"prob_it\", \"prob_es\"]\n",
    "    miss = [c for c in req if c not in df.columns]\n",
    "    if miss:\n",
    "        raise ValueError(f\"Mancano colonne in {p}: {miss}\")\n",
    "    return df\n",
    "\n",
    "def mcnemar_by_emotion(base_dir: str, kd_dir: str, split: str, tag: str) -> str:\n",
    "    \"\"\"\n",
    "    Costruisce la tabella McNemar per-emozione su KD vs baseline e la salva in posthoc__<split>/mcnemar_<tag>.csv\n",
    "    \"\"\"\n",
    "    base_df = _read_preds_df(base_dir)\n",
    "    kd_df   = _read_preds_df(kd_dir)\n",
    "\n",
    "    # sanity: stesso numero di righe\n",
    "    assert len(base_df) == len(kd_df), \"Le predizioni baseline e KD hanno lunghezze diverse.\"\n",
    "\n",
    "    rows = []\n",
    "    for emo, g_base in base_df.groupby(\"emotion\"):\n",
    "        g_kd = kd_df.iloc[g_base.index]  # allineamento per indice (stesso ordine del test loader)\n",
    "        y    = g_base[\"y\"].values\n",
    "        base_correct = (g_base[\"yhat\"].values == y)\n",
    "        kd_correct   = (g_kd[\"yhat\"].values   == y)\n",
    "        b = int(((base_correct == 1) & (kd_correct == 0)).sum())  # base giusta, kd sbaglia\n",
    "        c = int(((base_correct == 0) & (kd_correct == 1)).sum())  # base sbaglia, kd giusta\n",
    "        p = _mcnemar_exact_p(b, c)\n",
    "\n",
    "        acc_b = accuracy_score(y, g_base[\"yhat\"].values) if len(y) else np.nan\n",
    "        acc_k = accuracy_score(y, g_kd[\"yhat\"].values)   if len(y) else np.nan\n",
    "        f1_b  = f1_score(y, g_base[\"yhat\"].values, average=\"macro\") if len(y) else np.nan\n",
    "        f1_k  = f1_score(y, g_kd[\"yhat\"].values,   average=\"macro\") if len(y) else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"emotion\": emo,\n",
    "            \"N\": int(len(g_base)),\n",
    "            \"b\": b, \"c\": c, \"mcnemar_p\": p,\n",
    "            \"acc_base\": acc_b, \"acc_kd\": acc_k, \"ΔAcc\": acc_k - acc_b,\n",
    "            \"F1_base\": f1_b, \"F1_kd\": f1_k, \"ΔF1\": f1_k - f1_b,\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(rows).sort_values(\"emotion\")\n",
    "    out[\"FDR_sig_0.05\"] = _fdr_bh(out[\"mcnemar_p\"].values, alpha=0.05)\n",
    "\n",
    "    posthoc_dir = REPORTS_DIR / f\"posthoc__{split}\"\n",
    "    posthoc_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_csv = str(posthoc_dir / f\"mcnemar_{tag}.csv\")\n",
    "    out.to_csv(out_csv, index=False)\n",
    "\n",
    "    print(f\"[saved] {out_csv}\")\n",
    "    return out_csv\n",
    "\n",
    "# --------- Diagnosi per-emozione KD vs baseline (metriche + Δ + ECE opzionale) ---------\n",
    "def diagnose_by_dirs(base_dir: str, kd_dir: str, split: str, tag: str) -> str:\n",
    "    \"\"\"Confronta KD vs baseline per-emozione partendo da due cartelle report esplicite.\"\"\"\n",
    "    _ensure_test_files(base_dir)\n",
    "    _ensure_test_files(kd_dir)\n",
    "\n",
    "    pe_base = pd.read_csv(os.path.join(base_dir, \"TEST__per_emotion.csv\"))\n",
    "    pe_kd   = pd.read_csv(os.path.join(kd_dir,   \"TEST__per_emotion.csv\"))\n",
    "\n",
    "    m = pe_kd.merge(pe_base, on=\"emotion\", suffixes=(\"_kd\",\"_base\"))\n",
    "    m[\"ΔAcc\"] = m[\"acc_kd\"] - m[\"acc_base\"]\n",
    "    m[\"ΔF1\"]  = m[\"macro_f1_kd\"] - m[\"macro_f1_base\"]\n",
    "\n",
    "    # ECE (se disponibili)\n",
    "    ece_b = os.path.join(base_dir, \"TEST__ece_per_emotion.csv\")\n",
    "    ece_k = os.path.join(kd_dir,   \"TEST__ece_per_emotion.csv\")\n",
    "    if os.path.exists(ece_b) and os.path.exists(ece_k):\n",
    "        eb = pd.read_csv(ece_b).rename(columns={\"ECE\":\"ECE_base\"})\n",
    "        ek = pd.read_csv(ece_k).rename(columns={\"ECE\":\"ECE_kd\"})\n",
    "        m = m.merge(ek, on=\"emotion\").merge(eb, on=\"emotion\")\n",
    "        m[\"ΔECE\"] = m[\"ECE_kd\"] - m[\"ECE_base\"]\n",
    "\n",
    "    cols = [\"emotion\",\"acc_base\",\"acc_kd\",\"ΔAcc\",\"macro_f1_base\",\"macro_f1_kd\",\"ΔF1\"]\n",
    "    if \"ΔECE\" in m.columns:\n",
    "        cols += [\"ECE_base\",\"ECE_kd\",\"ΔECE\"]\n",
    "    m = m[cols].sort_values(\"ΔAcc\")  # peggiori in alto\n",
    "\n",
    "    out_csv = f\"{REPORTS_DIR}/diagnose__{tag}__{split}.csv\"\n",
    "    m.to_csv(out_csv, index=False)\n",
    "    print(f\"\\n== {tag} vs baseline ({split}) — peggiori ΔAcc in alto ==\")\n",
    "    print(m.to_string(index=False))\n",
    "    print(f\"[saved] {out_csv}\")\n",
    "    return out_csv\n",
    "\n",
    "# --------- MAIN: tutte le run richieste, train-if-missing + diagnosi + mcnemar + summary ---------\n",
    "if __name__ == \"__main__\":\n",
    "    # Puoi mettere anche [\"neutral_only_F0\", \"full_F0\"]\n",
    "    SPLITS = [\"neutral_only_F0\"]\n",
    "\n",
    "    # Tutte le run (NO GATE) che vuoi coprire\n",
    "    EXPS = [\n",
    "        # baseline\n",
    "        dict(run_id=\"E0_noKD\",\n",
    "             USE_L2_ML=False, LAMBDA_L2_TOP=0.0, LAMBDA_L2_MID=0.0,\n",
    "             L2_APPLY_PROB=0.0, L2_SCHEDULE='const',\n",
    "             CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "        # KD top+mid (base)\n",
    "        dict(run_id=\"E1b_noGate_both_base\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=1.0, LAMBDA_L2_MID=0.5,\n",
    "             L2_APPLY_PROB=1.0, L2_SCHEDULE='const',\n",
    "             CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "        # KD top-only\n",
    "        dict(run_id=\"E4_noGate_top_only\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=1.0, LAMBDA_L2_MID=0.0,\n",
    "             L2_APPLY_PROB=1.0, L2_SCHEDULE='const',\n",
    "             CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "        # KD light\n",
    "        dict(run_id=\"E5_noGate_light\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=0.5, LAMBDA_L2_MID=0.25,\n",
    "             L2_APPLY_PROB=0.3, L2_SCHEDULE='warmup', L2_WARMUP_EPOCHS=5,\n",
    "             CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "        # KD mid-only\n",
    "        dict(run_id=\"E7_noGate_mid_only\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=0.0, LAMBDA_L2_MID=0.5,\n",
    "             L2_APPLY_PROB=1.0, L2_SCHEDULE='const',\n",
    "             CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "    ]\n",
    "\n",
    "    for split in SPLITS:\n",
    "        print(f\"\\n======= FIND/OR-TRAIN + DIAGNOSE on split = {split} =======\")\n",
    "        # 1) baseline\n",
    "        BASELINE_CFG = EXPS[0]\n",
    "        base_dir = get_or_train(tag=\"E0_noKD\", split=split, cfg_if_missing=BASELINE_CFG)\n",
    "        base_sum = _load_summary_from_report(base_dir)\n",
    "\n",
    "        # raccogli righe summary per questo split\n",
    "        summary_rows = [{\n",
    "            \"run\": \"E0_noKD\",\n",
    "            \"split\": split,\n",
    "            \"run_dir\": base_dir,\n",
    "            **base_sum,\n",
    "        }]\n",
    "\n",
    "        # 2) tutte le KD\n",
    "        for cfg in EXPS[1:]:\n",
    "            tag = cfg[\"run_id\"]\n",
    "            kd_dir = get_or_train(tag=tag, split=split, cfg_if_missing=cfg)\n",
    "\n",
    "            # diagnosi per-emozione (ΔAcc / ΔF1 / ΔECE)\n",
    "            diagnose_by_dirs(base_dir, kd_dir, split, tag)\n",
    "\n",
    "            # McNemar per-emozione + FDR\n",
    "            mcnemar_by_emotion(base_dir, kd_dir, split, tag)\n",
    "\n",
    "            # summary test/val\n",
    "            kd_sum = _load_summary_from_report(kd_dir)\n",
    "            summary_rows.append({\n",
    "                \"run\": tag,\n",
    "                \"split\": split,\n",
    "                \"run_dir\": kd_dir,\n",
    "                **kd_sum,\n",
    "            })\n",
    "\n",
    "        # 3) salva tabellone per lo split con Δ vs baseline\n",
    "        df = pd.DataFrame(summary_rows).copy()\n",
    "        base_vals = df[df[\"run\"] == \"E0_noKD\"].iloc[0]\n",
    "        df[\"ΔF1_vs_noKD\"]    = df[\"test_macro_f1\"] - base_vals[\"test_macro_f1\"]\n",
    "        df[\"ΔESI_vs_noKD\"]   = base_vals[\"test_esi\"] - df[\"test_esi\"]                 # + = più uniforme tra emozioni\n",
    "        df[\"ΔWorst_vs_noKD\"] = df[\"test_worst_emotion_acc\"] - base_vals[\"test_worst_emotion_acc\"]\n",
    "        out_csv = REPORTS_DIR / f\"emotion_kd_nogate_summary_{split}.csv\"\n",
    "        df.sort_values(\"run\").to_csv(out_csv, index=False)\n",
    "        print(f\"[saved] {out_csv}\")\n",
    "\n",
    "    print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bf9604ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DEVICE: cpu\n",
      "\n",
      "===== TRAIN E0_noKD (full_F0) | L2=False  top=0.0 mid=0.0  p=0.0 sched=const gate=soft =====\n",
      "Epoch 01  Val-F1=0.500\n",
      "    en  it  es\n",
      "en   8   1   8\n",
      "it  12   6   2\n",
      "es   4   1  16\n",
      "  → New best: Val-F1=0.500  saved: ckpts/E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatesoft/best_student.pt\n",
      "Epoch 02  Val-F1=0.603\n",
      "    en  it  es\n",
      "en   9   5   3\n",
      "it   8  12   0\n",
      "es   2   5  14\n",
      "  → New best: Val-F1=0.603  saved: ckpts/E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatesoft/best_student.pt\n",
      "Epoch 03  Val-F1=0.704\n",
      "    en  it  es\n",
      "en   8   4   5\n",
      "it   5  15   0\n",
      "es   1   1  19\n",
      "  → New best: Val-F1=0.704  saved: ckpts/E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatesoft/best_student.pt\n",
      "Epoch 04  Val-F1=0.738\n",
      "    en  it  es\n",
      "en   8   6   3\n",
      "it   1  19   0\n",
      "es   1   3  17\n",
      "  → New best: Val-F1=0.738  saved: ckpts/E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatesoft/best_student.pt\n",
      "Epoch 05  Val-F1=0.735\n",
      "    en  it  es\n",
      "en   8   5   4\n",
      "it   0  20   0\n",
      "es   2   3  16\n",
      "Epoch 06  Val-F1=0.640\n",
      "    en  it  es\n",
      "en   6   9   2\n",
      "it   0  20   0\n",
      "es   5   3  13\n",
      "Epoch 07  Val-F1=0.636\n",
      "    en  it  es\n",
      "en  12   1   4\n",
      "it  13   7   0\n",
      "es   2   0  19\n",
      "Epoch 08  Val-F1=0.541\n",
      "    en  it  es\n",
      "en  12   5   0\n",
      "it  10  10   0\n",
      "es   5   7   9\n",
      "Epoch 09  Val-F1=0.673\n",
      "    en  it  es\n",
      "en  10   4   3\n",
      "it   6  14   0\n",
      "es   6   0  15\n",
      "Epoch 10  Val-F1=0.356\n",
      "    en  it  es\n",
      "en  17   0   0\n",
      "it  16   4   0\n",
      "es  15   3   3\n",
      "Epoch 11  Val-F1=0.340\n",
      "    en  it  es\n",
      "en  12   5   0\n",
      "it   8  12   0\n",
      "es  15   6   0\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.738\n",
      "\n",
      "[TEST] N=49  Acc=0.571  Macro-F1=0.529\n",
      "    en  it  es\n",
      "en  13   7   1\n",
      "it   8  13   0\n",
      "es   5   0   2\n",
      "\n",
      "===== TRAIN E1_KD_both_base (full_F0) | L2=True  top=1.0 mid=0.5  p=1.0 sched=const gate=soft =====\n",
      "Epoch 01  Val-F1=0.640\n",
      "    en  it  es\n",
      "en   7   6   4\n",
      "it   6  14   0\n",
      "es   4   0  17\n",
      "  → New best: Val-F1=0.640  saved: ckpts/E1_KD_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatesoft/best_student.pt\n",
      "Epoch 02  Val-F1=0.617\n",
      "    en  it  es\n",
      "en   6   7   4\n",
      "it   6  14   0\n",
      "es   3   1  17\n",
      "Epoch 03  Val-F1=0.682\n",
      "    en  it  es\n",
      "en   7   7   3\n",
      "it   1  19   0\n",
      "es   3   3  15\n",
      "  → New best: Val-F1=0.682  saved: ckpts/E1_KD_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatesoft/best_student.pt\n",
      "Epoch 04  Val-F1=0.656\n",
      "    en  it  es\n",
      "en   8   7   2\n",
      "it   0  20   0\n",
      "es   2   8  11\n",
      "Epoch 05  Val-F1=0.673\n",
      "    en  it  es\n",
      "en  10   6   1\n",
      "it   4  16   0\n",
      "es   8   0  13\n",
      "Epoch 06  Val-F1=0.681\n",
      "    en  it  es\n",
      "en   7   7   3\n",
      "it   1  19   0\n",
      "es   4   2  15\n",
      "Epoch 07  Val-F1=0.592\n",
      "    en  it  es\n",
      "en   6   7   4\n",
      "it   0  20   0\n",
      "es  11   0  10\n",
      "Epoch 08  Val-F1=0.568\n",
      "    en  it  es\n",
      "en  11   3   3\n",
      "it  13   7   0\n",
      "es   6   0  15\n",
      "Epoch 09  Val-F1=0.670\n",
      "    en  it  es\n",
      "en   6   7   4\n",
      "it   6  14   0\n",
      "es   0   0  21\n",
      "Epoch 10  Val-F1=0.721\n",
      "    en  it  es\n",
      "en  12   4   1\n",
      "it   1  17   2\n",
      "es   8   0  13\n",
      "  → New best: Val-F1=0.721  saved: ckpts/E1_KD_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatesoft/best_student.pt\n",
      "Epoch 11  Val-F1=0.661\n",
      "    en  it  es\n",
      "en   4   5   8\n",
      "it   2  18   0\n",
      "es   0   1  20\n",
      "Epoch 12  Val-F1=0.595\n",
      "    en  it  es\n",
      "en   1   9   7\n",
      "it   0  20   0\n",
      "es   0   0  21\n",
      "Epoch 13  Val-F1=0.660\n",
      "    en  it  es\n",
      "en   7   3   7\n",
      "it   8  12   0\n",
      "es   0   0  21\n",
      "Epoch 14  Val-F1=0.590\n",
      "    en  it  es\n",
      "en   4   7   6\n",
      "it   6  13   1\n",
      "es   1   0  20\n",
      "Epoch 15  Val-F1=0.461\n",
      "    en  it  es\n",
      "en  11   2   4\n",
      "it  18   2   0\n",
      "es   3   2  16\n",
      "Epoch 16  Val-F1=0.574\n",
      "    en  it  es\n",
      "en  13   3   1\n",
      "it  11   8   1\n",
      "es   9   0  12\n",
      "Epoch 17  Val-F1=0.661\n",
      "    en  it  es\n",
      "en  16   0   1\n",
      "it   7  12   1\n",
      "es  11   0  10\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.721\n",
      "\n",
      "[TEST] N=49  Acc=0.347  Macro-F1=0.340\n",
      "    en  it  es\n",
      "en   8   7   6\n",
      "it   7   5   9\n",
      "es   3   0   4\n",
      "\n",
      "===== TRAIN E2_KD_both_emaware_softgate (full_F0) | L2=True  top=1.0 mid=0.5  p=1.0 sched=warmup gate=soft =====\n",
      "Epoch 01  Val-F1=0.614\n",
      "    en  it  es\n",
      "en   5   3   9\n",
      "it   8  12   0\n",
      "es   0   0  21\n",
      "  → New best: Val-F1=0.614  saved: ckpts/E2_KD_both_emaware_softgate__full_F0__L21__top1__mid0.5__p1__schedwarmup__gatesoft/best_student.pt\n",
      "Epoch 02  Val-F1=0.614\n",
      "    en  it  es\n",
      "en   6   6   5\n",
      "it   6  14   0\n",
      "es   0   4  17\n",
      "Epoch 03  Val-F1=0.647\n",
      "    en  it  es\n",
      "en   5   7   5\n",
      "it   2  18   0\n",
      "es   2   2  17\n",
      "  → New best: Val-F1=0.647  saved: ckpts/E2_KD_both_emaware_softgate__full_F0__L21__top1__mid0.5__p1__schedwarmup__gatesoft/best_student.pt\n",
      "Epoch 04  Val-F1=0.703\n",
      "    en  it  es\n",
      "en   5   7   5\n",
      "it   2  18   0\n",
      "es   0   0  21\n",
      "  → New best: Val-F1=0.703  saved: ckpts/E2_KD_both_emaware_softgate__full_F0__L21__top1__mid0.5__p1__schedwarmup__gatesoft/best_student.pt\n",
      "Epoch 05  Val-F1=0.680\n",
      "    en  it  es\n",
      "en  10   1   6\n",
      "it   9  11   0\n",
      "es   2   0  19\n",
      "Epoch 06  Val-F1=0.634\n",
      "    en  it  es\n",
      "en   2   7   8\n",
      "it   0  20   0\n",
      "es   0   0  21\n",
      "Epoch 07  Val-F1=0.691\n",
      "    en  it  es\n",
      "en  13   2   2\n",
      "it   5  12   3\n",
      "es   6   0  15\n",
      "Epoch 08  Val-F1=0.679\n",
      "    en  it  es\n",
      "en  14   0   3\n",
      "it  12   8   0\n",
      "es   3   0  18\n",
      "Epoch 09  Val-F1=0.687\n",
      "    en  it  es\n",
      "en  10   6   1\n",
      "it   3  17   0\n",
      "es   8   0  13\n",
      "Epoch 10  Val-F1=0.433\n",
      "    en  it  es\n",
      "en  14   0   3\n",
      "it  20   0   0\n",
      "es   5   0  16\n",
      "Epoch 11  Val-F1=0.445\n",
      "    en  it  es\n",
      "en  16   1   0\n",
      "it  10  10   0\n",
      "es  19   0   2\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.703\n",
      "\n",
      "[TEST] N=49  Acc=0.571  Macro-F1=0.600\n",
      "    en  it  es\n",
      "en  10   9   2\n",
      "it   7  11   3\n",
      "es   0   0   7\n",
      "\n",
      "===== TRAIN E3_KD_both_emaware_hardgate (full_F0) | L2=True  top=1.0 mid=0.5  p=1.0 sched=warmup gate=hard =====\n",
      "Epoch 01  Val-F1=0.586\n",
      "    en  it  es\n",
      "en   6   5   6\n",
      "it   6  13   1\n",
      "es   4   1  16\n",
      "  → New best: Val-F1=0.586  saved: ckpts/E3_KD_both_emaware_hardgate__full_F0__L21__top1__mid0.5__p1__schedwarmup__gatehard/best_student.pt\n",
      "Epoch 02  Val-F1=0.703\n",
      "    en  it  es\n",
      "en   6   5   6\n",
      "it   1  19   0\n",
      "es   3   0  18\n",
      "  → New best: Val-F1=0.703  saved: ckpts/E3_KD_both_emaware_hardgate__full_F0__L21__top1__mid0.5__p1__schedwarmup__gatehard/best_student.pt\n",
      "Epoch 03  Val-F1=0.617\n",
      "    en  it  es\n",
      "en   5   5   7\n",
      "it   7  13   0\n",
      "es   1   0  20\n",
      "Epoch 04  Val-F1=0.697\n",
      "    en  it  es\n",
      "en  14   2   1\n",
      "it   6  14   0\n",
      "es   9   0  12\n",
      "Epoch 05  Val-F1=0.665\n",
      "    en  it  es\n",
      "en  11   1   5\n",
      "it   9  10   1\n",
      "es   3   0  18\n",
      "Epoch 06  Val-F1=0.640\n",
      "    en  it  es\n",
      "en  11   6   0\n",
      "it   4  16   0\n",
      "es  11   0  10\n",
      "Epoch 07  Val-F1=0.638\n",
      "    en  it  es\n",
      "en   7   6   4\n",
      "it   2  16   2\n",
      "es   6   0  15\n",
      "Epoch 08  Val-F1=0.645\n",
      "    en  it  es\n",
      "en   6   3   8\n",
      "it   6  14   0\n",
      "es   2   0  19\n",
      "Epoch 09  Val-F1=0.710\n",
      "    en  it  es\n",
      "en  12   1   4\n",
      "it   7  13   0\n",
      "es   5   0  16\n",
      "  → New best: Val-F1=0.710  saved: ckpts/E3_KD_both_emaware_hardgate__full_F0__L21__top1__mid0.5__p1__schedwarmup__gatehard/best_student.pt\n",
      "Epoch 10  Val-F1=0.633\n",
      "    en  it  es\n",
      "en   5   7   5\n",
      "it   3  17   0\n",
      "es   1   3  17\n",
      "Epoch 11  Val-F1=0.659\n",
      "    en  it  es\n",
      "en   6   8   3\n",
      "it   3  16   1\n",
      "es   3   0  18\n",
      "Epoch 12  Val-F1=0.414\n",
      "    en  it  es\n",
      "en   9   2   6\n",
      "it  18   2   0\n",
      "es   5   1  15\n",
      "Epoch 13  Val-F1=0.643\n",
      "    en  it  es\n",
      "en   5   4   8\n",
      "it   3  14   3\n",
      "es   0   0  21\n",
      "Epoch 14  Val-F1=0.606\n",
      "    en  it  es\n",
      "en  15   1   1\n",
      "it   9   9   2\n",
      "es  10   0  11\n",
      "Epoch 15  Val-F1=0.623\n",
      "    en  it  es\n",
      "en   9   2   6\n",
      "it  11   9   0\n",
      "es   2   0  19\n",
      "Epoch 16  Val-F1=0.549\n",
      "    en  it  es\n",
      "en  10   0   7\n",
      "it  12   5   3\n",
      "es   2   0  19\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.710\n",
      "\n",
      "[TEST] N=49  Acc=0.469  Macro-F1=0.435\n",
      "    en  it  es\n",
      "en  14   5   2\n",
      "it  14   7   0\n",
      "es   5   0   2\n",
      "\n",
      "===== TRAIN E0_noKD (neutral_only_F0) | L2=False  top=0.0 mid=0.0  p=0.0 sched=const gate=soft =====\n",
      "Epoch 01  Val-F1=0.222\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   1   0   2\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.222  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatesoft/best_student.pt\n",
      "Epoch 02  Val-F1=0.222\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   1   0   2\n",
      "es   0   0   3\n",
      "Epoch 03  Val-F1=0.222\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   1   0   2\n",
      "es   0   0   3\n",
      "Epoch 04  Val-F1=0.552\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   1   2   0\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.552  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatesoft/best_student.pt\n",
      "Epoch 05  Val-F1=0.452\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   2   1   0\n",
      "es   0   0   3\n",
      "Epoch 06  Val-F1=0.250\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   2   0   1\n",
      "es   0   0   3\n",
      "Epoch 07  Val-F1=0.552\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   1   2   0\n",
      "es   0   0   3\n",
      "Epoch 08  Val-F1=0.822\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   1   2   0\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.822  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatesoft/best_student.pt\n",
      "Epoch 09  Val-F1=1.000\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=1.000  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatesoft/best_student.pt\n",
      "Epoch 10  Val-F1=0.667\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   2   1   0\n",
      "es   0   0   3\n",
      "Epoch 11  Val-F1=0.262\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   2   1   0\n",
      "es   3   0   0\n",
      "Epoch 12  Val-F1=0.333\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   3   0   0\n",
      "Epoch 13  Val-F1=0.300\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   0   1   2\n",
      "es   3   0   0\n",
      "Epoch 14  Val-F1=0.262\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   1   2\n",
      "es   2   0   1\n",
      "Epoch 15  Val-F1=0.262\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   2   1   0\n",
      "es   3   0   0\n",
      "Epoch 16  Val-F1=0.378\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   1   2   0\n",
      "es   3   0   0\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 1.000\n",
      "\n",
      "[TEST] N=49  Acc=0.449  Macro-F1=0.432\n",
      "    en  it  es\n",
      "en   4   9   8\n",
      "it   1  11   9\n",
      "es   0   0   7\n",
      "\n",
      "===== TRAIN E1_KD_both_base (neutral_only_F0) | L2=True  top=1.0 mid=0.5  p=1.0 sched=const gate=soft =====\n",
      "Epoch 01  Val-F1=0.083\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   3   0   0\n",
      "es   3   0   0\n",
      "  → New best: Val-F1=0.083  saved: ckpts/E1_KD_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatesoft/best_student.pt\n",
      "Epoch 02  Val-F1=0.083\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   3   0   0\n",
      "es   3   0   0\n",
      "Epoch 03  Val-F1=0.083\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   3   0   0\n",
      "es   3   0   0\n",
      "Epoch 04  Val-F1=0.262\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   3   0   0\n",
      "es   2   0   1\n",
      "  → New best: Val-F1=0.262  saved: ckpts/E1_KD_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatesoft/best_student.pt\n",
      "Epoch 05  Val-F1=0.389\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   2   1   0\n",
      "es   1   0   2\n",
      "  → New best: Val-F1=0.389  saved: ckpts/E1_KD_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatesoft/best_student.pt\n",
      "Epoch 06  Val-F1=0.167\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   2   1   0\n",
      "es   3   0   0\n",
      "Epoch 07  Val-F1=0.250\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   0   3   0\n",
      "es   2   1   0\n",
      "Epoch 08  Val-F1=0.452\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   0   3   0\n",
      "es   2   0   1\n",
      "  → New best: Val-F1=0.452  saved: ckpts/E1_KD_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatesoft/best_student.pt\n",
      "Epoch 09  Val-F1=0.457\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   2   1\n",
      "es   1   0   2\n",
      "  → New best: Val-F1=0.457  saved: ckpts/E1_KD_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatesoft/best_student.pt\n",
      "Epoch 10  Val-F1=0.333\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   1   2\n",
      "es   1   0   2\n",
      "Epoch 11  Val-F1=0.567\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   0   2   1\n",
      "es   2   0   1\n",
      "  → New best: Val-F1=0.567  saved: ckpts/E1_KD_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatesoft/best_student.pt\n",
      "Epoch 12  Val-F1=0.333\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   1   2\n",
      "es   1   0   2\n",
      "Epoch 13  Val-F1=0.556\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   1   0   2\n",
      "Epoch 14  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.619  saved: ckpts/E1_KD_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatesoft/best_student.pt\n",
      "Epoch 15  Val-F1=0.517\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   0   3   0\n",
      "es   0   1   2\n",
      "Epoch 16  Val-F1=0.383\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   2   1\n",
      "Epoch 17  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Epoch 18  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Epoch 19  Val-F1=0.556\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   1   0   2\n",
      "Epoch 20  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Epoch 21  Val-F1=0.552\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   1   2   0\n",
      "es   0   0   3\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.619\n",
      "\n",
      "[TEST] N=49  Acc=0.469  Macro-F1=0.418\n",
      "    en  it  es\n",
      "en   1  19   1\n",
      "it   0  17   4\n",
      "es   0   2   5\n",
      "\n",
      "===== TRAIN E2_KD_both_emaware_softgate (neutral_only_F0) | L2=True  top=1.0 mid=0.5  p=1.0 sched=warmup gate=soft =====\n",
      "Epoch 01  Val-F1=0.262\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   0   0   3\n",
      "es   2   0   1\n",
      "  → New best: Val-F1=0.262  saved: ckpts/E2_KD_both_emaware_softgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatesoft/best_student.pt\n",
      "Epoch 02  Val-F1=0.262\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   0   0   3\n",
      "es   2   0   1\n",
      "Epoch 03  Val-F1=0.148\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   0   3\n",
      "es   1   0   2\n",
      "Epoch 04  Val-F1=0.200\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   0   3\n",
      "es   0   0   3\n",
      "Epoch 05  Val-F1=0.417\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   1   1   1\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.417  saved: ckpts/E2_KD_both_emaware_softgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatesoft/best_student.pt\n",
      "Epoch 06  Val-F1=0.357\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   1   1   1\n",
      "es   1   0   2\n",
      "Epoch 07  Val-F1=0.552\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   1   2   0\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.552  saved: ckpts/E2_KD_both_emaware_softgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatesoft/best_student.pt\n",
      "Epoch 08  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.619  saved: ckpts/E2_KD_both_emaware_softgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatesoft/best_student.pt\n",
      "Epoch 09  Val-F1=0.517\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   2   1\n",
      "es   0   0   3\n",
      "Epoch 10  Val-F1=0.457\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   2   1\n",
      "es   1   0   2\n",
      "Epoch 11  Val-F1=0.333\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   2   1\n",
      "es   1   1   1\n",
      "Epoch 12  Val-F1=0.452\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   0   3   0\n",
      "es   2   1   0\n",
      "Epoch 13  Val-F1=0.675\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   0   3   0\n",
      "es   1   1   1\n",
      "  → New best: Val-F1=0.675  saved: ckpts/E2_KD_both_emaware_softgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatesoft/best_student.pt\n",
      "Epoch 14  Val-F1=0.452\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   0   3   0\n",
      "es   2   1   0\n",
      "Epoch 15  Val-F1=0.250\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   0   3   0\n",
      "es   2   1   0\n",
      "Epoch 16  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Epoch 17  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Epoch 18  Val-F1=0.667\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   0   3   0\n",
      "es   2   0   1\n",
      "Epoch 19  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Epoch 20  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.675\n",
      "\n",
      "[TEST] N=49  Acc=0.408  Macro-F1=0.309\n",
      "    en  it  es\n",
      "en   8   9   4\n",
      "it   9  12   0\n",
      "es   7   0   0\n",
      "\n",
      "===== TRAIN E3_KD_both_emaware_hardgate (neutral_only_F0) | L2=True  top=1.0 mid=0.5  p=1.0 sched=warmup gate=hard =====\n",
      "Epoch 01  Val-F1=0.244\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   2   0   1\n",
      "es   2   0   1\n",
      "  → New best: Val-F1=0.244  saved: ckpts/E3_KD_both_emaware_hardgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatehard/best_student.pt\n",
      "Epoch 02  Val-F1=0.262\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   3   0   0\n",
      "es   2   0   1\n",
      "  → New best: Val-F1=0.262  saved: ckpts/E3_KD_both_emaware_hardgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatehard/best_student.pt\n",
      "Epoch 03  Val-F1=0.262\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   3   0   0\n",
      "es   2   0   1\n",
      "Epoch 04  Val-F1=0.111\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   2   0   1\n",
      "es   2   0   1\n",
      "Epoch 05  Val-F1=0.222\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   3   0   0\n",
      "es   1   0   2\n",
      "Epoch 06  Val-F1=0.467\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   2   0   1\n",
      "  → New best: Val-F1=0.467  saved: ckpts/E3_KD_both_emaware_hardgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatehard/best_student.pt\n",
      "Epoch 07  Val-F1=0.457\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   2   1\n",
      "es   1   0   2\n",
      "Epoch 08  Val-F1=0.467\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   2   0   1\n",
      "Epoch 09  Val-F1=0.556\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   1   0   2\n",
      "  → New best: Val-F1=0.556  saved: ckpts/E3_KD_both_emaware_hardgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatehard/best_student.pt\n",
      "Epoch 10  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.619  saved: ckpts/E3_KD_both_emaware_hardgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatehard/best_student.pt\n",
      "Epoch 11  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Epoch 12  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Epoch 13  Val-F1=0.517\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   2   1\n",
      "es   0   0   3\n",
      "Epoch 14  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Epoch 15  Val-F1=0.508\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   1   2\n",
      "Epoch 16  Val-F1=0.675\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   0   3   0\n",
      "es   1   1   1\n",
      "  → New best: Val-F1=0.675  saved: ckpts/E3_KD_both_emaware_hardgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatehard/best_student.pt\n",
      "Epoch 17  Val-F1=0.508\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   1   2\n",
      "Epoch 18  Val-F1=0.389\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   1   2\n",
      "es   0   0   3\n",
      "Epoch 19  Val-F1=0.389\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   1   2\n",
      "es   0   0   3\n",
      "Epoch 20  Val-F1=0.389\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   1   2\n",
      "es   0   0   3\n",
      "Epoch 21  Val-F1=0.200\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   0   3\n",
      "es   0   0   3\n",
      "Epoch 22  Val-F1=0.333\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   1   2\n",
      "es   1   0   2\n",
      "Epoch 23  Val-F1=0.517\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   2   1\n",
      "es   0   0   3\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.675\n",
      "\n",
      "[TEST] N=49  Acc=0.510  Macro-F1=0.426\n",
      "    en  it  es\n",
      "en   1  18   2\n",
      "it   0  21   0\n",
      "es   4   0   3\n",
      "\n",
      "================ EMOTION-KD SUMMARY ================\n",
      "                        run           split  USE_L2_ML  L2_top  L2_mid  L2_apply_prob L2_schedule gate_mode  gate_thresh  best_val_macro_f1  test_macro_f1  test_acc  test_esi  test_worst_emotion_acc                                                                                   run_name  ΔF1_vs_noKD  ΔESI_vs_noKD  ΔWorst_vs_noKD\n",
      "                    E0_noKD         full_F0          0     0.0     0.0            0.0       const      soft          0.6           0.737843       0.529113  0.571429  0.184616                0.400000                                E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatesoft     0.000000      0.000000        0.000000\n",
      "            E1_KD_both_base         full_F0          1     1.0     0.5            1.0       const      soft          0.6           0.721183       0.340326  0.346939  0.240224                0.000000                      E1_KD_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatesoft    -0.188786     -0.055608       -0.400000\n",
      "E2_KD_both_emaware_softgate         full_F0          1     1.0     0.5            1.0      warmup      soft          0.6           0.703428       0.599914  0.571429  0.138460                0.428571         E2_KD_both_emaware_softgate__full_F0__L21__top1__mid0.5__p1__schedwarmup__gatesoft     0.070802      0.046157        0.028571\n",
      "E3_KD_both_emaware_hardgate         full_F0          1     1.0     0.5            1.0      warmup      hard          0.6           0.710187       0.435466  0.469388  0.205148                0.285714         E3_KD_both_emaware_hardgate__full_F0__L21__top1__mid0.5__p1__schedwarmup__gatehard    -0.093647     -0.020532       -0.114286\n",
      "                    E0_noKD neutral_only_F0          0     0.0     0.0            0.0       const      soft          0.6           1.000000       0.431964  0.448980  0.174148                0.285714                        E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatesoft     0.000000      0.000000        0.000000\n",
      "            E1_KD_both_base neutral_only_F0          1     1.0     0.5            1.0       const      soft          0.6           0.619048       0.418472  0.469388  0.139252                0.250000              E1_KD_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatesoft    -0.013492      0.034896       -0.035714\n",
      "E2_KD_both_emaware_softgate neutral_only_F0          1     1.0     0.5            1.0      warmup      soft          0.6           0.674603       0.308995  0.408163  0.052199                0.333333 E2_KD_both_emaware_softgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatesoft    -0.122969      0.121949        0.047619\n",
      "E3_KD_both_emaware_hardgate neutral_only_F0          1     1.0     0.5            1.0      warmup      hard          0.6           0.674603       0.425641  0.510204  0.148517                0.375000 E3_KD_both_emaware_hardgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatehard    -0.006322      0.025631        0.089286\n",
      "\n",
      "Saved: reports/emotion_kd_summary.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jx/nf2g6k1s1550mrw1rrvdw69h0000gn/T/ipykernel_23627/3603149086.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_delta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;31m# Esegui!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m     \u001b[0mrun_suite_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/jx/nf2g6k1s1550mrw1rrvdw69h0000gn/T/ipykernel_23627/3603149086.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ΔF1\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"macro_f1_kd\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"macro_f1_base\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ΔAcc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc_kd\"\u001b[0m\u001b[0;34m]\u001b[0m      \u001b[0;34m-\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc_base\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                 \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"exp\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"emotion\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"emotion\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ΔF1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ΔF1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ΔAcc\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ΔAcc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m     \u001b[0mdf_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"split\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"exp\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"emotion\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_delta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mdf_delta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reports/emotion_deltas.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSaved: reports/emotion_deltas.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6923\u001b[0m                 \u001b[0;34mf\"Length of ascending ({len(ascending)})\"\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6924\u001b[0m                 \u001b[0;34mf\" != length of by ({len(by)})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6925\u001b[0m             )\n\u001b[1;32m   6926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6927\u001b[0;31m             \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6929\u001b[0m             \u001b[0;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6930\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m-> 6927\u001b[0;31m         \u001b[0;34m...\u001b[0m     \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_natsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1840\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1844\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'split'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# Runner KD (mid/top) — emotion-aware + confidence-gate — CPU only\n",
    "# Richiede gli split:\n",
    "#   - splits_session2/full_F0/{train,val,test}_midtop.csv\n",
    "#   - splits_session2/neutral_only_F0/{train,val,test}_midtop.csv\n",
    "# Colonne richieste nei CSV: mouth_path, (lang|label), (emotion|emotion_id), t_conf, layer10_mean_path, layer11_mean_path\n",
    "\n",
    "import os, json, random, copy, math, contextlib, glob\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.video import r3d_18, R3D_18_Weights\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "# ───────────── Config base ─────────────\n",
    "SEED = 42\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 8\n",
    "LR, WD = 3e-4, 1e-3\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "LANGS = ['en','it','es']\n",
    "OUT_H, OUT_W, L = 64, 64, 32\n",
    "MIXUP_ALPHA = 0.30\n",
    "PATIENCE = 7\n",
    "MAX_LR = 3e-4\n",
    "DIV_FACTOR = 10\n",
    "FINAL_DIV = 100\n",
    "\n",
    "# Splits (usa i tuoi *_midtop.csv)\n",
    "DATA_SPLITS = {\n",
    "    \"full_F0\": {\n",
    "        \"train\": \"splits_session2/full_F0/train.csv\",\n",
    "        \"val\":   \"splits_session2/full_F0/val.csv\",\n",
    "        \"test\":  \"splits_session2/full_F0/test.csv\",\n",
    "    },\n",
    "    \"neutral_only_F0\": {\n",
    "        \"train\": \"splits_session2/neutral_only_F0/train.csv\",\n",
    "        \"val\":   \"splits_session2/neutral_only_F0/val.csv\",\n",
    "        \"test\":  \"splits_session2/neutral_only_F0/test.csv\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# ───────────── Device: forza CPU ─────────────\n",
    "FORCE_CPU = True\n",
    "if FORCE_CPU:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    AMP_ENABLED = False\n",
    "    PIN_MEMORY  = False\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available()\n",
    "                          else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "    AMP_ENABLED = (DEVICE.type == 'cuda')\n",
    "    PIN_MEMORY  = (DEVICE.type == 'cuda')\n",
    "    torch.backends.cudnn.benchmark = (DEVICE.type == 'cuda')\n",
    "print(\"Using DEVICE:\", DEVICE)\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# Emotion map\n",
    "EMO_ID2NAME = {0:\"neutro\",1:\"rabbia\",2:\"disgusto\",3:\"paura\",4:\"gioia\",5:\"tristezza\",6:\"sorpresa\"}\n",
    "\n",
    "# Pesi emotion-aware (modificabili)\n",
    "LAM_TOP_EMO = {\"neutro\":0.8,\"rabbia\":1.2,\"disgusto\":1.1,\"paura\":1.3,\"gioia\":1.0,\"tristezza\":1.1,\"sorpresa\":1.2}\n",
    "LAM_MID_EMO = {\"neutro\":0.8,\"rabbia\":1.0,\"disgusto\":1.0,\"paura\":1.1,\"gioia\":0.9,\"tristezza\":1.0,\"sorpresa\":1.0}\n",
    "\n",
    "# ───────────── Metriche ─────────────\n",
    "def macro_f1(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)[2]\n",
    "\n",
    "def ece_by_emotion(df_probs: pd.DataFrame, n_bins: int = 15) -> pd.DataFrame:\n",
    "    rows=[]\n",
    "    for emo, g in df_probs.groupby(\"emotion\"):\n",
    "        probs = g[[\"prob_en\",\"prob_it\",\"prob_es\"]].values\n",
    "        y = g[\"y\"].values.astype(int)\n",
    "        conf = probs.max(axis=1)\n",
    "        pred = probs.argmax(axis=1)\n",
    "        correct = (pred == y).astype(float)\n",
    "        bins = np.linspace(0,1,n_bins+1)\n",
    "        ece=0.0\n",
    "        for i in range(n_bins):\n",
    "            m = (conf>bins[i]) & (conf<=bins[i+1])\n",
    "            if m.sum()==0: continue\n",
    "            ece += abs(correct[m].mean() - conf[m].mean()) * (m.mean())\n",
    "        rows.append({\"emotion\":emo, \"ECE\": float(ece)})\n",
    "    return pd.DataFrame(rows).sort_values(\"emotion\")\n",
    "\n",
    "# ───────────── Augmentazioni ─────────────\n",
    "class SpecAug3D:\n",
    "    def __init__(self, H, W, T_mask=4, S_mask=4):\n",
    "        self.tf = T.Compose([\n",
    "            T.ToPILImage(),\n",
    "            T.RandomResizedCrop((H,W), scale=(0.95,1.0), ratio=(1.0,1.0)),\n",
    "            T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),\n",
    "            T.RandomHorizontalFlip(0.5),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "        self.T_mask, self.S_mask = T_mask, S_mask\n",
    "    def __call__(self, vid):\n",
    "        frames = []\n",
    "        for f in vid:\n",
    "            img = (f*255).byte()\n",
    "            t   = self.tf(img).squeeze(0)\n",
    "            frames.append(t)\n",
    "        vid = torch.stack(frames)\n",
    "        L_,H,W = vid.shape\n",
    "        if L_ > self.T_mask:\n",
    "            t0 = random.randrange(0, L_-self.T_mask+1)\n",
    "            vid[t0:t0+self.T_mask] = 0\n",
    "        if H>self.S_mask and W>self.S_mask:\n",
    "            fi = random.randrange(0, L_)\n",
    "            h0 = random.randrange(0, H-self.S_mask+1)\n",
    "            w0 = random.randrange(0, W-self.S_mask+1)\n",
    "            vid[fi,h0:h0+self.S_mask,w0:w0+self.S_mask] = 0\n",
    "        return vid\n",
    "\n",
    "class RandomErasing3D:\n",
    "    def __init__(self, p=0.3, size=(8,8,8)):\n",
    "        self.p = p; self.d, self.h, self.w = size\n",
    "    def __call__(self, vid):\n",
    "        if random.random()>self.p: return vid\n",
    "        L_,H,W = vid.shape\n",
    "        sd = random.randint(0, max(0, L_-self.d))\n",
    "        sh = random.randint(0, max(0, H-self.h))\n",
    "        sw = random.randint(0, max(0, W-self.w))\n",
    "        vid[sd:sd+self.d, sh:sh+self.h, sw:sw+self.w] = 0\n",
    "        return vid\n",
    "\n",
    "def mixup_return_params(x, y_onehot, alpha=MIXUP_ALPHA):\n",
    "    if alpha <= 0:\n",
    "        B = x.size(0); idx = torch.arange(B, device=x.device); lam = 1.0\n",
    "        return x, y_onehot, lam, idx\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    idx = torch.randperm(x.size(0), device=x.device)\n",
    "    x_m = lam*x + (1-lam)*x[idx]\n",
    "    y_m = lam*y_onehot + (1-lam)*y_onehot[idx]\n",
    "    return x_m, y_m, float(lam), idx\n",
    "\n",
    "# ───────────── Loss ─────────────\n",
    "class SoftFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__(); self.alpha, self.gamma = alpha, gamma\n",
    "    def forward(self, logits, y_soft):\n",
    "        logp = F.log_softmax(logits,1)\n",
    "        p    = logp.exp()\n",
    "        ce   = -(y_soft * logp).sum(1)\n",
    "        pt   = (y_soft * p).sum(1)\n",
    "        return ( self.alpha * (1-pt)**self.gamma * ce ).mean()\n",
    "\n",
    "# ───────────── MixStyle ─────────────\n",
    "class MixStyle(nn.Module):\n",
    "    def __init__(self, p=0.3, α=0.1):\n",
    "        super().__init__(); self.p, self.α = p, α\n",
    "    def forward(self, x):\n",
    "        if not self.training or random.random()>self.p:\n",
    "            return x\n",
    "        B,C = x.shape\n",
    "        mu  = x.mean(1,keepdim=True)\n",
    "        sig = (x.var(1,keepdim=True)+1e-6).sqrt()\n",
    "        lm  = np.random.beta(self.α, self.α)\n",
    "        perm= torch.randperm(B,device=x.device)\n",
    "        mu2, sig2 = mu[perm], sig[perm]\n",
    "        x_norm = (x-mu)/sig\n",
    "        return x_norm*(lm*sig + (1-lm)*sig2) + (lm*mu + (1-lm)*mu2)\n",
    "\n",
    "# ───────────── Dataset ─────────────\n",
    "TEACHER_L10_COL = \"layer10_mean_path\"\n",
    "TEACHER_L11_COL = \"layer11_mean_path\"\n",
    "\n",
    "class MouthDSEmotion(Dataset):\n",
    "    def __init__(self,csv,L=32,augment=False,need_teacher=False):\n",
    "        df = pd.read_csv(csv).copy()\n",
    "        if 'mouth_path' in df.columns:\n",
    "            df = df.query('mouth_path.notna()')\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # lingua\n",
    "        if 'lang' in df.columns:\n",
    "            df['label'] = df['lang'].astype(str).str.lower()\n",
    "        elif 'label' in df.columns:\n",
    "            df['label'] = df['label'].astype(str).str.lower()\n",
    "        else:\n",
    "            raise ValueError(\"Manca colonna lingua: attesa 'lang' o 'label'.\")\n",
    "\n",
    "        # emozione\n",
    "        if 'emotion' not in df.columns and 'emotion_id' in df.columns:\n",
    "            df['emotion'] = df['emotion_id'].map(EMO_ID2NAME)\n",
    "        df['emotion'] = df['emotion'].astype(str)\n",
    "\n",
    "        self.df, self.L = df, L\n",
    "        self.l2i         = {l:i for i,l in enumerate(LANGS)}\n",
    "        self.spec        = SpecAug3D(OUT_H,OUT_W) if augment else None\n",
    "        self.randomerase = RandomErasing3D()      if augment else None\n",
    "        self.need_teacher = need_teacher\n",
    "\n",
    "        if self.need_teacher:\n",
    "            if TEACHER_L10_COL not in self.df.columns or TEACHER_L11_COL not in self.df.columns:\n",
    "                raise ValueError(f\"Per KD servono colonne teacher: '{TEACHER_L10_COL}', '{TEACHER_L11_COL}'.\")\n",
    "\n",
    "    def _align(self,a):\n",
    "        T0 = a.shape[0]\n",
    "        if T0>=self.L: idx = np.linspace(0,T0-1,self.L).astype(int)\n",
    "        else:          idx = np.concatenate([np.arange(T0), np.full(self.L-T0, T0-1)])\n",
    "        return a[idx]\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        r = self.df.iloc[i]\n",
    "        a = np.load(r.mouth_path,allow_pickle=True)\n",
    "        if a.dtype==np.uint8: a = a.astype('float32')/255.\n",
    "        else: a = a.astype('float32')\n",
    "        if a.ndim==4 and a.shape[-1]==3: a = a.mean(-1)\n",
    "        a = self._align(a)\n",
    "\n",
    "        v = torch.from_numpy(a)  # [L,H,W]\n",
    "        if self.spec:        v = self.spec(v)\n",
    "        if self.randomerase: v = self.randomerase(v)\n",
    "        v5 = v.unsqueeze(0).unsqueeze(0)\n",
    "        v5 = F.interpolate(v5, size=(self.L,OUT_H,OUT_W), mode='trilinear', align_corners=False)\n",
    "        x  = (v5 - 0.5)/0.5\n",
    "        x  = x.squeeze(0)                     # [1, L, H, W]\n",
    "        y  = torch.tensor(self.l2i[str(r.label).lower()],dtype=torch.long)\n",
    "        emo = str(r.emotion)\n",
    "        tconf = float(r.get(\"t_conf\", np.nan))\n",
    "\n",
    "        if not self.need_teacher:\n",
    "            return x, y, emo, tconf\n",
    "\n",
    "        l10 = l11 = None\n",
    "        p10 = r.get(TEACHER_L10_COL, None)\n",
    "        p11 = r.get(TEACHER_L11_COL, None)\n",
    "        if isinstance(p10,str) and os.path.exists(p10): l10 = torch.from_numpy(np.load(p10)).float()\n",
    "        if isinstance(p11,str) and os.path.exists(p11): l11 = torch.from_numpy(np.load(p11)).float()\n",
    "        return x, y, emo, tconf, l10, l11\n",
    "\n",
    "def collate_with_optional_teacher(batch):\n",
    "    xs, ys, emos, confs, l10s, l11s = [], [], [], [], [], []\n",
    "    for item in batch:\n",
    "        if len(item)==4:\n",
    "            x,y,emo,tc = item\n",
    "            xs.append(x); ys.append(y); emos.append(emo); confs.append(tc)\n",
    "        else:\n",
    "            x,y,emo,tc,l10,l11 = item\n",
    "            xs.append(x); ys.append(y); emos.append(emo); confs.append(tc); l10s.append(l10); l11s.append(l11)\n",
    "    x = torch.stack(xs,0); y = torch.stack(ys,0)\n",
    "    confs = torch.tensor([0.0 if np.isnan(c) else c for c in confs], dtype=torch.float32)\n",
    "    if len(l10s)==0:\n",
    "        return x, y, emos, confs\n",
    "    return x, y, emos, confs, l10s, l11s\n",
    "\n",
    "# ───────────── Modello ─────────────\n",
    "class Student(nn.Module):\n",
    "    def __init__(self, proj_dim=128):\n",
    "        super().__init__()\n",
    "        try:\n",
    "            self.backbone = r3d_18(weights=R3D_18_Weights.DEFAULT)\n",
    "        except Exception as _:\n",
    "            # fallback se non hai i pesi pre-addestrati in locale\n",
    "            self.backbone = r3d_18(weights=None)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.mixstyle   = MixStyle(p=0.3, α=0.1)\n",
    "        self.proj_v     = nn.Sequential(nn.LayerNorm(512), nn.Linear(512, proj_dim))\n",
    "        self.head       = nn.Sequential(nn.LayerNorm(512), nn.Linear(512,256), nn.GELU(), nn.Dropout(0.1),\n",
    "                                        nn.Linear(256,len(LANGS)))\n",
    "    def forward(self, x):\n",
    "        x = x.repeat(1,3,1,1,1)  # [B,1,L,H,W] -> [B,3,L,H,W]\n",
    "        f = self.backbone(x)     # [B,512]\n",
    "        f = self.mixstyle(f)\n",
    "        logits = self.head(f)\n",
    "        z_v = self.proj_v(f)     # [B,proj]\n",
    "        return logits, f, z_v\n",
    "\n",
    "# ───────────── Sampler bilanciato ─────────────\n",
    "def make_sampler(df):\n",
    "    cnt = df['label'].astype(str).str.lower().value_counts().reindex(LANGS,fill_value=0).to_dict()\n",
    "    w   = df['label'].astype(str).str.lower().map(lambda l:1.0/(cnt[l]+1e-6)).tolist()\n",
    "    return WeightedRandomSampler(w, num_samples=len(w), replacement=True)\n",
    "\n",
    "# ───────────── Loader builder ─────────────\n",
    "def build_loaders(train_csv, val_csv, need_teacher):\n",
    "    df_tr = pd.read_csv(train_csv)\n",
    "    dl_tr = DataLoader(MouthDSEmotion(train_csv, L, augment=True,  need_teacher=need_teacher),\n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       sampler=make_sampler(df_tr),\n",
    "                       num_workers=NUM_WORKERS,\n",
    "                       pin_memory=False,\n",
    "                       collate_fn=collate_with_optional_teacher)\n",
    "    dl_va = DataLoader(MouthDSEmotion(val_csv,   L, augment=False, need_teacher=False),\n",
    "                       batch_size=BATCH_SIZE, shuffle=False,\n",
    "                       num_workers=NUM_WORKERS, pin_memory=False,\n",
    "                       collate_fn=collate_with_optional_teacher)\n",
    "    return dl_tr, dl_va\n",
    "\n",
    "# ───────────── Eval helpers ─────────────\n",
    "def evaluate_emotion(csv_path, ckpt_path, proj_l11_top, proj_l10_mid, top_adapter, mid_adapter, proj_dim=128, run_dir=None, title=\"\"):\n",
    "    model = Student(proj_dim=proj_dim)\n",
    "    state = torch.load(ckpt_path, map_location='cpu')\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    for m in model.backbone.modules():\n",
    "        if isinstance(m, nn.BatchNorm3d):\n",
    "            m.eval(); m.weight.requires_grad_(False); m.bias.requires_grad_(False)\n",
    "    model.eval()\n",
    "\n",
    "    dl = DataLoader(MouthDSEmotion(csv_path, L, augment=False, need_teacher=False),\n",
    "                    batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False,\n",
    "                    collate_fn=collate_with_optional_teacher)\n",
    "\n",
    "    y_true, y_pred, emos, probs = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            x, y, emo, _ = batch\n",
    "            logits, _, _ = model(x)\n",
    "            y_true += y.cpu().tolist()\n",
    "            y_pred += logits.argmax(1).cpu().tolist()\n",
    "            pr = F.softmax(logits,1).cpu().numpy()\n",
    "            probs.append(pr)\n",
    "            emos += list(emo)\n",
    "    y_true = np.array(y_true); y_pred = np.array(y_pred)\n",
    "    probs  = np.concatenate(probs) if probs else np.zeros((0,len(LANGS)))\n",
    "    all_labels = list(range(len(LANGS)))\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred) if len(y_true) else 0.0\n",
    "    mf1 = f1_score(y_true, y_pred, average=\"macro\") if len(y_true) else 0.0\n",
    "    cm  = confusion_matrix(y_true, y_pred, labels=all_labels) if len(y_true) else np.zeros((len(LANGS),len(LANGS)), dtype=int)\n",
    "    print(f\"\\n[{title}] N={len(y_true)}  Acc={acc:.3f}  Macro-F1={mf1:.3f}\")\n",
    "    print(pd.DataFrame(cm, index=LANGS, columns=LANGS))\n",
    "\n",
    "    # per-emozione\n",
    "    dfp = pd.DataFrame({\n",
    "        \"y\": y_true, \"yhat\": y_pred, \"emotion\": emos,\n",
    "        \"prob_en\": probs[:,0] if len(probs) else [],\n",
    "        \"prob_it\": probs[:,1] if len(probs) else [],\n",
    "        \"prob_es\": probs[:,2] if len(probs) else [],\n",
    "    })\n",
    "    rows=[]\n",
    "    for emo,g in dfp.groupby(\"emotion\"):\n",
    "        rows.append({\n",
    "            \"emotion\": emo,\n",
    "            \"acc\": accuracy_score(g.y, g.yhat),\n",
    "            \"macro_f1\": f1_score(g.y, g.yhat, average=\"macro\")\n",
    "        })\n",
    "    per_emo = pd.DataFrame(rows).sort_values(\"emotion\")\n",
    "    esi = float(per_emo[\"macro_f1\"].std()) if len(per_emo)>0 else float(\"nan\")\n",
    "    worst_acc = float(per_emo[\"acc\"].min()) if len(per_emo)>0 else float(\"nan\")\n",
    "    ece_df = ece_by_emotion(dfp)\n",
    "\n",
    "    if run_dir is not None:\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "        dfp.to_csv(os.path.join(run_dir, f\"{title}__preds.csv\"), index=False)\n",
    "        per_emo.to_csv(os.path.join(run_dir, f\"{title}__per_emotion.csv\"), index=False)\n",
    "        ece_df.to_csv(os.path.join(run_dir, f\"{title}__ece_per_emotion.csv\"), index=False)\n",
    "\n",
    "    return dict(N=len(y_true), acc=float(acc), macro_f1=float(mf1),\n",
    "                per_emotion=per_emo, esi=float(esi), worst_acc=float(worst_acc),\n",
    "                ece=ece_df, preds=dfp)\n",
    "\n",
    "# ───────────── Infer dims teacher (mid/top) ─────────────\n",
    "def infer_teacher_dims(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    for _,r in df.iterrows():\n",
    "        p10 = r.get(TEACHER_L10_COL, None)\n",
    "        p11 = r.get(TEACHER_L11_COL, None)\n",
    "        if isinstance(p10,str) and os.path.exists(p10) and isinstance(p11,str) and os.path.exists(p11):\n",
    "            v10 = np.load(p10); v11 = np.load(p11)\n",
    "            return int(v10.shape[-1]), int(v11.shape[-1])\n",
    "    return 512, 512  # fallback prudente\n",
    "\n",
    "# ───────────── Training di UNA RUN ─────────────\n",
    "def train_one_run_emotion(run_cfg, split_key=\"full_F0\"):\n",
    "    TRAIN_CSV = DATA_SPLITS[split_key][\"train\"]\n",
    "    VAL_CSV   = DATA_SPLITS[split_key][\"val\"]\n",
    "    TEST_CSV  = DATA_SPLITS[split_key][\"test\"]\n",
    "\n",
    "    RUN_ID         = run_cfg['run_id']\n",
    "    USE_L2_ML      = run_cfg.get('USE_L2_ML', False)\n",
    "    LAMBDA_L2_TOP  = float(run_cfg.get('LAMBDA_L2_TOP', 0.0))\n",
    "    LAMBDA_L2_MID  = float(run_cfg.get('LAMBDA_L2_MID', 0.0))\n",
    "    L2_APPLY_PROB  = float(run_cfg.get('L2_APPLY_PROB', 1.0))\n",
    "    L2_SCHEDULE    = run_cfg.get('L2_SCHEDULE', 'const')        # 'const' | 'warmup'\n",
    "    L2_WARMUP_E    = int(run_cfg.get('L2_WARMUP_EPOCHS', 5))\n",
    "    PROJ_DIM       = int(run_cfg.get('PROJ_DIM', 128))\n",
    "\n",
    "    # gate config\n",
    "    CONF_GATE_MODE   = run_cfg.get('CONF_GATE_MODE', 'soft')    # 'soft' or 'hard'\n",
    "    CONF_GATE_THRESH = float(run_cfg.get('CONF_GATE_THRESH', 0.60))\n",
    "\n",
    "    need_teacher = USE_L2_ML\n",
    "    dl_tr, dl_va = build_loaders(TRAIN_CSV, VAL_CSV, need_teacher=need_teacher)\n",
    "\n",
    "    model = Student(proj_dim=PROJ_DIM)\n",
    "\n",
    "    # Projection heads\n",
    "    proj_l11_top = nn.Linear(512, PROJ_DIM)   # teacher top → proj_dim\n",
    "    proj_l10_mid = nn.Linear(512, 512)        # teacher mid → 512\n",
    "\n",
    "    # Freeze BN (comunque utile su CPU)\n",
    "    for m in model.backbone.modules():\n",
    "        if isinstance(m, nn.BatchNorm3d):\n",
    "            m.eval(); m.weight.requires_grad_(False); m.bias.requires_grad_(False)\n",
    "\n",
    "    # Adattatori dai dims teacher reali\n",
    "    if USE_L2_ML:\n",
    "        d10, d11 = infer_teacher_dims(TRAIN_CSV)   # es. Whisper-small: 768, 768\n",
    "        mid_adapter = (nn.Identity() if d10 == 512 else nn.Linear(d10, 512))\n",
    "        top_adapter = (nn.Identity() if d11 == 512 else nn.Linear(d11, 512))\n",
    "    else:\n",
    "        mid_adapter = nn.Identity()\n",
    "        top_adapter = nn.Identity()\n",
    "\n",
    "    params = list(model.parameters()) \\\n",
    "           + list(proj_l11_top.parameters()) \\\n",
    "           + list(proj_l10_mid.parameters())\n",
    "    if isinstance(top_adapter, nn.Linear): params += list(top_adapter.parameters())\n",
    "    if isinstance(mid_adapter, nn.Linear): params += list(mid_adapter.parameters())\n",
    "    opt   = AdamW(params, lr=LR, weight_decay=WD)\n",
    "\n",
    "    total = EPOCHS * max(1, len(dl_tr))\n",
    "    sched = OneCycleLR(opt, max_lr=MAX_LR, total_steps=total, pct_start=0.3,\n",
    "                       div_factor=DIV_FACTOR, final_div_factor=FINAL_DIV, anneal_strategy='cos')\n",
    "    crit  = SoftFocalLoss()\n",
    "\n",
    "    run_name = (f\"{RUN_ID}__{split_key}\"\n",
    "                f\"__L2{int(USE_L2_ML)}__top{LAMBDA_L2_TOP:g}__mid{LAMBDA_L2_MID:g}\"\n",
    "                f\"__p{L2_APPLY_PROB:g}__sched{L2_SCHEDULE}__gate{CONF_GATE_MODE}\")\n",
    "    ckpt_dir = os.path.join(\"ckpts\", run_name); os.makedirs(ckpt_dir, exist_ok=True)\n",
    "    best_path_student = os.path.join(ckpt_dir, \"best_student.pt\")\n",
    "    best_path_proj_l11 = os.path.join(ckpt_dir, \"best_proj_l11_top.pt\")\n",
    "    best_path_proj_l10 = os.path.join(ckpt_dir, \"best_proj_l10_mid.pt\")\n",
    "\n",
    "    last_path_student = os.path.join(ckpt_dir, \"last_student.pt\")\n",
    "    last_path_proj_l11 = os.path.join(ckpt_dir, \"last_proj_l11_top.pt\")\n",
    "    last_path_proj_l10 = os.path.join(ckpt_dir, \"last_proj_l10_mid.pt\")\n",
    "\n",
    "    run_dir = os.path.join(\"reports\", run_name); os.makedirs(run_dir, exist_ok=True)\n",
    "    epoch_logs = []\n",
    "    best_f1, patience = -1.0, 0\n",
    "\n",
    "    def eff_lambda(base, ep):\n",
    "        if L2_SCHEDULE == 'warmup' and L2_WARMUP_E>0:\n",
    "            return float(base) * min(1.0, ep / L2_WARMUP_E)\n",
    "        return float(base)\n",
    "\n",
    "    print(f\"\\n===== TRAIN {RUN_ID} ({split_key}) | L2={USE_L2_ML}  top={LAMBDA_L2_TOP} mid={LAMBDA_L2_MID}  p={L2_APPLY_PROB} sched={L2_SCHEDULE} gate={CONF_GATE_MODE} =====\")\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train(); proj_l11_top.train(); proj_l10_mid.train()\n",
    "        if isinstance(top_adapter, nn.Module): top_adapter.train()\n",
    "        if isinstance(mid_adapter, nn.Module): mid_adapter.train()\n",
    "\n",
    "        sup_loss_sum = 0.0\n",
    "        l2_top_sum = 0.0\n",
    "        l2_mid_sum = 0.0\n",
    "        cover_cnt = 0\n",
    "        seen_cnt  = 0\n",
    "\n",
    "        for batch in dl_tr:\n",
    "            if USE_L2_ML:\n",
    "                x, y, emos, tconfs, l10, l11 = batch\n",
    "            else:\n",
    "                x, y, emos, tconfs = batch\n",
    "                l10 = l11 = None\n",
    "\n",
    "            # (CPU) move\n",
    "            # (sono già CPU — lasciamo per coerenza API)\n",
    "            x = x.to('cpu'); y = y.to('cpu'); tconfs = tconfs.to('cpu')\n",
    "\n",
    "            # mixup\n",
    "            y_onehot = F.one_hot(y, len(LANGS)).float()\n",
    "            x_m, y_m, lam, idx = mixup_return_params(x, y_onehot)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            amp_ctx = contextlib.nullcontext\n",
    "\n",
    "            with amp_ctx():\n",
    "                logits_m, f_m, z_v_m = model(x_m)\n",
    "                loss_sup = crit(logits_m, y_m)\n",
    "\n",
    "                l2_top = torch.tensor(0.0)\n",
    "                l2_mid = torch.tensor(0.0)\n",
    "\n",
    "                if USE_L2_ML:\n",
    "                    logits_c, f_c, z_v_c = model(x)\n",
    "\n",
    "                    B = x.size(0)\n",
    "                    have = torch.tensor(\n",
    "                        [(isinstance(l10[i], torch.Tensor)) and (isinstance(l11[i], torch.Tensor)) for i in range(B)],\n",
    "                        dtype=torch.bool\n",
    "                    )\n",
    "                    seen_cnt += int(B); cover_cnt += int(have.sum().item())\n",
    "\n",
    "                    if have.any():\n",
    "                        idxs = torch.nonzero(have).squeeze(1)          # indici CPU\n",
    "                        l10_t = torch.stack([l10[i.item()] for i in idxs], dim=0)  # [M, d10]\n",
    "                        l11_t = torch.stack([l11[i.item()] for i in idxs], dim=0)  # [M, d11]\n",
    "                        conf_sel = tconfs[idxs]                                      # [M]\n",
    "                        emo_sel  = [emos[i.item()] for i in idxs]\n",
    "\n",
    "                        # adattatori → 512\n",
    "                        l10_512 = mid_adapter(l10_t)    # [M,512]\n",
    "                        l11_512 = top_adapter(l11_t)    # [M,512]\n",
    "\n",
    "                        f_sel  = f_c[have]              # [M,512]\n",
    "                        z_sel  = z_v_c[have]            # [M,proj]\n",
    "                        pt     = proj_l11_top(l11_512)  # [M,proj]\n",
    "                        pm     = proj_l10_mid(l10_512)  # [M,512]\n",
    "\n",
    "                        # gate confidenza\n",
    "                        if CONF_GATE_MODE == 'soft':\n",
    "                            gate = conf_sel.clamp(0,1)                  # [M] pesi 0..1\n",
    "                        else:\n",
    "                            gate = (conf_sel >= CONF_GATE_THRESH).float()  # [M] {0,1}\n",
    "\n",
    "                        # pesi per-emozione\n",
    "                        lam_top_e = torch.tensor([LAM_TOP_EMO.get(e,1.0) for e in emo_sel])\n",
    "                        lam_mid_e = torch.tensor([LAM_MID_EMO.get(e,1.0) for e in emo_sel])\n",
    "\n",
    "                        # schedule epocale\n",
    "                        lam_top_base = eff_lambda(LAMBDA_L2_TOP, ep)\n",
    "                        lam_mid_base = eff_lambda(LAMBDA_L2_MID, ep)\n",
    "\n",
    "                        # normalizza e calcola MSE per-sample\n",
    "                        z_n  = F.normalize(z_sel, dim=1);  pt_n = F.normalize(pt, dim=1)\n",
    "                        f_n  = F.normalize(f_sel, dim=1);  pm_n = F.normalize(pm, dim=1)\n",
    "\n",
    "                        top_vec = ((z_n - pt_n)**2).sum(1)   # [M]\n",
    "                        mid_vec = ((f_n - pm_n)**2).sum(1)   # [M]\n",
    "\n",
    "                        # loss con pesi emotion-aware e gate confidenza\n",
    "                        w_top = lam_top_base * lam_top_e * gate\n",
    "                        w_mid = lam_mid_base * lam_mid_e * gate\n",
    "\n",
    "                        eps = 1e-6\n",
    "                        if w_top.sum() > 0:\n",
    "                            l2_top = (w_top * top_vec).sum() / (w_top.sum() + eps)\n",
    "                            loss_sup = loss_sup + l2_top\n",
    "                        if w_mid.sum() > 0:\n",
    "                            l2_mid = (w_mid * mid_vec).sum() / (w_mid.sum() + eps)\n",
    "                            loss_sup = loss_sup + l2_mid\n",
    "\n",
    "                loss = loss_sup\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                list(model.parameters())\n",
    "                + list(proj_l11_top.parameters())\n",
    "                + list(proj_l10_mid.parameters())\n",
    "                + (list(top_adapter.parameters()) if isinstance(top_adapter, nn.Linear) else [])\n",
    "                + (list(mid_adapter.parameters()) if isinstance(mid_adapter, nn.Linear) else []),\n",
    "                1.0\n",
    "            )\n",
    "            opt.step(); opt.zero_grad()\n",
    "            sched.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                sup_loss_sum += float(loss_sup.item())\n",
    "                l2_top_sum   += float(l2_top.item()) if isinstance(l2_top, torch.Tensor) else float(l2_top)\n",
    "                l2_mid_sum   += float(l2_mid.item()) if isinstance(l2_mid, torch.Tensor) else float(l2_mid)\n",
    "\n",
    "        # ── Validation (macro-F1) ───────────────────────────\n",
    "        model.eval()\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in DataLoader(MouthDSEmotion(VAL_CSV, L, augment=False, need_teacher=False),\n",
    "                                    batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False,\n",
    "                                    collate_fn=collate_with_optional_teacher):\n",
    "                x,y,_,_ = batch\n",
    "                logits,_,_ = model(x)\n",
    "                preds += logits.argmax(1).cpu().tolist()\n",
    "                gts   += y.cpu().tolist()\n",
    "        f1 = macro_f1(gts, preds)\n",
    "        cm = confusion_matrix(gts, preds, labels=list(range(len(LANGS))))\n",
    "        print(f\"Epoch {ep:02d}  Val-F1={f1:.3f}\")\n",
    "        print(pd.DataFrame(cm, index=LANGS, columns=LANGS))\n",
    "\n",
    "        loss_sup_mean = sup_loss_sum / max(1, len(dl_tr))\n",
    "        l2_top_mean   = l2_top_sum / max(1, len(dl_tr))\n",
    "        l2_mid_mean   = l2_mid_sum / max(1, len(dl_tr))\n",
    "        cover_rate    = (cover_cnt / max(1, seen_cnt)) * 100.0\n",
    "        epoch_logs.append(dict(epoch=ep, val_f1=float(f1),\n",
    "                               loss_sup_mean=loss_sup_mean,\n",
    "                               loss_l2_top_mean=l2_top_mean,\n",
    "                               loss_l2_mid_mean=l2_mid_mean,\n",
    "                               teacher_cover_pct=cover_rate))\n",
    "        pd.DataFrame(epoch_logs).to_csv(os.path.join(run_dir, \"epoch_log.csv\"), index=False)\n",
    "\n",
    "        # early stopping\n",
    "        improved = f1 > best_f1 + 1e-6\n",
    "        if improved:\n",
    "            best_f1, patience = f1, 0\n",
    "            torch.save(model.state_dict(), best_path_student)\n",
    "            torch.save(proj_l11_top.state_dict(), best_path_proj_l11)\n",
    "            torch.save(proj_l10_mid.state_dict(), best_path_proj_l10)\n",
    "            print(f\"  → New best: Val-F1={f1:.3f}  saved: {best_path_student}\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= PATIENCE:\n",
    "                print(\"Early stopping\"); break\n",
    "\n",
    "    # save last\n",
    "    torch.save(model.state_dict(), last_path_student)\n",
    "    torch.save(proj_l11_top.state_dict(), last_path_proj_l11)\n",
    "    torch.save(proj_l10_mid.state_dict(), last_path_proj_l10)\n",
    "\n",
    "    print(f\"Best Val-F1 (VAL) = {best_f1:.3f}\")\n",
    "\n",
    "    # Eval TEST con report per emozione\n",
    "    test_report = evaluate_emotion(TEST_CSV, best_path_student,\n",
    "                                   proj_l11_top, proj_l10_mid, top_adapter, mid_adapter,\n",
    "                                   proj_dim=PROJ_DIM, run_dir=run_dir, title=\"TEST\")\n",
    "\n",
    "    # Salva riassunto\n",
    "    summary = {\n",
    "        \"run\": RUN_ID,\n",
    "        \"split\": split_key,\n",
    "        \"USE_L2_ML\": int(USE_L2_ML),\n",
    "        \"L2_top\": LAMBDA_L2_TOP,\n",
    "        \"L2_mid\": LAMBDA_L2_MID,\n",
    "        \"L2_apply_prob\": L2_APPLY_PROB,\n",
    "        \"L2_schedule\": L2_SCHEDULE,\n",
    "        \"gate_mode\": CONF_GATE_MODE,\n",
    "        \"gate_thresh\": CONF_GATE_THRESH,\n",
    "        \"best_val_macro_f1\": float(best_f1),\n",
    "        \"test_macro_f1\": float(test_report[\"macro_f1\"]),\n",
    "        \"test_acc\": float(test_report[\"acc\"]),\n",
    "        \"test_esi\": float(test_report[\"esi\"]),\n",
    "        \"test_worst_emotion_acc\": float(test_report[\"worst_acc\"]),\n",
    "    }\n",
    "    with open(os.path.join(run_dir, \"summary.json\"), \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    return best_path_student, run_name, summary\n",
    "\n",
    "# ───────────── RUN SUITE + REPORT (Full + Neutral→Full) ─────────────\n",
    "def run_suite_emotion():\n",
    "    EXPERIMENTS = [\n",
    "        # Baseline — no KD\n",
    "        dict(run_id=\"E0_noKD\",\n",
    "             USE_L2_ML=False, LAMBDA_L2_TOP=0.0, LAMBDA_L2_MID=0.0,\n",
    "             L2_APPLY_PROB=0.0, L2_SCHEDULE='const',\n",
    "             CONF_GATE_MODE='soft', CONF_GATE_THRESH=0.60),\n",
    "\n",
    "        # KD base (senza emotion-aware/gate)\n",
    "        dict(run_id=\"E1_KD_both_base\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=1.0, LAMBDA_L2_MID=0.5,\n",
    "             L2_APPLY_PROB=1.0, L2_SCHEDULE='const',\n",
    "             CONF_GATE_MODE='soft', CONF_GATE_THRESH=0.60),\n",
    "\n",
    "        # KD emotion-aware + soft gate (warmup)\n",
    "        dict(run_id=\"E2_KD_both_emaware_softgate\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=1.0, LAMBDA_L2_MID=0.5,\n",
    "             L2_APPLY_PROB=1.0, L2_SCHEDULE='warmup', L2_WARMUP_EPOCHS=5,\n",
    "             CONF_GATE_MODE='soft', CONF_GATE_THRESH=0.60),\n",
    "\n",
    "        # KD emotion-aware + hard gate (warmup)\n",
    "        dict(run_id=\"E3_KD_both_emaware_hardgate\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=1.0, LAMBDA_L2_MID=0.5,\n",
    "             L2_APPLY_PROB=1.0, L2_SCHEDULE='warmup', L2_WARMUP_EPOCHS=5,\n",
    "             CONF_GATE_MODE='hard', CONF_GATE_THRESH=0.60),\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    for split_key in [\"full_F0\", \"neutral_only_F0\"]:\n",
    "        for cfg in EXPERIMENTS:\n",
    "            best_ckpt, run_name, summary = train_one_run_emotion(cfg, split_key=split_key)\n",
    "            summary[\"run_name\"] = run_name\n",
    "            results.append(summary)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    # Δ vs baseline per ciascuno split\n",
    "    out_rows=[]\n",
    "    for split_key, g in df.groupby(\"split\"):\n",
    "        base = g[g[\"run\"]==\"E0_noKD\"].iloc[0]\n",
    "        gg = g.copy()\n",
    "        gg[\"ΔF1_vs_noKD\"]     = gg[\"test_macro_f1\"] - base[\"test_macro_f1\"]\n",
    "        gg[\"ΔESI_vs_noKD\"]    = base[\"test_esi\"] - gg[\"test_esi\"]              # positivo = più robusto (ESI↓)\n",
    "        gg[\"ΔWorst_vs_noKD\"]  = gg[\"test_worst_emotion_acc\"] - base[\"test_worst_emotion_acc\"]\n",
    "        out_rows.append(gg)\n",
    "    df_all = pd.concat(out_rows, ignore_index=True)\n",
    "\n",
    "    print(\"\\n================ EMOTION-KD SUMMARY ================\")\n",
    "    print(df_all.sort_values([\"split\",\"run\"]).to_string(index=False))\n",
    "\n",
    "    os.makedirs(\"reports\", exist_ok=True)\n",
    "    out_csv = \"reports/emotion_kd_summary.csv\"\n",
    "    df_all.to_csv(out_csv, index=False)\n",
    "    print(f\"\\nSaved: {out_csv}\")\n",
    "\n",
    "    # Δ per emozione (confronta E2/E3 vs E0) su ciascuno split\n",
    "    rows=[]\n",
    "    for split in [\"full_F0\",\"neutral_only_F0\"]:\n",
    "        base_dirs = glob.glob(f\"reports/*E0_noKD*__{split}\")\n",
    "        if not base_dirs: continue\n",
    "        base_dir = sorted(base_dirs)[-1]\n",
    "        df_base  = pd.read_csv(os.path.join(base_dir, \"TEST__per_emotion.csv\"))\n",
    "        for exp in [\"E1_KD_both_base\",\"E2_KD_both_emaware_softgate\",\"E3_KD_both_emaware_hardgate\"]:\n",
    "            exp_dirs = glob.glob(f\"reports/*{exp}*__{split}\")\n",
    "            if not exp_dirs: continue\n",
    "            run_dir = sorted(exp_dirs)[-1]\n",
    "            df_kd   = pd.read_csv(os.path.join(run_dir, \"TEST__per_emotion.csv\"))\n",
    "            m = df_kd.merge(df_base, on=\"emotion\", suffixes=(\"_kd\",\"_base\"))\n",
    "            m[\"ΔF1\"]  = m[\"macro_f1_kd\"] - m[\"macro_f1_base\"]\n",
    "            m[\"ΔAcc\"] = m[\"acc_kd\"]      - m[\"acc_base\"]\n",
    "            for _,r in m.iterrows():\n",
    "                rows.append({\"split\":split,\"exp\":exp,\"emotion\":r[\"emotion\"],\"ΔF1\":r[\"ΔF1\"],\"ΔAcc\":r[\"ΔAcc\"]})\n",
    "    df_delta = pd.DataFrame(rows).sort_values([\"split\",\"exp\",\"emotion\"])\n",
    "    if len(df_delta):\n",
    "        df_delta.to_csv(\"reports/emotion_deltas.csv\", index=False)\n",
    "        print(\"\\nSaved: reports/emotion_deltas.csv\")\n",
    "        print(df_delta.head(12).to_string(index=False))\n",
    "\n",
    "# Esegui!\n",
    "if __name__ == \"__main__\":\n",
    "    run_suite_emotion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc2d75e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'NEWEMODB/manifest_test_full_F0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 293\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[OK] Finito. Riepilogo in:\u001b[39m\u001b[38;5;124m\"\u001b[39m, (Path(OUTDIR) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_all_runs.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 293\u001b[0m     run_all()\n",
      "Cell \u001b[0;32mIn[64], line 255\u001b[0m, in \u001b[0;36mrun_all\u001b[0;34m()\u001b[0m\n\u001b[1;32m    253\u001b[0m loaders: Dict[\u001b[38;5;28mstr\u001b[39m, DataLoader] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m csv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m RUNS)):\n\u001b[0;32m--> 255\u001b[0m     ds \u001b[38;5;241m=\u001b[39m MouthNPYDataset(csv, out_h\u001b[38;5;241m=\u001b[39mH, out_w\u001b[38;5;241m=\u001b[39mW, L\u001b[38;5;241m=\u001b[39mL)\n\u001b[1;32m    256\u001b[0m     loaders[csv] \u001b[38;5;241m=\u001b[39m DataLoader(ds, batch_size\u001b[38;5;241m=\u001b[39mBATCH, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DATA] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: N=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ds)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[64], line 77\u001b[0m, in \u001b[0;36mMouthNPYDataset.__init__\u001b[0;34m(self, csv_path, out_h, out_w, L, label_col, mouth_col, emotion_col)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, csv_path: \u001b[38;5;28mstr\u001b[39m, out_h\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, out_w\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, L\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     76\u001b[0m              label_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, mouth_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmouth_path\u001b[39m\u001b[38;5;124m\"\u001b[39m, emotion_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_path)\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_w, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL \u001b[38;5;241m=\u001b[39m out_h, out_w, L\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_col, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmouth_col, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotion_col \u001b[38;5;241m=\u001b[39m label_col, mouth_col, emotion_col\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'NEWEMODB/manifest_test_full_F0.csv'"
     ]
    }
   ],
   "source": [
    "# ===================== EVAL-ONLY (usa i dataset/funzioni di questo file) =====================\n",
    "\n",
    "# Ordine tabella come in tesi\n",
    "EMO_TEX_ORDER = [\"sorpresa\",\"rabbia\",\"neutro\",\"gioia\",\"paura\",\"disgusto\",\"tristezza\"]\n",
    "\n",
    "def _latex_per_emozione(per_emo_df: pd.DataFrame, ece_df: pd.DataFrame, caption: str, label: str) -> str:\n",
    "    # per_emo_df: colonne ['emotion','acc','macro_f1']\n",
    "    # ece_df:     colonne ['emotion','ECE']\n",
    "    m = per_emo_df.merge(ece_df, on=\"emotion\", how=\"left\")\n",
    "    m[\"ord\"] = m[\"emotion\"].map({n:i for i,n in enumerate(EMO_TEX_ORDER)})\n",
    "    m = m.sort_values(\"ord\").drop(columns=[\"ord\"])\n",
    "    lines = [\n",
    "        r\"\\begin{table}[h!]\",\n",
    "        r\"\\centering\",\n",
    "        rf\"\\caption{{{caption}}}\",\n",
    "        rf\"\\label{{{label}}}\",\n",
    "        r\"\\begin{tabular}{llll}\",\n",
    "        r\"\\hline\",\n",
    "        r\"\\textbf{Emozione} & \\textbf{Accuracy} & \\textbf{Macro-F1} & \\textbf{Calibrazione} \\\\ \\hline\"\n",
    "    ]\n",
    "    for _, r in m.iterrows():\n",
    "        name = str(r[\"emotion\"]).capitalize()\n",
    "        lines.append(f\"{name} & {float(r['acc']):.3f} & {float(r['macro_f1']):.3f} & {float(r['ECE']):.3f} \\\\\\\\\")\n",
    "    lines += [r\"\\hline\", r\"\\end{tabular}\", r\"\\end{table}\"]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def eval_only():\n",
    "    # Usa i test CSV già definiti nello script\n",
    "    TEST_FULL   = DATA_SPLITS[\"full_F0\"][\"test\"]\n",
    "    TEST_NEUTRO = DATA_SPLITS[\"neutral_only_F0\"][\"test\"]\n",
    "\n",
    "    # Elenco best checkpoint da valutare (gli stessi dei log)\n",
    "    EVALS = [\n",
    "        # Emotion-ON (full_F0)\n",
    "        dict(name=\"E0_noKD__full_F0\",\n",
    "             csv=TEST_FULL,\n",
    "             ckpt=\"ckpts/E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E1_KD_both_base__full_F0\",\n",
    "             csv=TEST_FULL,\n",
    "             ckpt=\"ckpts/E1_KD_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E2_KD_both_emaware_softgate__full_F0\",\n",
    "             csv=TEST_FULL,\n",
    "             ckpt=\"ckpts/E2_KD_both_emaware_softgate__full_F0__L21__top1__mid0.5__p1__schedwarmup__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E3_KD_both_emaware_hardgate__full_F0\",\n",
    "             csv=TEST_FULL,\n",
    "             ckpt=\"ckpts/E3_KD_both_emaware_hardgate__full_F0__L21__top1__mid0.5__p1__schedwarmup__gatehard/best_student.pt\"),\n",
    "\n",
    "        # Emotion-OFF (neutral_only_F0)\n",
    "        dict(name=\"E0_noKD__neutral_only_F0\",\n",
    "             csv=TEST_NEUTRO,\n",
    "             ckpt=\"ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E1_KD_both_base__neutral_only_F0\",\n",
    "             csv=TEST_NEUTRO,\n",
    "             ckpt=\"ckpts/E1_KD_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E2_KD_both_emaware_softgate__neutral_only_F0\",\n",
    "             csv=TEST_NEUTRO,\n",
    "             ckpt=\"ckpts/E2_KD_both_emaware_softgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E3_KD_both_emaware_hardgate__neutral_only_F0\",\n",
    "             csv=TEST_NEUTRO,\n",
    "             ckpt=\"ckpts/E3_KD_both_emaware_hardgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatehard/best_student.pt\"),\n",
    "    ]\n",
    "\n",
    "    out_root = Path(\"reports_eval_only\"); out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Moduli \"segnaposto\": evaluate_emotion non usa i teacher in eval (need_teacher=False),\n",
    "    # ma richiede questi argomenti; passiamo Linear/Identity dummy.\n",
    "    dummy_proj_top = nn.Linear(512, 128)\n",
    "    dummy_proj_mid = nn.Linear(512, 512)\n",
    "    dummy_top_adapter = nn.Identity()\n",
    "    dummy_mid_adapter = nn.Identity()\n",
    "\n",
    "    for e in EVALS:\n",
    "        name, csv, ckpt = e[\"name\"], e[\"csv\"], e[\"ckpt\"]\n",
    "        run_dir = out_root / name\n",
    "        run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        rep = evaluate_emotion(\n",
    "            csv_path=csv,\n",
    "            ckpt_path=ckpt,\n",
    "            proj_l11_top=dummy_proj_top,\n",
    "            proj_l10_mid=dummy_proj_mid,\n",
    "            top_adapter=dummy_top_adapter,\n",
    "            mid_adapter=dummy_mid_adapter,\n",
    "            proj_dim=128,\n",
    "            run_dir=str(run_dir),\n",
    "            title=\"TEST\"\n",
    "        )\n",
    "\n",
    "        # Genera tabella LaTeX (Accuracy, Macro-F1, ECE per emozione)\n",
    "        split_label = \"full\\\\_F0\" if \"full_F0\" in name else \"neutral\\\\_only\\\\_F0\"\n",
    "        caption = f\"Prestazioni per emozione — {name.replace('_','\\\\_')}\"\n",
    "        label   = f\"tab:per-emozione-{name.replace('_','-')}\"\n",
    "        tex = _latex_per_emozione(rep[\"per_emotion\"], rep[\"ece\"], caption, label)\n",
    "        (run_dir / f\"per_emozione_{name}.tex\").write_text(tex, encoding=\"utf-8\")\n",
    "\n",
    "        # Stampa quick log e LaTeX per copia/collo\n",
    "        print(f\"\\n[{name}] N={rep['N']}  Acc={rep['acc']:.3f}  Macro-F1={rep['macro_f1']:.3f}  ESI={rep['esi']:.3f}  WorstAcc={rep['worst_acc']:.3f}\")\n",
    "        print(\"\\n----- Tabella LaTeX -----\\n\")\n",
    "        print(tex)\n",
    "        print(\"\\n-------------------------\")\n",
    "\n",
    "# ===== Entry point =====\n",
    "if __name__ == \"__main__\":\n",
    "    # Commenta la riga sotto se non vuoi più allenare:\n",
    "    # run_suite_emotion()\n",
    "\n",
    "    # Esegui solo la valutazione dai checkpoint best:\n",
    "    eval_only()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d338413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DEVICE: cpu\n",
      "\n",
      "===== TRAIN E0_noKD (full_F0) | L2=False  top=0.0 mid=0.0  p=0.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.578\n",
      "    en  it  es\n",
      "en  38  31   0\n",
      "it   0  32  17\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.578  saved: ckpts/E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.695\n",
      "    en  it  es\n",
      "en  22  47   0\n",
      "it   0  48   1\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.695  saved: ckpts/E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 03  Val-F1=0.682\n",
      "    en  it  es\n",
      "en  28  41   0\n",
      "it   2  44   3\n",
      "es   0   0   7\n",
      "Epoch 04  Val-F1=0.647\n",
      "    en  it  es\n",
      "en  22  47   0\n",
      "it   1  45   3\n",
      "es   0   0   7\n",
      "Epoch 05  Val-F1=0.714\n",
      "    en  it  es\n",
      "en  48  21   0\n",
      "it   8  40   1\n",
      "es   0   3   4\n",
      "  → New best: Val-F1=0.714  saved: ckpts/E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 06  Val-F1=0.572\n",
      "    en  it  es\n",
      "en  16  53   0\n",
      "it   0  44   5\n",
      "es   0   0   7\n",
      "Epoch 07  Val-F1=0.816\n",
      "    en  it  es\n",
      "en  46  23   0\n",
      "it   5  43   1\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.816  saved: ckpts/E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 08  Val-F1=0.645\n",
      "    en  it  es\n",
      "en  39  30   0\n",
      "it   8  41   0\n",
      "es   0   4   3\n",
      "Epoch 09  Val-F1=0.615\n",
      "    en  it  es\n",
      "en  17  52   0\n",
      "it   0  46   3\n",
      "es   0   0   7\n",
      "Epoch 10  Val-F1=0.760\n",
      "    en  it  es\n",
      "en  67   2   0\n",
      "it   7  40   2\n",
      "es   0   4   3\n",
      "Epoch 11  Val-F1=0.735\n",
      "    en  it  es\n",
      "en  59  10   0\n",
      "it  14  34   1\n",
      "es   0   3   4\n",
      "Epoch 12  Val-F1=0.559\n",
      "    en  it  es\n",
      "en  69   0   0\n",
      "it  14  35   0\n",
      "es   0   7   0\n",
      "Epoch 13  Val-F1=0.489\n",
      "    en  it  es\n",
      "en  14  55   0\n",
      "it   0  39  10\n",
      "es   0   0   7\n",
      "Epoch 14  Val-F1=0.608\n",
      "    en  it  es\n",
      "en  69   0   0\n",
      "it  14  16  19\n",
      "es   0   0   7\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.816\n",
      "\n",
      "[TEST] N=167  Acc=0.593  Macro-F1=0.613\n",
      "    en  it  es\n",
      "en  51  32   0\n",
      "it  29  41   0\n",
      "es   0   7   7\n",
      "\n",
      "===== TRAIN E1b_noGate_both_base (full_F0) | L2=True  top=1.0 mid=0.5  p=1.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.370\n",
      "    en  it  es\n",
      "en  34  23  12\n",
      "it   4  10  35\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.370  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.471\n",
      "    en  it  es\n",
      "en  48  21   0\n",
      "it   1  13  35\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.471  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 03  Val-F1=0.411\n",
      "    en  it  es\n",
      "en  14  55   0\n",
      "it   0  31  18\n",
      "es   0   0   7\n",
      "Epoch 04  Val-F1=0.572\n",
      "    en  it  es\n",
      "en  69   0   0\n",
      "it  14  13  22\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.572  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 05  Val-F1=0.582\n",
      "    en  it  es\n",
      "en  20  49   0\n",
      "it   4  40   5\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.582  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 06  Val-F1=0.784\n",
      "    en  it  es\n",
      "en  69   0   0\n",
      "it  14  29   6\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.784  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 07  Val-F1=0.737\n",
      "    en  it  es\n",
      "en  31  38   0\n",
      "it   3  46   0\n",
      "es   0   1   6\n",
      "Epoch 08  Val-F1=0.743\n",
      "    en  it  es\n",
      "en  44  25   0\n",
      "it   8  38   3\n",
      "es   0   0   7\n",
      "Epoch 09  Val-F1=0.863\n",
      "    en  it  es\n",
      "en  69   0   0\n",
      "it  14  33   2\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.863  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 10  Val-F1=0.862\n",
      "    en  it  es\n",
      "en  63   6   0\n",
      "it   9  38   2\n",
      "es   0   0   7\n",
      "Epoch 11  Val-F1=0.841\n",
      "    en  it  es\n",
      "en  69   0   0\n",
      "it  14  32   3\n",
      "es   0   0   7\n",
      "Epoch 12  Val-F1=0.841\n",
      "    en  it  es\n",
      "en  69   0   0\n",
      "it  14  32   3\n",
      "es   0   0   7\n",
      "Epoch 13  Val-F1=0.573\n",
      "    en  it  es\n",
      "en  14  55   0\n",
      "it   0  45   4\n",
      "es   0   0   7\n",
      "Epoch 14  Val-F1=0.671\n",
      "    en  it  es\n",
      "en  19  50   0\n",
      "it   0  49   0\n",
      "es   0   1   6\n",
      "Epoch 15  Val-F1=0.859\n",
      "    en  it  es\n",
      "en  59  10   0\n",
      "it   6  41   2\n",
      "es   0   0   7\n",
      "Epoch 16  Val-F1=0.820\n",
      "    en  it  es\n",
      "en  69   0   0\n",
      "it  14  31   4\n",
      "es   0   0   7\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.863\n",
      "\n",
      "[TEST] N=167  Acc=0.659  Macro-F1=0.703\n",
      "    en  it  es\n",
      "en  79   4   0\n",
      "it  53  17   0\n",
      "es   0   0  14\n",
      "\n",
      "===== TRAIN E4_noGate_top_only (full_F0) | L2=True  top=1.0 mid=0.0  p=1.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.355\n",
      "    en  it  es\n",
      "en  36  25   8\n",
      "it   5   7  37\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.355  saved: ckpts/E4_noGate_top_only__full_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.309\n",
      "    en  it  es\n",
      "en  18  45   6\n",
      "it   0  14  35\n",
      "es   0   0   7\n",
      "Epoch 03  Val-F1=0.393\n",
      "    en  it  es\n",
      "en  67   2   0\n",
      "it  14   0  35\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.393  saved: ckpts/E4_noGate_top_only__full_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 04  Val-F1=0.542\n",
      "    en  it  es\n",
      "en  65   4   0\n",
      "it  14  12  23\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.542  saved: ckpts/E4_noGate_top_only__full_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 05  Val-F1=0.666\n",
      "    en  it  es\n",
      "en  24  45   0\n",
      "it   0  46   3\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.666  saved: ckpts/E4_noGate_top_only__full_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 06  Val-F1=0.640\n",
      "    en  it  es\n",
      "en  68   1   0\n",
      "it  14  35   0\n",
      "es   0   6   1\n",
      "Epoch 07  Val-F1=0.657\n",
      "    en  it  es\n",
      "en  25  44   0\n",
      "it   0  48   1\n",
      "es   0   2   5\n",
      "Epoch 08  Val-F1=0.580\n",
      "    en  it  es\n",
      "en  60   9   0\n",
      "it  13  34   2\n",
      "es   0   6   1\n",
      "Epoch 09  Val-F1=0.597\n",
      "    en  it  es\n",
      "en  11  58   0\n",
      "it   3  45   1\n",
      "es   0   0   7\n",
      "Epoch 10  Val-F1=0.499\n",
      "    en  it  es\n",
      "en  56  13   0\n",
      "it  13  36   0\n",
      "es   0   7   0\n",
      "Epoch 11  Val-F1=0.492\n",
      "    en  it  es\n",
      "en  28  41   0\n",
      "it   0  29  20\n",
      "es   0   0   7\n",
      "Epoch 12  Val-F1=0.665\n",
      "    en  it  es\n",
      "en  45  24   0\n",
      "it   6  34   9\n",
      "es   0   0   7\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.666\n",
      "\n",
      "[TEST] N=167  Acc=0.539  Macro-F1=0.595\n",
      "    en  it  es\n",
      "en  32  51   0\n",
      "it  18  45   7\n",
      "es   0   1  13\n",
      "\n",
      "===== TRAIN E7_noGate_mid_only (full_F0) | L2=True  top=0.0 mid=0.5  p=1.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.464\n",
      "    en  it  es\n",
      "en  40  29   0\n",
      "it  10  16  23\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.464  saved: ckpts/E7_noGate_mid_only__full_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.767\n",
      "    en  it  es\n",
      "en  69   0   0\n",
      "it  14  28   7\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.767  saved: ckpts/E7_noGate_mid_only__full_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 03  Val-F1=0.908\n",
      "    en  it  es\n",
      "en  68   1   0\n",
      "it  14  35   0\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.908  saved: ckpts/E7_noGate_mid_only__full_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 04  Val-F1=0.640\n",
      "    en  it  es\n",
      "en  44  25   0\n",
      "it   7  32  10\n",
      "es   0   0   7\n",
      "Epoch 05  Val-F1=0.526\n",
      "    en  it  es\n",
      "en  14  55   0\n",
      "it   0  42   7\n",
      "es   0   0   7\n",
      "Epoch 06  Val-F1=0.666\n",
      "    en  it  es\n",
      "en  66   3   0\n",
      "it  14  22  13\n",
      "es   0   0   7\n",
      "Epoch 07  Val-F1=0.646\n",
      "    en  it  es\n",
      "en  45  24   0\n",
      "it   9  31   9\n",
      "es   0   0   7\n",
      "Epoch 08  Val-F1=0.659\n",
      "    en  it  es\n",
      "en  34  35   0\n",
      "it   1  41   7\n",
      "es   0   0   7\n",
      "Epoch 09  Val-F1=0.635\n",
      "    en  it  es\n",
      "en  32  37   0\n",
      "it   3  39   7\n",
      "es   0   0   7\n",
      "Epoch 10  Val-F1=0.881\n",
      "    en  it  es\n",
      "en  68   1   0\n",
      "it  14  34   1\n",
      "es   0   0   7\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.908\n",
      "\n",
      "[TEST] N=167  Acc=0.545  Macro-F1=0.436\n",
      "    en  it  es\n",
      "en  80   3   0\n",
      "it  63   7   0\n",
      "es   0  10   4\n",
      "\n",
      "===== TRAIN E5_noGate_light (full_F0) | L2=True  top=0.5 mid=0.25  p=0.3 sched=warmup gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.438\n",
      "    en  it  es\n",
      "en  45  23   1\n",
      "it   6  11  32\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.438  saved: ckpts/E5_noGate_light__full_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.431\n",
      "    en  it  es\n",
      "en  19  42   8\n",
      "it   0  39  10\n",
      "es   0   3   4\n",
      "Epoch 03  Val-F1=0.333\n",
      "    en  it  es\n",
      "en   4  65   0\n",
      "it   0  32  17\n",
      "es   0   0   7\n",
      "Epoch 04  Val-F1=0.529\n",
      "    en  it  es\n",
      "en  16  53   0\n",
      "it   0  41   8\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.529  saved: ckpts/E5_noGate_light__full_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 05  Val-F1=0.622\n",
      "    en  it  es\n",
      "en  64   5   0\n",
      "it  11  20  18\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.622  saved: ckpts/E5_noGate_light__full_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 06  Val-F1=0.751\n",
      "    en  it  es\n",
      "en  33  36   0\n",
      "it   3  45   1\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.751  saved: ckpts/E5_noGate_light__full_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 07  Val-F1=0.664\n",
      "    en  it  es\n",
      "en  26  43   0\n",
      "it   3  43   3\n",
      "es   0   0   7\n",
      "Epoch 08  Val-F1=0.702\n",
      "    en  it  es\n",
      "en  40  29   0\n",
      "it   5  39   5\n",
      "es   0   0   7\n",
      "Epoch 09  Val-F1=0.536\n",
      "    en  it  es\n",
      "en  17  52   0\n",
      "it   0  41   8\n",
      "es   0   0   7\n",
      "Epoch 10  Val-F1=0.572\n",
      "    en  it  es\n",
      "en  20  49   0\n",
      "it   0  42   7\n",
      "es   0   0   7\n",
      "Epoch 11  Val-F1=0.881\n",
      "    en  it  es\n",
      "en  68   1   0\n",
      "it  14  34   1\n",
      "es   0   0   7\n",
      "  → New best: Val-F1=0.881  saved: ckpts/E5_noGate_light__full_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 12  Val-F1=0.707\n",
      "    en  it  es\n",
      "en  32  37   0\n",
      "it   2  44   3\n",
      "es   0   0   7\n",
      "Epoch 13  Val-F1=0.663\n",
      "    en  it  es\n",
      "en  28  41   0\n",
      "it   2  43   4\n",
      "es   0   0   7\n",
      "Epoch 14  Val-F1=0.809\n",
      "    en  it  es\n",
      "en  67   2   0\n",
      "it  14  31   4\n",
      "es   0   0   7\n",
      "Epoch 15  Val-F1=0.755\n",
      "    en  it  es\n",
      "en  42  27   0\n",
      "it   4  42   3\n",
      "es   0   0   7\n",
      "Epoch 16  Val-F1=0.725\n",
      "    en  it  es\n",
      "en  34  35   0\n",
      "it   1  45   3\n",
      "es   0   0   7\n",
      "Epoch 17  Val-F1=0.533\n",
      "    en  it  es\n",
      "en  61   8   0\n",
      "it  11  37   1\n",
      "es   0   7   0\n",
      "Epoch 18  Val-F1=0.796\n",
      "    en  it  es\n",
      "en  54  15   0\n",
      "it  11  37   1\n",
      "es   0   1   6\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.881\n",
      "\n",
      "[TEST] N=167  Acc=0.563  Macro-F1=0.502\n",
      "    en  it  es\n",
      "en  79   4   0\n",
      "it  61   9   0\n",
      "es   0   8   6\n",
      "\n",
      "===== TRAIN E0_noKD (neutral_only_F0) | L2=False  top=0.0 mid=0.0  p=0.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.381\n",
      "    en  it  es\n",
      "en   9   1   0\n",
      "it   2   0   5\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.381  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.355\n",
      "    en  it  es\n",
      "en   5   5   0\n",
      "it   1   1   5\n",
      "es   0   0   1\n",
      "Epoch 03  Val-F1=0.467\n",
      "    en  it  es\n",
      "en   5   5   0\n",
      "it   0   3   4\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.467  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 04  Val-F1=0.475\n",
      "    en  it  es\n",
      "en   5   5   0\n",
      "it   1   3   3\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.475  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 05  Val-F1=0.725\n",
      "    en  it  es\n",
      "en   5   5   0\n",
      "it   2   5   0\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.725  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 06  Val-F1=0.600\n",
      "    en  it  es\n",
      "en   8   2   0\n",
      "it   2   3   2\n",
      "es   0   0   1\n",
      "Epoch 07  Val-F1=0.685\n",
      "    en  it  es\n",
      "en   4   6   0\n",
      "it   2   5   0\n",
      "es   0   0   1\n",
      "Epoch 08  Val-F1=0.388\n",
      "    en  it  es\n",
      "en   4   5   1\n",
      "it   1   6   0\n",
      "es   0   1   0\n",
      "Epoch 09  Val-F1=0.546\n",
      "    en  it  es\n",
      "en   7   3   0\n",
      "it   1   3   3\n",
      "es   0   0   1\n",
      "Epoch 10  Val-F1=0.843\n",
      "    en  it  es\n",
      "en   7   3   0\n",
      "it   1   6   0\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.843  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 11  Val-F1=0.333\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   3   4\n",
      "es   0   0   1\n",
      "Epoch 12  Val-F1=0.670\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   3   2\n",
      "es   0   0   1\n",
      "Epoch 13  Val-F1=0.366\n",
      "    en  it  es\n",
      "en   4   6   0\n",
      "it   0   5   2\n",
      "es   0   1   0\n",
      "Epoch 14  Val-F1=0.566\n",
      "    en  it  es\n",
      "en   7   3   0\n",
      "it   2   3   2\n",
      "es   0   0   1\n",
      "Epoch 15  Val-F1=0.616\n",
      "    en  it  es\n",
      "en   7   3   0\n",
      "it   1   4   2\n",
      "es   0   0   1\n",
      "Epoch 16  Val-F1=0.838\n",
      "    en  it  es\n",
      "en   8   2   0\n",
      "it   2   5   0\n",
      "es   0   0   1\n",
      "Epoch 17  Val-F1=0.378\n",
      "    en  it  es\n",
      "en   4   6   0\n",
      "it   1   2   4\n",
      "es   0   0   1\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.843\n",
      "\n",
      "[TEST] N=167  Acc=0.599  Macro-F1=0.687\n",
      "    en  it  es\n",
      "en  59  24   0\n",
      "it  42  28   0\n",
      "es   0   1  13\n",
      "\n",
      "===== TRAIN E1b_noGate_both_base (neutral_only_F0) | L2=True  top=1.0 mid=0.5  p=1.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.279\n",
      "    en  it  es\n",
      "en   3   5   2\n",
      "it   0   3   4\n",
      "es   0   1   0\n",
      "  → New best: Val-F1=0.279  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.283\n",
      "    en  it  es\n",
      "en   3   7   0\n",
      "it   1   1   5\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.283  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 03  Val-F1=0.153\n",
      "    en  it  es\n",
      "en   0   8   2\n",
      "it   0   2   5\n",
      "es   0   0   1\n",
      "Epoch 04  Val-F1=0.103\n",
      "    en  it  es\n",
      "en   0   6   4\n",
      "it   0   1   6\n",
      "es   0   0   1\n",
      "Epoch 05  Val-F1=0.376\n",
      "    en  it  es\n",
      "en   6   2   2\n",
      "it   1   1   5\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.376  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 06  Val-F1=0.481\n",
      "    en  it  es\n",
      "en   7   3   0\n",
      "it   1   2   4\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.481  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 07  Val-F1=0.375\n",
      "    en  it  es\n",
      "en   4   6   0\n",
      "it   0   2   5\n",
      "es   0   0   1\n",
      "Epoch 08  Val-F1=0.497\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   1   4\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.497  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 09  Val-F1=0.471\n",
      "    en  it  es\n",
      "en   9   1   0\n",
      "it   2   1   4\n",
      "es   0   0   1\n",
      "Epoch 10  Val-F1=0.292\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   1   2   4\n",
      "es   0   0   1\n",
      "Epoch 11  Val-F1=0.585\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   2   3\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.585  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 12  Val-F1=0.546\n",
      "    en  it  es\n",
      "en   7   3   0\n",
      "it   1   3   3\n",
      "es   0   0   1\n",
      "Epoch 13  Val-F1=0.333\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   3   4\n",
      "es   0   0   1\n",
      "Epoch 14  Val-F1=0.585\n",
      "    en  it  es\n",
      "en   5   5   0\n",
      "it   0   5   2\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.585  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 15  Val-F1=0.496\n",
      "    en  it  es\n",
      "en   3   7   0\n",
      "it   0   5   2\n",
      "es   0   0   1\n",
      "Epoch 16  Val-F1=0.314\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   7   0\n",
      "es   0   1   0\n",
      "Epoch 17  Val-F1=0.585\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   2   3\n",
      "es   0   0   1\n",
      "Epoch 18  Val-F1=0.566\n",
      "    en  it  es\n",
      "en   7   3   0\n",
      "it   2   3   2\n",
      "es   0   0   1\n",
      "Epoch 19  Val-F1=0.496\n",
      "    en  it  es\n",
      "en   3   7   0\n",
      "it   0   5   2\n",
      "es   0   0   1\n",
      "Epoch 20  Val-F1=0.566\n",
      "    en  it  es\n",
      "en   7   3   0\n",
      "it   2   3   2\n",
      "es   0   0   1\n",
      "Epoch 21  Val-F1=0.542\n",
      "    en  it  es\n",
      "en   4   6   0\n",
      "it   0   5   2\n",
      "es   0   0   1\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.585\n",
      "\n",
      "[TEST] N=167  Acc=0.581  Macro-F1=0.513\n",
      "    en  it  es\n",
      "en  44  39   0\n",
      "it  20  50   0\n",
      "es   0  11   3\n",
      "\n",
      "===== TRAIN E4_noGate_top_only (neutral_only_F0) | L2=True  top=1.0 mid=0.0  p=1.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.291\n",
      "    en  it  es\n",
      "en   6   0   4\n",
      "it   1   0   6\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.291  saved: ckpts/E4_noGate_top_only__neutral_only_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.282\n",
      "    en  it  es\n",
      "en   5   4   1\n",
      "it   1   0   6\n",
      "es   0   0   1\n",
      "Epoch 03  Val-F1=0.244\n",
      "    en  it  es\n",
      "en   4   4   2\n",
      "it   1   0   6\n",
      "es   0   0   1\n",
      "Epoch 04  Val-F1=0.103\n",
      "    en  it  es\n",
      "en   0   4   6\n",
      "it   0   1   6\n",
      "es   0   0   1\n",
      "Epoch 05  Val-F1=0.103\n",
      "    en  it  es\n",
      "en   0   6   4\n",
      "it   0   1   6\n",
      "es   0   0   1\n",
      "Epoch 06  Val-F1=0.150\n",
      "    en  it  es\n",
      "en   0   7   3\n",
      "it   0   2   5\n",
      "es   0   0   1\n",
      "Epoch 07  Val-F1=0.312\n",
      "    en  it  es\n",
      "en   4   5   1\n",
      "it   1   1   5\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.312  saved: ckpts/E4_noGate_top_only__neutral_only_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 08  Val-F1=0.190\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   2   0   5\n",
      "es   0   0   1\n",
      "Epoch 09  Val-F1=0.296\n",
      "    en  it  es\n",
      "en   6   2   2\n",
      "it   2   0   5\n",
      "es   0   0   1\n",
      "Epoch 10  Val-F1=0.398\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   0   5\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.398  saved: ckpts/E4_noGate_top_only__neutral_only_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 11  Val-F1=0.552\n",
      "    en  it  es\n",
      "en   9   1   0\n",
      "it   2   2   3\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.552  saved: ckpts/E4_noGate_top_only__neutral_only_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 12  Val-F1=0.435\n",
      "    en  it  es\n",
      "en   3   7   0\n",
      "it   0   4   3\n",
      "es   0   0   1\n",
      "Epoch 13  Val-F1=0.190\n",
      "    en  it  es\n",
      "en   1   9   0\n",
      "it   1   1   5\n",
      "es   0   0   1\n",
      "Epoch 14  Val-F1=0.634\n",
      "    en  it  es\n",
      "en   9   1   0\n",
      "it   2   3   2\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.634  saved: ckpts/E4_noGate_top_only__neutral_only_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 15  Val-F1=0.497\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   1   4\n",
      "es   0   0   1\n",
      "Epoch 16  Val-F1=0.652\n",
      "    en  it  es\n",
      "en   8   2   0\n",
      "it   1   4   2\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.652  saved: ckpts/E4_noGate_top_only__neutral_only_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 17  Val-F1=0.634\n",
      "    en  it  es\n",
      "en   9   1   0\n",
      "it   2   3   2\n",
      "es   0   0   1\n",
      "Epoch 18  Val-F1=0.546\n",
      "    en  it  es\n",
      "en   7   3   0\n",
      "it   1   3   3\n",
      "es   0   0   1\n",
      "Epoch 19  Val-F1=0.585\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   2   3\n",
      "es   0   0   1\n",
      "Epoch 20  Val-F1=0.333\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   3   4\n",
      "es   0   0   1\n",
      "Epoch 21  Val-F1=0.882\n",
      "    en  it  es\n",
      "en   7   3   0\n",
      "it   0   7   0\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.882  saved: ckpts/E4_noGate_top_only__neutral_only_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 22  Val-F1=0.524\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   6   1\n",
      "es   0   0   1\n",
      "Epoch 23  Val-F1=0.333\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   3   4\n",
      "es   0   0   1\n",
      "Epoch 24  Val-F1=0.444\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   5   2\n",
      "es   0   0   1\n",
      "Epoch 25  Val-F1=0.652\n",
      "    en  it  es\n",
      "en   8   2   0\n",
      "it   1   4   2\n",
      "es   0   0   1\n",
      "Epoch 26  Val-F1=0.444\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   5   2\n",
      "es   0   0   1\n",
      "Epoch 27  Val-F1=0.542\n",
      "    en  it  es\n",
      "en   5   5   0\n",
      "it   1   4   2\n",
      "es   0   0   1\n",
      "Epoch 28  Val-F1=0.471\n",
      "    en  it  es\n",
      "en   9   1   0\n",
      "it   2   1   4\n",
      "es   0   0   1\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.882\n",
      "\n",
      "[TEST] N=167  Acc=0.557  Macro-F1=0.427\n",
      "    en  it  es\n",
      "en  51  32   0\n",
      "it  28  41   1\n",
      "es   0  13   1\n",
      "\n",
      "===== TRAIN E7_noGate_mid_only (neutral_only_F0) | L2=True  top=0.0 mid=0.5  p=1.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.123\n",
      "    en  it  es\n",
      "en   0   9   1\n",
      "it   1   1   5\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.123  saved: ckpts/E7_noGate_mid_only__neutral_only_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.277\n",
      "    en  it  es\n",
      "en   1   9   0\n",
      "it   0   3   4\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.277  saved: ckpts/E7_noGate_mid_only__neutral_only_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 03  Val-F1=0.657\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   7   0\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.657  saved: ckpts/E7_noGate_mid_only__neutral_only_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 04  Val-F1=0.528\n",
      "    en  it  es\n",
      "en   0  10   0\n",
      "it   0   7   0\n",
      "es   0   0   1\n",
      "Epoch 05  Val-F1=0.500\n",
      "    en  it  es\n",
      "en   4   5   1\n",
      "it   2   4   1\n",
      "es   0   0   1\n",
      "Epoch 06  Val-F1=0.694\n",
      "    en  it  es\n",
      "en   8   2   0\n",
      "it   2   4   1\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.694  saved: ckpts/E7_noGate_mid_only__neutral_only_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 07  Val-F1=0.497\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   1   4\n",
      "es   0   0   1\n",
      "Epoch 08  Val-F1=0.801\n",
      "    en  it  es\n",
      "en   5   5   0\n",
      "it   0   7   0\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.801  saved: ckpts/E7_noGate_mid_only__neutral_only_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 09  Val-F1=0.444\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   5   2\n",
      "es   0   0   1\n",
      "Epoch 10  Val-F1=0.524\n",
      "    en  it  es\n",
      "en   9   1   0\n",
      "it   2   5   0\n",
      "es   0   1   0\n",
      "Epoch 11  Val-F1=0.321\n",
      "    en  it  es\n",
      "en   4   6   0\n",
      "it   1   1   5\n",
      "es   0   0   1\n",
      "Epoch 12  Val-F1=0.444\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   5   2\n",
      "es   0   0   1\n",
      "Epoch 13  Val-F1=0.559\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   5   0\n",
      "es   0   1   0\n",
      "Epoch 14  Val-F1=0.444\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   5   2\n",
      "es   0   0   1\n",
      "Epoch 15  Val-F1=0.444\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   5   2\n",
      "es   0   0   1\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.801\n",
      "\n",
      "[TEST] N=167  Acc=0.473  Macro-F1=0.335\n",
      "    en  it  es\n",
      "en  63  20   0\n",
      "it  53  15   2\n",
      "es   0  13   1\n",
      "\n",
      "===== TRAIN E5_noGate_light (neutral_only_F0) | L2=True  top=0.5 mid=0.25  p=0.3 sched=warmup gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.083\n",
      "    en  it  es\n",
      "en   0   6   4\n",
      "it   0   2   5\n",
      "es   0   1   0\n",
      "  → New best: Val-F1=0.083  saved: ckpts/E5_noGate_light__neutral_only_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.324\n",
      "    en  it  es\n",
      "en   2   7   1\n",
      "it   0   3   4\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.324  saved: ckpts/E5_noGate_light__neutral_only_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 03  Val-F1=0.326\n",
      "    en  it  es\n",
      "en   3   6   1\n",
      "it   0   2   5\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.326  saved: ckpts/E5_noGate_light__neutral_only_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 04  Val-F1=0.419\n",
      "    en  it  es\n",
      "en   4   5   1\n",
      "it   0   3   4\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.419  saved: ckpts/E5_noGate_light__neutral_only_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 05  Val-F1=0.323\n",
      "    en  it  es\n",
      "en   3   4   3\n",
      "it   0   2   5\n",
      "es   0   0   1\n",
      "Epoch 06  Val-F1=0.722\n",
      "    en  it  es\n",
      "en   4   6   0\n",
      "it   1   6   0\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.722  saved: ckpts/E5_noGate_light__neutral_only_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 07  Val-F1=0.343\n",
      "    en  it  es\n",
      "en   5   3   2\n",
      "it   1   1   5\n",
      "es   0   0   1\n",
      "Epoch 08  Val-F1=0.398\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   0   5\n",
      "es   0   0   1\n",
      "Epoch 09  Val-F1=0.444\n",
      "    en  it  es\n",
      "en   8   2   0\n",
      "it   2   1   4\n",
      "es   0   0   1\n",
      "Epoch 10  Val-F1=0.658\n",
      "    en  it  es\n",
      "en   7   3   0\n",
      "it   2   4   1\n",
      "es   0   0   1\n",
      "Epoch 11  Val-F1=0.497\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   1   4\n",
      "es   0   0   1\n",
      "Epoch 12  Val-F1=0.398\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   0   5\n",
      "es   0   0   1\n",
      "Epoch 13  Val-F1=0.663\n",
      "    en  it  es\n",
      "en   7   3   0\n",
      "it   0   5   2\n",
      "es   0   0   1\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.722\n",
      "\n",
      "[TEST] N=167  Acc=0.467  Macro-F1=0.496\n",
      "    en  it  es\n",
      "en  52  31   0\n",
      "it  48  17   5\n",
      "es   0   5   9\n",
      "\n",
      "================ EMOTION-KD (NO-GATE) SUMMARY ================\n",
      "                 run           split  USE_L2_ML  L2_top  L2_mid  L2_apply_prob L2_schedule gate_mode  gate_thresh emo_weights  best_val_macro_f1  test_macro_f1  test_acc  test_esi  test_worst_emotion_acc                                                                                     run_name  ΔF1_vs_noKD  ΔESI_vs_noKD  ΔWorst_vs_noKD\n",
      "             E0_noKD         full_F0          0     0.0    0.00            0.0       const      none          0.6        none           0.815942       0.613033  0.592814  0.154888                0.541667                         E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone     0.000000      0.000000        0.000000\n",
      "E1b_noGate_both_base         full_F0          1     1.0    0.50            1.0       const      none          0.6        none           0.862591       0.702837  0.658683  0.034432                0.625000          E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone     0.089803      0.120456        0.083333\n",
      "  E4_noGate_top_only         full_F0          1     1.0    0.00            1.0       const      none          0.6        none           0.665600       0.594944  0.538922  0.053463                0.458333              E4_noGate_top_only__full_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone    -0.018090      0.101425       -0.083333\n",
      "     E5_noGate_light         full_F0          1     0.5    0.25            0.3      warmup      none          0.6        none           0.881173       0.502107  0.562874  0.091628                0.541667         E5_noGate_light__full_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone    -0.110926      0.063260        0.000000\n",
      "  E7_noGate_mid_only         full_F0          1     0.0    0.50            1.0       const      none          0.6        none           0.908064       0.435988  0.544910  0.145540                0.458333            E7_noGate_mid_only__full_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone    -0.177045      0.009347       -0.083333\n",
      "             E0_noKD neutral_only_F0          0     0.0    0.00            0.0       const      none          0.6        none           0.842593       0.686517  0.598802  0.052749                0.521739                 E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone     0.000000      0.000000        0.000000\n",
      "E1b_noGate_both_base neutral_only_F0          1     1.0    0.50            1.0       const      none          0.6        none           0.584967       0.513272  0.580838  0.122109                0.541667  E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone    -0.173245     -0.069360        0.019928\n",
      "  E4_noGate_top_only neutral_only_F0          1     1.0    0.00            1.0       const      none          0.6        none           0.882353       0.426757  0.556886  0.076459                0.500000      E4_noGate_top_only__neutral_only_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone    -0.259760     -0.023710       -0.021739\n",
      "     E5_noGate_light neutral_only_F0          1     0.5    0.25            0.3      warmup      none          0.6        none           0.721637       0.495862  0.467066  0.053049                0.416667 E5_noGate_light__neutral_only_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone    -0.190655     -0.000300       -0.105072\n",
      "  E7_noGate_mid_only neutral_only_F0          1     0.0    0.50            1.0       const      none          0.6        none           0.801170       0.335017  0.473054  0.084570                0.391304    E7_noGate_mid_only__neutral_only_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone    -0.351501     -0.031821       -0.130435\n",
      "\n",
      "Saved: reports/emotion_kd_nogate_summary.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jx/nf2g6k1s1550mrw1rrvdw69h0000gn/T/ipykernel_23627/1121234098.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_delta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;31m# Esegui!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m     \u001b[0mrun_suite_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/jx/nf2g6k1s1550mrw1rrvdw69h0000gn/T/ipykernel_23627/1121234098.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ΔF1\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"macro_f1_kd\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"macro_f1_base\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ΔAcc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc_kd\"\u001b[0m\u001b[0;34m]\u001b[0m      \u001b[0;34m-\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc_base\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"exp\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"emotion\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"emotion\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ΔF1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ΔF1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ΔAcc\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ΔAcc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m     \u001b[0mdf_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"split\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"exp\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"emotion\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_delta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0mdf_delta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reports/emotion_deltas_nogate.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSaved: reports/emotion_deltas_nogate.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6923\u001b[0m                 \u001b[0;34mf\"Length of ascending ({len(ascending)})\"\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6924\u001b[0m                 \u001b[0;34mf\" != length of by ({len(by)})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6925\u001b[0m             )\n\u001b[1;32m   6926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6927\u001b[0;31m             \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6929\u001b[0m             \u001b[0;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6930\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m-> 6927\u001b[0;31m         \u001b[0;34m...\u001b[0m     \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_natsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1840\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1844\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'split'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# Runner KD (mid/top) — emotion-aware + confidence-gate — CPU only\n",
    "# Opzione A: aggiunte varianti NO-GATE e NO-EMOTION-WEIGHTS + apply_prob per \"KD light\"\n",
    "# Richiede gli split:\n",
    "#   - splits_session2/full_F0/{train,val,test}_midtop.csv\n",
    "#   - splits_session2/neutral_only_F0/{train,val,test}_midtop.csv\n",
    "# Colonne richieste nei CSV: mouth_path, (lang|label), (emotion|emotion_id), t_conf, layer10_mean_path, layer11_mean_path\n",
    "\n",
    "import os, json, random, copy, math, contextlib, glob\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.video import r3d_18, R3D_18_Weights\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "# ───────────── Config base ─────────────\n",
    "SEED = 42\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 8\n",
    "LR, WD = 3e-4, 1e-3\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "LANGS = ['en','it','es']\n",
    "OUT_H, OUT_W, L = 64, 64, 32\n",
    "MIXUP_ALPHA = 0.30\n",
    "PATIENCE = 7\n",
    "MAX_LR = 3e-4\n",
    "DIV_FACTOR = 10\n",
    "FINAL_DIV = 100\n",
    "\n",
    "# Splits (usa i tuoi *_midtop.csv)\n",
    "DATA_SPLITS = {\n",
    "    \"full_F0\": {\n",
    "        \"train\": \"splits_session2/full_F0/train_midtop.csv\",\n",
    "        \"val\":   \"splits_session2/full_F0/val_midtop.csv\",\n",
    "        \"test\":  \"splits_session2/full_F0/test_midtop.csv\",\n",
    "    },\n",
    "    \"neutral_only_F0\": {\n",
    "        \"train\": \"splits_session2/neutral_only_F0/train_midtop.csv\",\n",
    "        \"val\":   \"splits_session2/neutral_only_F0/val_midtop.csv\",\n",
    "        \"test\":  \"splits_session2/neutral_only_F0/test_midtop.csv\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# ───────────── Device: forza CPU ─────────────\n",
    "DEVICE = torch.device('cpu')\n",
    "AMP_ENABLED = False\n",
    "PIN_MEMORY  = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "print(\"Using DEVICE:\", DEVICE)\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# Emotion map\n",
    "EMO_ID2NAME = {0:\"neutro\",1:\"rabbia\",2:\"disgusto\",3:\"paura\",4:\"gioia\",5:\"tristezza\",6:\"sorpresa\"}\n",
    "\n",
    "# Pesi emotion-aware (di default; disattivabili con EMO_WEIGHTS_MODE='none')\n",
    "LAM_TOP_EMO = {\"neutro\":0.8,\"rabbia\":1.2,\"disgusto\":1.1,\"paura\":1.3,\"gioia\":1.0,\"tristezza\":1.1,\"sorpresa\":1.2}\n",
    "LAM_MID_EMO = {\"neutro\":0.8,\"rabbia\":1.0,\"disgusto\":1.0,\"paura\":1.1,\"gioia\":0.9,\"tristezza\":1.0,\"sorpresa\":1.0}\n",
    "\n",
    "# ───────────── Metriche ─────────────\n",
    "def macro_f1(y_true, y_pred):\n",
    "    return precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)[2]\n",
    "\n",
    "def ece_by_emotion(df_probs: pd.DataFrame, n_bins: int = 15) -> pd.DataFrame:\n",
    "    rows=[]\n",
    "    for emo, g in df_probs.groupby(\"emotion\"):\n",
    "        probs = g[[\"prob_en\",\"prob_it\",\"prob_es\"]].values\n",
    "        y = g[\"y\"].values.astype(int)\n",
    "        conf = probs.max(axis=1)\n",
    "        pred = probs.argmax(axis=1)\n",
    "        correct = (pred == y).astype(float)\n",
    "        bins = np.linspace(0,1,n_bins+1)\n",
    "        ece=0.0\n",
    "        for i in range(n_bins):\n",
    "            m = (conf>bins[i]) & (conf<=bins[i+1])\n",
    "            if m.sum()==0: continue\n",
    "            ece += abs(correct[m].mean() - conf[m].mean()) * (m.mean())\n",
    "        rows.append({\"emotion\":emo, \"ECE\": float(ece)})\n",
    "    return pd.DataFrame(rows).sort_values(\"emotion\")\n",
    "\n",
    "# ───────────── Augmentazioni ─────────────\n",
    "class SpecAug3D:\n",
    "    def __init__(self, H, W, T_mask=4, S_mask=4):\n",
    "        self.tf = T.Compose([\n",
    "            T.ToPILImage(),\n",
    "            T.RandomResizedCrop((H,W), scale=(0.95,1.0), ratio=(1.0,1.0)),\n",
    "            T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),\n",
    "            T.RandomHorizontalFlip(0.5),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "        self.T_mask, self.S_mask = T_mask, S_mask\n",
    "    def __call__(self, vid):\n",
    "        frames = []\n",
    "        for f in vid:\n",
    "            img = (f*255).byte()\n",
    "            t   = self.tf(img).squeeze(0)\n",
    "            frames.append(t)\n",
    "        vid = torch.stack(frames)\n",
    "        L_,H,W = vid.shape\n",
    "        if L_ > self.T_mask:\n",
    "            t0 = random.randrange(0, L_-self.T_mask+1)\n",
    "            vid[t0:t0+self.T_mask] = 0\n",
    "        if H>self.S_mask and W>self.S_mask:\n",
    "            fi = random.randrange(0, L_)\n",
    "            h0 = random.randrange(0, H-self.S_mask+1)\n",
    "            w0 = random.randrange(0, W-self.S_mask+1)\n",
    "            vid[fi,h0:h0+self.S_mask,w0:w0+self.S_mask] = 0\n",
    "        return vid\n",
    "\n",
    "class RandomErasing3D:\n",
    "    def __init__(self, p=0.3, size=(8,8,8)):\n",
    "        self.p = p; self.d, self.h, self.w = size\n",
    "    def __call__(self, vid):\n",
    "        if random.random()>self.p: return vid\n",
    "        L_,H,W = vid.shape\n",
    "        sd = random.randint(0, max(0, L_-self.d))\n",
    "        sh = random.randint(0, max(0, H-self.h))\n",
    "        sw = random.randint(0, max(0, W-self.w))\n",
    "        vid[sd:sd+self.d, sh:sh+self.h, sw:sw+self.w] = 0\n",
    "        return vid\n",
    "\n",
    "def mixup_return_params(x, y_onehot, alpha=MIXUP_ALPHA):\n",
    "    if alpha <= 0:\n",
    "        B = x.size(0); idx = torch.arange(B, device=x.device); lam = 1.0\n",
    "        return x, y_onehot, lam, idx\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    idx = torch.randperm(x.size(0))\n",
    "    x_m = lam*x + (1-lam)*x[idx]\n",
    "    y_m = lam*y_onehot + (1-lam)*y_onehot[idx]\n",
    "    return x_m, y_m, float(lam), idx\n",
    "\n",
    "# ───────────── Loss ─────────────\n",
    "class SoftFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__(); self.alpha, self.gamma = alpha, gamma\n",
    "    def forward(self, logits, y_soft):\n",
    "        logp = F.log_softmax(logits,1)\n",
    "        p    = logp.exp()\n",
    "        ce   = -(y_soft * logp).sum(1)\n",
    "        pt   = (y_soft * p).sum(1)\n",
    "        return ( self.alpha * (1-pt)**self.gamma * ce ).mean()\n",
    "\n",
    "# ───────────── MixStyle ─────────────\n",
    "class MixStyle(nn.Module):\n",
    "    def __init__(self, p=0.3, α=0.1):\n",
    "        super().__init__(); self.p, self.α = p, α\n",
    "    def forward(self, x):\n",
    "        if not self.training or random.random()>self.p:\n",
    "            return x\n",
    "        B,C = x.shape\n",
    "        mu  = x.mean(1,keepdim=True)\n",
    "        sig = (x.var(1,keepdim=True)+1e-6).sqrt()\n",
    "        lm  = np.random.beta(self.α, self.α)\n",
    "        perm= torch.randperm(B)\n",
    "        mu2, sig2 = mu[perm], sig[perm]\n",
    "        x_norm = (x-mu)/sig\n",
    "        return x_norm*(lm*sig + (1-lm)*sig2) + (lm*mu + (1-lm)*mu2)\n",
    "\n",
    "# ───────────── Dataset ─────────────\n",
    "TEACHER_L10_COL = \"layer10_mean_path\"\n",
    "TEACHER_L11_COL = \"layer11_mean_path\"\n",
    "\n",
    "class MouthDSEmotion(Dataset):\n",
    "    def __init__(self,csv,L=32,augment=False,need_teacher=False):\n",
    "        df = pd.read_csv(csv).copy()\n",
    "        if 'mouth_path' in df.columns:\n",
    "            df = df.query('mouth_path.notna()')\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # lingua\n",
    "        if 'lang' in df.columns:\n",
    "            df['label'] = df['lang'].astype(str).str.lower()\n",
    "        elif 'label' in df.columns:\n",
    "            df['label'] = df['label'].astype(str).str.lower()\n",
    "        else:\n",
    "            raise ValueError(\"Manca colonna lingua: attesa 'lang' o 'label'.\")\n",
    "\n",
    "        # emozione\n",
    "        if 'emotion' not in df.columns and 'emotion_id' in df.columns:\n",
    "            df['emotion'] = df['emotion_id'].map(EMO_ID2NAME)\n",
    "        df['emotion'] = df['emotion'].astype(str)\n",
    "\n",
    "        self.df, self.L = df, L\n",
    "        self.l2i         = {l:i for i,l in enumerate(LANGS)}\n",
    "        self.spec        = SpecAug3D(OUT_H,OUT_W) if augment else None\n",
    "        self.randomerase = RandomErasing3D()      if augment else None\n",
    "        self.need_teacher = need_teacher\n",
    "\n",
    "        if self.need_teacher:\n",
    "            if TEACHER_L10_COL not in self.df.columns or TEACHER_L11_COL not in self.df.columns:\n",
    "                raise ValueError(f\"Per KD servono colonne teacher: '{TEACHER_L10_COL}', '{TEACHER_L11_COL}'.\")\n",
    "\n",
    "    def _align(self,a):\n",
    "        T0 = a.shape[0]\n",
    "        if T0>=self.L: idx = np.linspace(0,T0-1,self.L).astype(int)\n",
    "        else:          idx = np.concatenate([np.arange(T0), np.full(self.L-T0, T0-1)])\n",
    "        return a[idx]\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        r = self.df.iloc[i]\n",
    "        a = np.load(r.mouth_path,allow_pickle=True)\n",
    "        if a.dtype==np.uint8: a = a.astype('float32')/255.\n",
    "        else: a = a.astype('float32')\n",
    "        if a.ndim==4 and a.shape[-1]==3: a = a.mean(-1)\n",
    "        a = self._align(a)\n",
    "\n",
    "        v = torch.from_numpy(a)  # [L,H,W]\n",
    "        if self.spec:        v = self.spec(v)\n",
    "        if self.randomerase: v = self.randomerase(v)\n",
    "        v5 = v.unsqueeze(0).unsqueeze(0)\n",
    "        v5 = F.interpolate(v5, size=(self.L,OUT_H,OUT_W), mode='trilinear', align_corners=False)\n",
    "        x  = (v5 - 0.5)/0.5\n",
    "        x  = x.squeeze(0)                     # [1, L, H, W]\n",
    "        y  = torch.tensor(self.l2i[str(r.label).lower()],dtype=torch.long)\n",
    "        emo = str(r.emotion)\n",
    "        tconf = float(r.get(\"t_conf\", np.nan))\n",
    "\n",
    "        if not self.need_teacher:\n",
    "            return x, y, emo, tconf\n",
    "\n",
    "        l10 = l11 = None\n",
    "        p10 = r.get(TEACHER_L10_COL, None)\n",
    "        p11 = r.get(TEACHER_L11_COL, None)\n",
    "        if isinstance(p10,str) and os.path.exists(p10): l10 = torch.from_numpy(np.load(p10)).float()\n",
    "        if isinstance(p11,str) and os.path.exists(p11): l11 = torch.from_numpy(np.load(p11)).float()\n",
    "        return x, y, emo, tconf, l10, l11\n",
    "\n",
    "def collate_with_optional_teacher(batch):\n",
    "    xs, ys, emos, confs, l10s, l11s = [], [], [], [], [], []\n",
    "    for item in batch:\n",
    "        if len(item)==4:\n",
    "            x,y,emo,tc = item\n",
    "            xs.append(x); ys.append(y); emos.append(emo); confs.append(tc)\n",
    "        else:\n",
    "            x,y,emo,tc,l10,l11 = item\n",
    "            xs.append(x); ys.append(y); emos.append(emo); confs.append(tc); l10s.append(l10); l11s.append(l11)\n",
    "    x = torch.stack(xs,0); y = torch.stack(ys,0)\n",
    "    confs = torch.tensor([0.0 if np.isnan(c) else c for c in confs], dtype=torch.float32)\n",
    "    if len(l10s)==0:\n",
    "        return x, y, emos, confs\n",
    "    return x, y, emos, confs, l10s, l11s\n",
    "\n",
    "# ───────────── Modello ─────────────\n",
    "class Student(nn.Module):\n",
    "    def __init__(self, proj_dim=128):\n",
    "        super().__init__()\n",
    "        try:\n",
    "            self.backbone = r3d_18(weights=R3D_18_Weights.DEFAULT)\n",
    "        except Exception as _:\n",
    "            self.backbone = r3d_18(weights=None)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.mixstyle   = MixStyle(p=0.3, α=0.1)\n",
    "        self.proj_v     = nn.Sequential(nn.LayerNorm(512), nn.Linear(512, proj_dim))\n",
    "        self.head       = nn.Sequential(nn.LayerNorm(512), nn.Linear(512,256), nn.GELU(), nn.Dropout(0.1),\n",
    "                                        nn.Linear(256,len(LANGS)))\n",
    "    def forward(self, x):\n",
    "        x = x.repeat(1,3,1,1,1)  # [B,1,L,H,W] -> [B,3,L,H,W]\n",
    "        f = self.backbone(x)     # [B,512]\n",
    "        f = self.mixstyle(f)\n",
    "        logits = self.head(f)\n",
    "        z_v = self.proj_v(f)     # [B,proj]\n",
    "        return logits, f, z_v\n",
    "\n",
    "# ───────────── Sampler bilanciato ─────────────\n",
    "def make_sampler(df):\n",
    "    cnt = df['label'].astype(str).str.lower().value_counts().reindex(LANGS,fill_value=0).to_dict()\n",
    "    w   = df['label'].astype(str).str.lower().map(lambda l:1.0/(cnt[l]+1e-6)).tolist()\n",
    "    return WeightedRandomSampler(w, num_samples=len(w), replacement=True)\n",
    "\n",
    "# ───────────── Loader builder ─────────────\n",
    "def build_loaders(train_csv, val_csv, need_teacher):\n",
    "    df_tr = pd.read_csv(train_csv)\n",
    "    dl_tr = DataLoader(MouthDSEmotion(train_csv, L, augment=True,  need_teacher=need_teacher),\n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       sampler=make_sampler(df_tr),\n",
    "                       num_workers=NUM_WORKERS,\n",
    "                       pin_memory=False,\n",
    "                       collate_fn=collate_with_optional_teacher)\n",
    "    dl_va = DataLoader(MouthDSEmotion(val_csv,   L, augment=False, need_teacher=False),\n",
    "                       batch_size=BATCH_SIZE, shuffle=False,\n",
    "                       num_workers=NUM_WORKERS, pin_memory=False,\n",
    "                       collate_fn=collate_with_optional_teacher)\n",
    "    return dl_tr, dl_va\n",
    "\n",
    "# ───────────── Eval helpers ─────────────\n",
    "def evaluate_emotion(csv_path, ckpt_path, proj_l11_top, proj_l10_mid, top_adapter, mid_adapter, proj_dim=128, run_dir=None, title=\"\"):\n",
    "    model = Student(proj_dim=proj_dim)\n",
    "    state = torch.load(ckpt_path, map_location='cpu')\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    for m in model.backbone.modules():\n",
    "        if isinstance(m, nn.BatchNorm3d):\n",
    "            m.eval(); m.weight.requires_grad_(False); m.bias.requires_grad_(False)\n",
    "    model.eval()\n",
    "\n",
    "    dl = DataLoader(MouthDSEmotion(csv_path, L, augment=False, need_teacher=False),\n",
    "                    batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False,\n",
    "                    collate_fn=collate_with_optional_teacher)\n",
    "\n",
    "    y_true, y_pred, emos, probs = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            x, y, emo, _ = batch\n",
    "            logits, _, _ = model(x)\n",
    "            y_true += y.cpu().tolist()\n",
    "            y_pred += logits.argmax(1).cpu().tolist()\n",
    "            pr = F.softmax(logits,1).cpu().numpy()\n",
    "            probs.append(pr)\n",
    "            emos += list(emo)\n",
    "    y_true = np.array(y_true); y_pred = np.array(y_pred)\n",
    "    probs  = np.concatenate(probs) if probs else np.zeros((0,len(LANGS)))\n",
    "    all_labels = list(range(len(LANGS)))\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred) if len(y_true) else 0.0\n",
    "    mf1 = f1_score(y_true, y_pred, average=\"macro\") if len(y_true) else 0.0\n",
    "    cm  = confusion_matrix(y_true, y_pred, labels=all_labels) if len(y_true) else np.zeros((len(LANGS),len(LANGS)), dtype=int)\n",
    "    print(f\"\\n[{title}] N={len(y_true)}  Acc={acc:.3f}  Macro-F1={mf1:.3f}\")\n",
    "    print(pd.DataFrame(cm, index=LANGS, columns=LANGS))\n",
    "\n",
    "    # per-emozione\n",
    "    dfp = pd.DataFrame({\n",
    "        \"y\": y_true, \"yhat\": y_pred, \"emotion\": emos,\n",
    "        \"prob_en\": probs[:,0] if len(probs) else [],\n",
    "        \"prob_it\": probs[:,1] if len(probs) else [],\n",
    "        \"prob_es\": probs[:,2] if len(probs) else [],\n",
    "    })\n",
    "    rows=[]\n",
    "    for emo,g in dfp.groupby(\"emotion\"):\n",
    "        rows.append({\n",
    "            \"emotion\": emo,\n",
    "            \"acc\": accuracy_score(g.y, g.yhat),\n",
    "            \"macro_f1\": f1_score(g.y, g.yhat, average=\"macro\")\n",
    "        })\n",
    "    per_emo = pd.DataFrame(rows).sort_values(\"emotion\")\n",
    "    esi = float(per_emo[\"macro_f1\"].std()) if len(per_emo)>0 else float(\"nan\")\n",
    "    worst_acc = float(per_emo[\"acc\"].min()) if len(per_emo)>0 else float(\"nan\")\n",
    "    ece_df = ece_by_emotion(dfp)\n",
    "\n",
    "    if run_dir is not None:\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "        dfp.to_csv(os.path.join(run_dir, f\"{title}__preds.csv\"), index=False)\n",
    "        per_emo.to_csv(os.path.join(run_dir, f\"{title}__per_emotion.csv\"), index=False)\n",
    "        ece_df.to_csv(os.path.join(run_dir, f\"{title}__ece_per_emotion.csv\"), index=False)\n",
    "\n",
    "    return dict(N=len(y_true), acc=float(acc), macro_f1=float(mf1),\n",
    "                per_emotion=per_emo, esi=float(esi), worst_acc=float(worst_acc),\n",
    "                ece=ece_df, preds=dfp)\n",
    "\n",
    "# ───────────── Infer dims teacher (mid/top) ─────────────\n",
    "def infer_teacher_dims(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    for _,r in df.iterrows():\n",
    "        p10 = r.get(TEACHER_L10_COL, None)\n",
    "        p11 = r.get(TEACHER_L11_COL, None)\n",
    "        if isinstance(p10,str) and os.path.exists(p10) and isinstance(p11,str) and os.path.exists(p11):\n",
    "            v10 = np.load(p10); v11 = np.load(p11)\n",
    "            return int(v10.shape[-1]), int(v11.shape[-1])\n",
    "    return 512, 512  # fallback prudente\n",
    "\n",
    "# ───────────── Training di UNA RUN ─────────────\n",
    "def train_one_run_emotion(run_cfg, split_key=\"full_F0\"):\n",
    "    TRAIN_CSV = DATA_SPLITS[split_key][\"train\"]\n",
    "    VAL_CSV   = DATA_SPLITS[split_key][\"val\"]\n",
    "    TEST_CSV  = DATA_SPLITS[split_key][\"test\"]\n",
    "\n",
    "    RUN_ID         = run_cfg['run_id']\n",
    "    USE_L2_ML      = run_cfg.get('USE_L2_ML', False)\n",
    "    LAMBDA_L2_TOP  = float(run_cfg.get('LAMBDA_L2_TOP', 0.0))\n",
    "    LAMBDA_L2_MID  = float(run_cfg.get('LAMBDA_L2_MID', 0.0))\n",
    "    L2_APPLY_PROB  = float(run_cfg.get('L2_APPLY_PROB', 1.0))   # <— nuova: applicazione stocastica KD\n",
    "    L2_SCHEDULE    = run_cfg.get('L2_SCHEDULE', 'const')        # 'const' | 'warmup'\n",
    "    L2_WARMUP_E    = int(run_cfg.get('L2_WARMUP_EPOCHS', 5))\n",
    "    PROJ_DIM       = int(run_cfg.get('PROJ_DIM', 128))\n",
    "\n",
    "    # gate & emo-weights config\n",
    "    CONF_GATE_MODE     = run_cfg.get('CONF_GATE_MODE', 'soft')    # 'none' | 'soft' | 'hard'\n",
    "    CONF_GATE_THRESH   = float(run_cfg.get('CONF_GATE_THRESH', 0.60))\n",
    "    EMO_WEIGHTS_MODE   = run_cfg.get('EMO_WEIGHTS_MODE', 'default')  # 'default' | 'none'\n",
    "\n",
    "    need_teacher = USE_L2_ML\n",
    "    dl_tr, dl_va = build_loaders(TRAIN_CSV, VAL_CSV, need_teacher=need_teacher)\n",
    "\n",
    "    model = Student(proj_dim=PROJ_DIM)\n",
    "\n",
    "    # Projection heads\n",
    "    proj_l11_top = nn.Linear(512, PROJ_DIM)   # teacher top → proj_dim\n",
    "    proj_l10_mid = nn.Linear(512, 512)        # teacher mid → 512\n",
    "\n",
    "    # Freeze BN\n",
    "    for m in model.backbone.modules():\n",
    "        if isinstance(m, nn.BatchNorm3d):\n",
    "            m.eval(); m.weight.requires_grad_(False); m.bias.requires_grad_(False)\n",
    "\n",
    "    # Adattatori dai dims teacher reali\n",
    "    if USE_L2_ML:\n",
    "        d10, d11 = infer_teacher_dims(TRAIN_CSV)   # es. Whisper-small: 768, 768\n",
    "        mid_adapter = (nn.Identity() if d10 == 512 else nn.Linear(d10, 512))\n",
    "        top_adapter = (nn.Identity() if d11 == 512 else nn.Linear(d11, 512))\n",
    "    else:\n",
    "        mid_adapter = nn.Identity()\n",
    "        top_adapter = nn.Identity()\n",
    "\n",
    "    params = list(model.parameters()) \\\n",
    "           + list(proj_l11_top.parameters()) \\\n",
    "           + list(proj_l10_mid.parameters())\n",
    "    if isinstance(top_adapter, nn.Linear): params += list(top_adapter.parameters())\n",
    "    if isinstance(mid_adapter, nn.Linear): params += list(mid_adapter.parameters())\n",
    "    opt   = AdamW(params, lr=LR, weight_decay=WD)\n",
    "\n",
    "    total = EPOCHS * max(1, len(dl_tr))\n",
    "    sched = OneCycleLR(opt, max_lr=MAX_LR, total_steps=total, pct_start=0.3,\n",
    "                       div_factor=DIV_FACTOR, final_div_factor=FINAL_DIV, anneal_strategy='cos')\n",
    "    crit  = SoftFocalLoss()\n",
    "\n",
    "    run_name = (f\"{RUN_ID}__{split_key}\"\n",
    "                f\"__L2{int(USE_L2_ML)}__top{LAMBDA_L2_TOP:g}__mid{LAMBDA_L2_MID:g}\"\n",
    "                f\"__p{L2_APPLY_PROB:g}__sched{L2_SCHEDULE}__gate{CONF_GATE_MODE}__emo{EMO_WEIGHTS_MODE}\")\n",
    "    ckpt_dir = os.path.join(\"ckpts\", run_name); os.makedirs(ckpt_dir, exist_ok=True)\n",
    "    best_path_student = os.path.join(ckpt_dir, \"best_student.pt\")\n",
    "    best_path_proj_l11 = os.path.join(ckpt_dir, \"best_proj_l11_top.pt\")\n",
    "    best_path_proj_l10 = os.path.join(ckpt_dir, \"best_proj_l10_mid.pt\")\n",
    "\n",
    "    last_path_student = os.path.join(ckpt_dir, \"last_student.pt\")\n",
    "    last_path_proj_l11 = os.path.join(ckpt_dir, \"last_proj_l11_top.pt\")\n",
    "    last_path_proj_l10 = os.path.join(ckpt_dir, \"last_proj_l10_mid.pt\")\n",
    "\n",
    "    run_dir = os.path.join(\"reports\", run_name); os.makedirs(run_dir, exist_ok=True)\n",
    "    epoch_logs = []\n",
    "    best_f1, patience = -1.0, 0\n",
    "\n",
    "    def eff_lambda(base, ep):\n",
    "        if L2_SCHEDULE == 'warmup' and L2_WARMUP_E>0:\n",
    "            return float(base) * min(1.0, ep / L2_WARMUP_E)\n",
    "        return float(base)\n",
    "\n",
    "    print(f\"\\n===== TRAIN {RUN_ID} ({split_key}) | L2={USE_L2_ML}  top={LAMBDA_L2_TOP} mid={LAMBDA_L2_MID}  p={L2_APPLY_PROB} sched={L2_SCHEDULE} gate={CONF_GATE_MODE} emo={EMO_WEIGHTS_MODE} =====\")\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train(); proj_l11_top.train(); proj_l10_mid.train()\n",
    "        if isinstance(top_adapter, nn.Module): top_adapter.train()\n",
    "        if isinstance(mid_adapter, nn.Module): mid_adapter.train()\n",
    "\n",
    "        sup_loss_sum = 0.0\n",
    "        l2_top_sum = 0.0\n",
    "        l2_mid_sum = 0.0\n",
    "        cover_cnt = 0\n",
    "        seen_cnt  = 0\n",
    "\n",
    "        for batch in dl_tr:\n",
    "            if USE_L2_ML:\n",
    "                x, y, emos, tconfs, l10, l11 = batch\n",
    "            else:\n",
    "                x, y, emos, tconfs = batch\n",
    "                l10 = l11 = None\n",
    "\n",
    "            # CPU tensors\n",
    "            y_onehot = F.one_hot(y, len(LANGS)).float()\n",
    "            x_m, y_m, lam, idx = mixup_return_params(x, y_onehot)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with contextlib.nullcontext():\n",
    "                logits_m, f_m, z_v_m = model(x_m)\n",
    "                loss_sup = crit(logits_m, y_m)\n",
    "\n",
    "                l2_top = torch.tensor(0.0)\n",
    "                l2_mid = torch.tensor(0.0)\n",
    "\n",
    "                if USE_L2_ML:\n",
    "                    logits_c, f_c, z_v_c = model(x)\n",
    "\n",
    "                    B = x.size(0)\n",
    "                    have = torch.tensor(\n",
    "                        [(isinstance(l10[i], torch.Tensor)) and (isinstance(l11[i], torch.Tensor)) for i in range(B)],\n",
    "                        dtype=torch.bool\n",
    "                    )\n",
    "                    seen_cnt += int(B); cover_cnt += int(have.sum().item())\n",
    "\n",
    "                    if have.any():\n",
    "                        idxs = torch.nonzero(have).squeeze(1)\n",
    "                        l10_t = torch.stack([l10[i.item()] for i in idxs], dim=0)  # [M, d10]\n",
    "                        l11_t = torch.stack([l11[i.item()] for i in idxs], dim=0)  # [M, d11]\n",
    "                        conf_sel = tconfs[idxs]                                    # [M]\n",
    "                        emo_sel  = [emos[i.item()] for i in idxs]\n",
    "\n",
    "                        # adattatori → 512\n",
    "                        l10_512 = mid_adapter(l10_t)    # [M,512]\n",
    "                        l11_512 = top_adapter(l11_t)    # [M,512]\n",
    "\n",
    "                        f_sel  = f_c[have]              # [M,512]\n",
    "                        z_sel  = z_v_c[have]            # [M,proj]\n",
    "                        pt     = proj_l11_top(l11_512)  # [M,proj]\n",
    "                        pm     = proj_l10_mid(l10_512)  # [M,512]\n",
    "\n",
    "                        # ---- GATE ----\n",
    "                        if CONF_GATE_MODE == 'none':\n",
    "                            gate = torch.ones_like(conf_sel)\n",
    "                        elif CONF_GATE_MODE == 'soft':\n",
    "                            gate = conf_sel.clamp(0,1)\n",
    "                        elif CONF_GATE_MODE == 'hard':\n",
    "                            gate = (conf_sel >= CONF_GATE_THRESH).float()\n",
    "                        else:\n",
    "                            gate = torch.ones_like(conf_sel)\n",
    "\n",
    "                        # ---- APPLY_PROB (KD light) ----\n",
    "                        if L2_APPLY_PROB < 0.999:\n",
    "                            keep_mask = (torch.rand_like(gate) < L2_APPLY_PROB).float()\n",
    "                            gate = gate * keep_mask  # integra la probabilità di applicazione\n",
    "\n",
    "                        # ---- PESI PER EMOZIONE ----\n",
    "                        if EMO_WEIGHTS_MODE == 'none':\n",
    "                            lam_top_e = torch.ones_like(gate)\n",
    "                            lam_mid_e = torch.ones_like(gate)\n",
    "                        else:\n",
    "                            lam_top_e = torch.tensor([LAM_TOP_EMO.get(e,1.0) for e in emo_sel])\n",
    "                            lam_mid_e = torch.tensor([LAM_MID_EMO.get(e,1.0) for e in emo_sel])\n",
    "\n",
    "                        # ---- schedule epocale ----\n",
    "                        lam_top_base = eff_lambda(LAMBDA_L2_TOP, ep)\n",
    "                        lam_mid_base = eff_lambda(LAMBDA_L2_MID, ep)\n",
    "\n",
    "                        # ---- normalizza e calcola distanze per-sample ----\n",
    "                        z_n  = F.normalize(z_sel, dim=1);  pt_n = F.normalize(pt, dim=1)\n",
    "                        f_n  = F.normalize(f_sel, dim=1);  pm_n = F.normalize(pm, dim=1)\n",
    "\n",
    "                        top_vec = ((z_n - pt_n)**2).sum(1)   # [M]\n",
    "                        mid_vec = ((f_n - pm_n)**2).sum(1)   # [M]\n",
    "\n",
    "                        # ---- loss con pesi (gate × emo × λ base) ----\n",
    "                        w_top = lam_top_base * lam_top_e * gate\n",
    "                        w_mid = lam_mid_base * lam_mid_e * gate\n",
    "\n",
    "                        eps = 1e-6\n",
    "                        if w_top.sum() > 0:\n",
    "                            l2_top = (w_top * top_vec).sum() / (w_top.sum() + eps)\n",
    "                            loss_sup = loss_sup + l2_top\n",
    "                        if w_mid.sum() > 0:\n",
    "                            l2_mid = (w_mid * mid_vec).sum() / (w_mid.sum() + eps)\n",
    "                            loss_sup = loss_sup + l2_mid\n",
    "\n",
    "                loss = loss_sup\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                list(model.parameters())\n",
    "                + list(proj_l11_top.parameters())\n",
    "                + list(proj_l10_mid.parameters())\n",
    "                + (list(top_adapter.parameters()) if isinstance(top_adapter, nn.Linear) else [])\n",
    "                + (list(mid_adapter.parameters()) if isinstance(mid_adapter, nn.Linear) else []),\n",
    "                1.0\n",
    "            )\n",
    "            opt.step(); opt.zero_grad()\n",
    "            sched.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                sup_loss_sum += float(loss_sup.item())\n",
    "                l2_top_sum   += float(l2_top.item()) if isinstance(l2_top, torch.Tensor) else float(l2_top)\n",
    "                l2_mid_sum   += float(l2_mid.item()) if isinstance(l2_mid, torch.Tensor) else float(l2_mid)\n",
    "\n",
    "        # ── Validation (macro-F1) ───────────────────────────\n",
    "        model.eval()\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in DataLoader(MouthDSEmotion(VAL_CSV, L, augment=False, need_teacher=False),\n",
    "                                    batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False,\n",
    "                                    collate_fn=collate_with_optional_teacher):\n",
    "                x,y,_,_ = batch\n",
    "                logits,_,_ = model(x)\n",
    "                preds += logits.argmax(1).cpu().tolist()\n",
    "                gts   += y.cpu().tolist()\n",
    "        f1 = macro_f1(gts, preds)\n",
    "        cm = confusion_matrix(gts, preds, labels=list(range(len(LANGS))))\n",
    "        print(f\"Epoch {ep:02d}  Val-F1={f1:.3f}\")\n",
    "        print(pd.DataFrame(cm, index=LANGS, columns=LANGS))\n",
    "\n",
    "        loss_sup_mean = sup_loss_sum / max(1, len(dl_tr))\n",
    "        l2_top_mean   = l2_top_sum / max(1, len(dl_tr))\n",
    "        l2_mid_mean   = l2_mid_sum / max(1, len(dl_tr))\n",
    "        cover_rate    = (cover_cnt / max(1, seen_cnt)) * 100.0\n",
    "        epoch_logs.append(dict(epoch=ep, val_f1=float(f1),\n",
    "                               loss_sup_mean=loss_sup_mean,\n",
    "                               loss_l2_top_mean=l2_top_mean,\n",
    "                               loss_l2_mid_mean=l2_mid_mean,\n",
    "                               teacher_cover_pct=cover_rate))\n",
    "        pd.DataFrame(epoch_logs).to_csv(os.path.join(run_dir, \"epoch_log.csv\"), index=False)\n",
    "\n",
    "        # early stopping\n",
    "        improved = f1 > best_f1 + 1e-6\n",
    "        if improved:\n",
    "            best_f1, patience = f1, 0\n",
    "            torch.save(model.state_dict(), best_path_student)\n",
    "            torch.save(proj_l11_top.state_dict(), best_path_proj_l11)\n",
    "            torch.save(proj_l10_mid.state_dict(), best_path_proj_l10)\n",
    "            print(f\"  → New best: Val-F1={f1:.3f}  saved: {best_path_student}\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= PATIENCE:\n",
    "                print(\"Early stopping\"); break\n",
    "\n",
    "    # save last\n",
    "    torch.save(model.state_dict(), last_path_student)\n",
    "    torch.save(proj_l11_top.state_dict(), last_path_proj_l11)\n",
    "    torch.save(proj_l10_mid.state_dict(), last_path_proj_l10)\n",
    "\n",
    "    print(f\"Best Val-F1 (VAL) = {best_f1:.3f}\")\n",
    "\n",
    "    # Eval TEST con report per emozione (inference: no gate/no teacher)\n",
    "    test_report = evaluate_emotion(TEST_CSV, best_path_student,\n",
    "                                   proj_l11_top, proj_l10_mid, top_adapter, mid_adapter,\n",
    "                                   proj_dim=PROJ_DIM, run_dir=run_dir, title=\"TEST\")\n",
    "\n",
    "    # Salva riassunto\n",
    "    summary = {\n",
    "        \"run\": RUN_ID,\n",
    "        \"split\": split_key,\n",
    "        \"USE_L2_ML\": int(USE_L2_ML),\n",
    "        \"L2_top\": LAMBDA_L2_TOP,\n",
    "        \"L2_mid\": LAMBDA_L2_MID,\n",
    "        \"L2_apply_prob\": L2_APPLY_PROB,\n",
    "        \"L2_schedule\": L2_SCHEDULE,\n",
    "        \"gate_mode\": CONF_GATE_MODE,\n",
    "        \"gate_thresh\": CONF_GATE_THRESH,\n",
    "        \"emo_weights\": EMO_WEIGHTS_MODE,\n",
    "        \"best_val_macro_f1\": float(best_f1),\n",
    "        \"test_macro_f1\": float(test_report[\"macro_f1\"]),\n",
    "        \"test_acc\": float(test_report[\"acc\"]),\n",
    "        \"test_esi\": float(test_report[\"esi\"]),\n",
    "        \"test_worst_emotion_acc\": float(test_report[\"worst_acc\"]),\n",
    "    }\n",
    "    with open(os.path.join(run_dir, \"summary.json\"), \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    return best_path_student, run_name, summary\n",
    "\n",
    "# ───────────── RUN SUITE + REPORT (Full + Neutral→Full) ─────────────\n",
    "def run_suite_emotion():\n",
    "    # Baseline + quattro varianti NO-GATE (Opzione A)\n",
    "    EXPERIMENTS = [\n",
    "        # Baseline — no KD\n",
    "        dict(run_id=\"E0_noKD\",\n",
    "             USE_L2_ML=False, LAMBDA_L2_TOP=0.0, LAMBDA_L2_MID=0.0,\n",
    "             L2_APPLY_PROB=0.0, L2_SCHEDULE='const',\n",
    "             CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "\n",
    "        # KD base (mid+top), NO gate, NO emo-weights\n",
    "        dict(run_id=\"E1b_noGate_both_base\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=1.0, LAMBDA_L2_MID=0.5,\n",
    "             L2_APPLY_PROB=1.0, L2_SCHEDULE='const',\n",
    "             CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "\n",
    "        # KD top-only, NO gate, NO emo-weights\n",
    "        dict(run_id=\"E4_noGate_top_only\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=1.0, LAMBDA_L2_MID=0.0,\n",
    "             L2_APPLY_PROB=1.0, L2_SCHEDULE='const',\n",
    "             CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "\n",
    "        # KD mid-only, NO gate, NO emo-weights\n",
    "        dict(run_id=\"E7_noGate_mid_only\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=0.0, LAMBDA_L2_MID=0.5,\n",
    "             L2_APPLY_PROB=1.0, L2_SCHEDULE='const',\n",
    "             CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "\n",
    "        # KD \"light\" (apply_prob 0.3 + warmup), NO gate, NO emo-weights\n",
    "        dict(run_id=\"E5_noGate_light\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=0.5, LAMBDA_L2_MID=0.25,\n",
    "             L2_APPLY_PROB=0.3, L2_SCHEDULE='warmup', L2_WARMUP_EPOCHS=5,\n",
    "             CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    for split_key in [\"full_F0\", \"neutral_only_F0\"]:\n",
    "        for cfg in EXPERIMENTS:\n",
    "            best_ckpt, run_name, summary = train_one_run_emotion(cfg, split_key=split_key)\n",
    "            summary[\"run_name\"] = run_name\n",
    "            results.append(summary)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    # Δ vs baseline per ciascuno split\n",
    "    out_rows=[]\n",
    "    for split_key, g in df.groupby(\"split\"):\n",
    "        base = g[g[\"run\"]==\"E0_noKD\"].iloc[0]\n",
    "        gg = g.copy()\n",
    "        gg[\"ΔF1_vs_noKD\"]     = gg[\"test_macro_f1\"] - base[\"test_macro_f1\"]\n",
    "        gg[\"ΔESI_vs_noKD\"]    = base[\"test_esi\"] - gg[\"test_esi\"]              # positivo = più robusto (ESI↓)\n",
    "        gg[\"ΔWorst_vs_noKD\"]  = gg[\"test_worst_emotion_acc\"] - base[\"test_worst_emotion_acc\"]\n",
    "        out_rows.append(gg)\n",
    "    df_all = pd.concat(out_rows, ignore_index=True)\n",
    "\n",
    "    print(\"\\n================ EMOTION-KD (NO-GATE) SUMMARY ================\")\n",
    "    print(df_all.sort_values([\"split\",\"run\"]).to_string(index=False))\n",
    "\n",
    "    os.makedirs(\"reports\", exist_ok=True)\n",
    "    out_csv = \"reports/emotion_kd_nogate_summary.csv\"\n",
    "    df_all.to_csv(out_csv, index=False)\n",
    "    print(f\"\\nSaved: {out_csv}\")\n",
    "\n",
    "    # Δ per emozione (confronta le varianti KD vs E0_noKD) su ciascuno split\n",
    "    kd_tags = [\"E1b_noGate_both_base\",\"E4_noGate_top_only\",\"E7_noGate_mid_only\",\"E5_noGate_light\"]\n",
    "    rows=[]\n",
    "    for split in [\"full_F0\",\"neutral_only_F0\"]:\n",
    "        base_dirs = glob.glob(f\"reports/*E0_noKD*__{split}\")\n",
    "        if not base_dirs: continue\n",
    "        base_dir = sorted(base_dirs)[-1]\n",
    "        df_base  = pd.read_csv(os.path.join(base_dir, \"TEST__per_emotion.csv\"))\n",
    "        for exp in kd_tags:\n",
    "            exp_dirs = glob.glob(f\"reports/*{exp}*__{split}\")\n",
    "            if not exp_dirs: continue\n",
    "            run_dir = sorted(exp_dirs)[-1]\n",
    "            df_kd   = pd.read_csv(os.path.join(run_dir, \"TEST__per_emotion.csv\"))\n",
    "            m = df_kd.merge(df_base, on=\"emotion\", suffixes=(\"_kd\",\"_base\"))\n",
    "            m[\"ΔF1\"]  = m[\"macro_f1_kd\"] - m[\"macro_f1_base\"]\n",
    "            m[\"ΔAcc\"] = m[\"acc_kd\"]      - m[\"acc_base\"]\n",
    "            for _,r in m.iterrows():\n",
    "                rows.append({\"split\":split,\"exp\":exp,\"emotion\":r[\"emotion\"],\"ΔF1\":r[\"ΔF1\"],\"ΔAcc\":r[\"ΔAcc\"]})\n",
    "    df_delta = pd.DataFrame(rows, columns=[\"split\",\"exp\",\"emotion\",\"ΔF1\",\"ΔAcc\"])\n",
    "    if not df_delta.empty:\n",
    "        df_delta = df_delta.sort_values([\"split\",\"exp\",\"emotion\"])\n",
    "        df_delta.to_csv(\"reports/emotion_deltas_nogate.csv\", index=False)\n",
    "        print(\"\\nSaved: reports/emotion_deltas_nogate.csv\")\n",
    "        print(df_delta.head(12).to_string(index=False))\n",
    "    else:\n",
    "        print(\"\\n[INFO] Nessun delta per-emozione calcolato: non trovati report compatibili.\")\n",
    "\n",
    "    if len(df_delta):\n",
    "        df_delta.to_csv(\"reports/emotion_deltas_nogate.csv\", index=False)\n",
    "        print(\"\\nSaved: reports/emotion_deltas_nogate.csv\")\n",
    "        print(df_delta.head(12).to_string(index=False))\n",
    "\n",
    "# Esegui!\n",
    "if __name__ == \"__main__\":\n",
    "    run_suite_emotion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1caf8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= RE-TRAIN on split = neutral_only_F0 =======\n",
      "\n",
      "===== TRAIN E0_noKD (neutral_only_F0) | L2=False  top=0.0 mid=0.0  p=0.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.347\n",
      "    en  it  es\n",
      "en   8   0   2\n",
      "it   1   0   6\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.347  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.369\n",
      "    en  it  es\n",
      "en   9   0   1\n",
      "it   2   0   5\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.369  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 03  Val-F1=0.341\n",
      "    en  it  es\n",
      "en   7   3   0\n",
      "it   2   0   5\n",
      "es   0   0   1\n",
      "Epoch 04  Val-F1=0.458\n",
      "    en  it  es\n",
      "en   6   4   0\n",
      "it   2   2   3\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.458  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 05  Val-F1=0.566\n",
      "    en  it  es\n",
      "en   7   3   0\n",
      "it   2   3   2\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.566  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 06  Val-F1=0.580\n",
      "    en  it  es\n",
      "en   6   4   0\n",
      "it   1   4   2\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.580  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 07  Val-F1=0.658\n",
      "    en  it  es\n",
      "en   7   3   0\n",
      "it   2   4   1\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.658  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 08  Val-F1=0.801\n",
      "    en  it  es\n",
      "en   5   5   0\n",
      "it   0   7   0\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.801  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 09  Val-F1=0.333\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   3   4\n",
      "es   0   0   1\n",
      "Epoch 10  Val-F1=0.764\n",
      "    en  it  es\n",
      "en   6   4   0\n",
      "it   2   5   0\n",
      "es   0   0   1\n",
      "Epoch 11  Val-F1=0.657\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   7   0\n",
      "es   0   0   1\n",
      "Epoch 12  Val-F1=0.657\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   7   0\n",
      "es   0   0   1\n",
      "Epoch 13  Val-F1=0.694\n",
      "    en  it  es\n",
      "en   8   2   0\n",
      "it   2   4   1\n",
      "es   0   0   1\n",
      "Epoch 14  Val-F1=0.444\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   5   2\n",
      "es   0   0   1\n",
      "Epoch 15  Val-F1=0.730\n",
      "    en  it  es\n",
      "en   9   1   0\n",
      "it   2   4   1\n",
      "es   0   0   1\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.801\n",
      "\n",
      "[TEST] N=167  Acc=0.569  Macro-F1=0.524\n",
      "    en  it  es\n",
      "en  32  51   0\n",
      "it  11  59   0\n",
      "es   0  10   4\n",
      "\n",
      "===== TRAIN E7_noGate_mid_only (neutral_only_F0) | L2=True  top=0.0 mid=0.5  p=1.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.291\n",
      "    en  it  es\n",
      "en   5   5   0\n",
      "it   2   0   5\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.291  saved: ckpts/E7_noGate_mid_only__neutral_only_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.291\n",
      "    en  it  es\n",
      "en   5   5   0\n",
      "it   2   0   5\n",
      "es   0   0   1\n",
      "Epoch 03  Val-F1=0.417\n",
      "    en  it  es\n",
      "en   7   3   0\n",
      "it   2   1   4\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.417  saved: ckpts/E7_noGate_mid_only__neutral_only_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 04  Val-F1=0.373\n",
      "    en  it  es\n",
      "en   4   5   1\n",
      "it   2   2   3\n",
      "es   0   0   1\n",
      "Epoch 05  Val-F1=0.768\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   4   1\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.768  saved: ckpts/E7_noGate_mid_only__neutral_only_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 06  Val-F1=0.230\n",
      "    en  it  es\n",
      "en   1   9   0\n",
      "it   0   2   5\n",
      "es   0   0   1\n",
      "Epoch 07  Val-F1=0.333\n",
      "    en  it  es\n",
      "en   3   7   0\n",
      "it   1   6   0\n",
      "es   0   1   0\n",
      "Epoch 08  Val-F1=0.314\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   7   0\n",
      "es   0   1   0\n",
      "Epoch 09  Val-F1=0.768\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   4   1\n",
      "es   0   0   1\n",
      "Epoch 10  Val-F1=0.496\n",
      "    en  it  es\n",
      "en   5   5   0\n",
      "it   2   3   2\n",
      "es   0   0   1\n",
      "Epoch 11  Val-F1=0.585\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   2   3\n",
      "es   0   0   1\n",
      "Epoch 12  Val-F1=0.457\n",
      "    en  it  es\n",
      "en   8   2   0\n",
      "it   2   4   1\n",
      "es   0   1   0\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.768\n",
      "\n",
      "[TEST] N=167  Acc=0.551  Macro-F1=0.468\n",
      "    en  it  es\n",
      "en  77   0   6\n",
      "it  62   1   7\n",
      "es   0   0  14\n",
      "\n",
      "== E7_noGate_mid_only vs baseline (neutral_only_F0) — peggiori ΔAcc in alto ==\n",
      "  emotion  acc_base   acc_kd      ΔAcc  macro_f1_base  macro_f1_kd       ΔF1  ECE_base   ECE_kd      ΔECE\n",
      "   rabbia  0.608696 0.521739 -0.086957       0.611111     0.444444 -0.166667  0.224356 0.089849 -0.134507\n",
      " sorpresa  0.625000 0.541667 -0.083333       0.629630     0.451389 -0.178241  0.169738 0.212622  0.042885\n",
      "    gioia  0.583333 0.541667 -0.041667       0.593371     0.451389 -0.141982  0.160563 0.079259 -0.081304\n",
      "    paura  0.625000 0.583333 -0.041667       0.432749     0.519387  0.086639  0.152023 0.077040 -0.074983\n",
      "   neutro  0.583333 0.583333  0.000000       0.602789     0.509091 -0.093698  0.281550 0.229350 -0.052200\n",
      " disgusto  0.500000 0.541667  0.041667       0.338624     0.451389  0.112765  0.162434 0.165332  0.002899\n",
      "tristezza  0.458333 0.541667  0.083333       0.313190     0.451389  0.138199  0.193241 0.105485 -0.087756\n",
      "[saved] reports/diagnose__E7_noGate_mid_only__neutral_only_F0.csv\n",
      "[saved] reports/emotion_kd_nogate_summary_neutral_only_F0.csv\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# === RE-TRAIN + DIAGNOSIS END-TO-END (no gate) ===\n",
    "import os, pandas as pd\n",
    "\n",
    "# Usa la tua train_one_run_emotion già definita nel notebook.\n",
    "\n",
    "def _ensure_test_files(run_dir: str):\n",
    "    req = [\"TEST__per_emotion.csv\", \"TEST__preds.csv\"]\n",
    "    miss = [f for f in req if not os.path.exists(os.path.join(run_dir, f))]\n",
    "    if miss:\n",
    "        raise FileNotFoundError(f\"Mancano file {miss} in {run_dir}.\")\n",
    "\n",
    "def diagnose_by_dirs(base_dir: str, kd_dir: str, split: str, tag: str):\n",
    "    \"\"\"Confronta KD vs baseline per-emozione partendo da due cartelle report esplicite.\"\"\"\n",
    "    _ensure_test_files(base_dir); _ensure_test_files(kd_dir)\n",
    "\n",
    "    pe_base = pd.read_csv(os.path.join(base_dir, \"TEST__per_emotion.csv\"))\n",
    "    pe_kd   = pd.read_csv(os.path.join(kd_dir,   \"TEST__per_emotion.csv\"))\n",
    "\n",
    "    m = pe_kd.merge(pe_base, on=\"emotion\", suffixes=(\"_kd\",\"_base\"))\n",
    "    m[\"ΔAcc\"] = m[\"acc_kd\"] - m[\"acc_base\"]\n",
    "    m[\"ΔF1\"]  = m[\"macro_f1_kd\"] - m[\"macro_f1_base\"]\n",
    "\n",
    "    # ECE (se disponibile)\n",
    "    ece_b = os.path.join(base_dir, \"TEST__ece_per_emotion.csv\")\n",
    "    ece_k = os.path.join(kd_dir,   \"TEST__ece_per_emotion.csv\")\n",
    "    if os.path.exists(ece_b) and os.path.exists(ece_k):\n",
    "        eb = pd.read_csv(ece_b).rename(columns={\"ECE\":\"ECE_base\"})\n",
    "        ek = pd.read_csv(ece_k).rename(columns={\"ECE\":\"ECE_kd\"})\n",
    "        m = m.merge(ek, on=\"emotion\").merge(eb, on=\"emotion\")\n",
    "        m[\"ΔECE\"] = m[\"ECE_kd\"] - m[\"ECE_base\"]\n",
    "\n",
    "    cols = [\"emotion\",\"acc_base\",\"acc_kd\",\"ΔAcc\",\"macro_f1_base\",\"macro_f1_kd\",\"ΔF1\"]\n",
    "    if \"ΔECE\" in m.columns: cols += [\"ECE_base\",\"ECE_kd\",\"ΔECE\"]\n",
    "    m = m[cols].sort_values(\"ΔAcc\")  # peggiori in alto\n",
    "\n",
    "    out_csv = f\"reports/diagnose__{tag}__{split}.csv\"\n",
    "    os.makedirs(\"reports\", exist_ok=True)\n",
    "    m.to_csv(out_csv, index=False)\n",
    "    print(f\"\\n== {tag} vs baseline ({split}) — peggiori ΔAcc in alto ==\")\n",
    "    print(m.to_string(index=False))\n",
    "    print(f\"[saved] {out_csv}\")\n",
    "    return out_csv\n",
    "\n",
    "def train_and_collect(cfg, split):\n",
    "    \"\"\"Allena UNA run, ritorna (run_dir, summary).\"\"\"\n",
    "    best_ckpt, run_name, summary = train_one_run_emotion(cfg, split_key=split)\n",
    "    run_dir = os.path.join(\"reports\", run_name)\n",
    "    _ensure_test_files(run_dir)\n",
    "    summary = {**summary, \"run_name\": run_name}\n",
    "    return run_dir, summary\n",
    "\n",
    "# ---------- COSA RIESGUIRE ----------\n",
    "SPLITS = [\"neutral_only_F0\"]  # aggiungi \"full_F0\" se vuoi rifare anche quello\n",
    "\n",
    "# set di esperimenti NO-GATE, come nei risultati che hai postato\n",
    "EXPS = [\n",
    "    # baseline\n",
    "    dict(run_id=\"E0_noKD\",\n",
    "         USE_L2_ML=False, LAMBDA_L2_TOP=0.0, LAMBDA_L2_MID=0.0,\n",
    "         L2_APPLY_PROB=0.0, L2_SCHEDULE='const',\n",
    "         CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "    # KD top+mid (base)\n",
    "    dict(run_id=\"E1b_noGate_both_base\",\n",
    "         USE_L2_ML=True, LAMBDA_L2_TOP=1.0, LAMBDA_L2_MID=0.5,\n",
    "         L2_APPLY_PROB=1.0, L2_SCHEDULE='const',\n",
    "         CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "    # KD top-only\n",
    "    dict(run_id=\"E4_noGate_top_only\",\n",
    "         USE_L2_ML=True, LAMBDA_L2_TOP=1.0, LAMBDA_L2_MID=0.0,\n",
    "         L2_APPLY_PROB=1.0, L2_SCHEDULE='const',\n",
    "         CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "    # KD light\n",
    "    dict(run_id=\"E5_noGate_light\",\n",
    "         USE_L2_ML=True, LAMBDA_L2_TOP=0.5, LAMBDA_L2_MID=0.25,\n",
    "         L2_APPLY_PROB=0.3, L2_SCHEDULE='warmup', L2_WARMUP_EPOCHS=5,\n",
    "         CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "    # KD mid-only\n",
    "    dict(run_id=\"E7_noGate_mid_only\",\n",
    "         USE_L2_ML=True, LAMBDA_L2_TOP=0.0, LAMBDA_L2_MID=0.5,\n",
    "         L2_APPLY_PROB=1.0, L2_SCHEDULE='const',\n",
    "         CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "]\n",
    "\n",
    "# ---------- ESECUZIONE ----------\n",
    "all_summaries = []\n",
    "for split in SPLITS:\n",
    "    run_dirs = {}\n",
    "    print(f\"\\n======= RE-TRAIN on split = {split} =======\")\n",
    "    for cfg in EXPS:\n",
    "        run_dir, summary = train_and_collect(cfg, split)\n",
    "        run_dirs[cfg[\"run_id\"]] = run_dir\n",
    "        all_summaries.append(summary)\n",
    "\n",
    "    # diagnosi per-emozione vs baseline\n",
    "    base_dir = run_dirs[\"E0_noKD\"]\n",
    "    for tag, kd_dir in run_dirs.items():\n",
    "        if tag == \"E0_noKD\": \n",
    "            continue\n",
    "        diagnose_by_dirs(base_dir, kd_dir, split, tag)\n",
    "\n",
    "# ---------- SUMMARY Δ vs baseline (uno per split) ----------\n",
    "df = pd.DataFrame(all_summaries)\n",
    "rows = []\n",
    "for split, g in df.groupby(\"split\"):\n",
    "    base = g[g[\"run\"]==\"E0_noKD\"].iloc[0]\n",
    "    gg = g.copy()\n",
    "    gg[\"ΔF1_vs_noKD\"]    = gg[\"test_macro_f1\"] - base[\"test_macro_f1\"]\n",
    "    gg[\"ΔESI_vs_noKD\"]   = base[\"test_esi\"] - gg[\"test_esi\"]                 # + = più uniforme tra emozioni\n",
    "    gg[\"ΔWorst_vs_noKD\"] = gg[\"test_worst_emotion_acc\"] - base[\"test_worst_emotion_acc\"]\n",
    "    out_csv = f\"reports/emotion_kd_nogate_summary_{split}.csv\"\n",
    "    gg.sort_values(\"run\").to_csv(out_csv, index=False)\n",
    "    print(f\"[saved] {out_csv}\")\n",
    "    rows.append(gg)\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7395acff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= RE-TRAIN on split = neutral_only_F0 =======\n",
      "\n",
      "===== TRAIN E1b_noGate_both_base (neutral_only_F0) | L2=True  top=1.0 mid=0.5  p=1.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.291\n",
      "    en  it  es\n",
      "en   3   7   0\n",
      "it   0   4   3\n",
      "es   1   0   0\n",
      "  → New best: Val-F1=0.291  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.369\n",
      "    en  it  es\n",
      "en   4   5   1\n",
      "it   0   2   5\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.369  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 03  Val-F1=0.379\n",
      "    en  it  es\n",
      "en   6   3   1\n",
      "it   1   1   5\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.379  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 04  Val-F1=0.282\n",
      "    en  it  es\n",
      "en   5   4   1\n",
      "it   1   0   6\n",
      "es   0   0   1\n",
      "Epoch 05  Val-F1=0.415\n",
      "    en  it  es\n",
      "en   7   3   0\n",
      "it   1   1   5\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.415  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 06  Val-F1=0.458\n",
      "    en  it  es\n",
      "en   6   4   0\n",
      "it   2   2   3\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.458  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 07  Val-F1=0.277\n",
      "    en  it  es\n",
      "en   1   9   0\n",
      "it   0   3   4\n",
      "es   0   0   1\n",
      "Epoch 08  Val-F1=0.398\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   0   5\n",
      "es   0   0   1\n",
      "Epoch 09  Val-F1=0.285\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   2   5\n",
      "es   0   0   1\n",
      "Epoch 10  Val-F1=0.524\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   6   1\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.524  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 11  Val-F1=0.914\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   5   0\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.914  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 12  Val-F1=0.580\n",
      "    en  it  es\n",
      "en   6   4   0\n",
      "it   1   4   2\n",
      "es   0   0   1\n",
      "Epoch 13  Val-F1=0.722\n",
      "    en  it  es\n",
      "en   4   6   0\n",
      "it   1   6   0\n",
      "es   0   0   1\n",
      "Epoch 14  Val-F1=0.366\n",
      "    en  it  es\n",
      "en   3   7   0\n",
      "it   0   7   0\n",
      "es   0   1   0\n",
      "Epoch 15  Val-F1=0.449\n",
      "    en  it  es\n",
      "en   6   4   0\n",
      "it   1   2   4\n",
      "es   0   0   1\n",
      "Epoch 16  Val-F1=0.694\n",
      "    en  it  es\n",
      "en   8   2   0\n",
      "it   2   4   1\n",
      "es   0   0   1\n",
      "Epoch 17  Val-F1=0.768\n",
      "    en  it  es\n",
      "en  10   0   0\n",
      "it   2   4   1\n",
      "es   0   0   1\n",
      "Epoch 18  Val-F1=0.314\n",
      "    en  it  es\n",
      "en   2   8   0\n",
      "it   0   7   0\n",
      "es   0   1   0\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.914\n",
      "\n",
      "[TEST] N=167  Acc=0.545  Macro-F1=0.511\n",
      "    en  it  es\n",
      "en  75   8   0\n",
      "it  60   4   6\n",
      "es   0   2  12\n",
      "\n",
      "===== TRAIN E4_noGate_top_only (neutral_only_F0) | L2=True  top=1.0 mid=0.0  p=1.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.378\n",
      "    en  it  es\n",
      "en   6   3   1\n",
      "it   1   3   3\n",
      "es   0   1   0\n",
      "  → New best: Val-F1=0.378  saved: ckpts/E4_noGate_top_only__neutral_only_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.278\n",
      "    en  it  es\n",
      "en   2   7   1\n",
      "it   0   2   5\n",
      "es   0   0   1\n",
      "Epoch 03  Val-F1=0.222\n",
      "    en  it  es\n",
      "en   1   8   1\n",
      "it   0   2   5\n",
      "es   0   0   1\n",
      "Epoch 04  Val-F1=0.278\n",
      "    en  it  es\n",
      "en   2   7   1\n",
      "it   0   2   5\n",
      "es   0   0   1\n",
      "Epoch 05  Val-F1=0.448\n",
      "    en  it  es\n",
      "en   6   4   0\n",
      "it   0   2   5\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.448  saved: ckpts/E4_noGate_top_only__neutral_only_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 06  Val-F1=0.469\n",
      "    en  it  es\n",
      "en   9   1   0\n",
      "it   1   1   5\n",
      "es   0   0   1\n",
      "  → New best: Val-F1=0.469  saved: ckpts/E4_noGate_top_only__neutral_only_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 80\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m======= RE-TRAIN on split = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m =======\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cfg \u001b[38;5;129;01min\u001b[39;00m EXPS:\n\u001b[0;32m---> 80\u001b[0m     run_dir, summary \u001b[38;5;241m=\u001b[39m train_and_collect(cfg, split)\n\u001b[1;32m     81\u001b[0m     run_dirs[cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m run_dir\n\u001b[1;32m     82\u001b[0m     all_summaries\u001b[38;5;241m.\u001b[39mappend(summary)\n",
      "Cell \u001b[0;32mIn[33], line 46\u001b[0m, in \u001b[0;36mtrain_and_collect\u001b[0;34m(cfg, split)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_and_collect\u001b[39m(cfg, split):\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Allena UNA run, ritorna (run_dir, summary).\"\"\"\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     best_ckpt, run_name, summary \u001b[38;5;241m=\u001b[39m train_one_run_emotion(cfg, split_key\u001b[38;5;241m=\u001b[39msplit)\n\u001b[1;32m     47\u001b[0m     run_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreports\u001b[39m\u001b[38;5;124m\"\u001b[39m, run_name)\n\u001b[1;32m     48\u001b[0m     _ensure_test_files(run_dir)\n",
      "Cell \u001b[0;32mIn[21], line 553\u001b[0m, in \u001b[0;36mtrain_one_run_emotion\u001b[0;34m(run_cfg, split_key)\u001b[0m\n\u001b[1;32m    549\u001b[0m                 loss_sup \u001b[38;5;241m=\u001b[39m loss_sup \u001b[38;5;241m+\u001b[39m l2_mid\n\u001b[1;32m    551\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_sup\n\u001b[0;32m--> 553\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    554\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28mlist\u001b[39m(model\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(proj_l11_top\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    561\u001b[0m )\n\u001b[1;32m    562\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep(); opt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    650\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m _engine_run_backward(\n\u001b[1;32m    354\u001b[0m     tensors,\n\u001b[1;32m    355\u001b[0m     grad_tensors_,\n\u001b[1;32m    356\u001b[0m     retain_graph,\n\u001b[1;32m    357\u001b[0m     create_graph,\n\u001b[1;32m    358\u001b[0m     inputs,\n\u001b[1;32m    359\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    360\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    361\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# === RE-TRAIN + DIAGNOSIS END-TO-END (no gate) ===\n",
    "import os, pandas as pd\n",
    "\n",
    "# Usa la tua train_one_run_emotion già definita nel notebook.\n",
    "\n",
    "def _ensure_test_files(run_dir: str):\n",
    "    req = [\"TEST__per_emotion.csv\", \"TEST__preds.csv\"]\n",
    "    miss = [f for f in req if not os.path.exists(os.path.join(run_dir, f))]\n",
    "    if miss:\n",
    "        raise FileNotFoundError(f\"Mancano file {miss} in {run_dir}.\")\n",
    "\n",
    "def diagnose_by_dirs(base_dir: str, kd_dir: str, split: str, tag: str):\n",
    "    \"\"\"Confronta KD vs baseline per-emozione partendo da due cartelle report esplicite.\"\"\"\n",
    "    _ensure_test_files(base_dir); _ensure_test_files(kd_dir)\n",
    "\n",
    "    pe_base = pd.read_csv(os.path.join(base_dir, \"TEST__per_emotion.csv\"))\n",
    "    pe_kd   = pd.read_csv(os.path.join(kd_dir,   \"TEST__per_emotion.csv\"))\n",
    "\n",
    "    m = pe_kd.merge(pe_base, on=\"emotion\", suffixes=(\"_kd\",\"_base\"))\n",
    "    m[\"ΔAcc\"] = m[\"acc_kd\"] - m[\"acc_base\"]\n",
    "    m[\"ΔF1\"]  = m[\"macro_f1_kd\"] - m[\"macro_f1_base\"]\n",
    "\n",
    "    # ECE (se disponibile)\n",
    "    ece_b = os.path.join(base_dir, \"TEST__ece_per_emotion.csv\")\n",
    "    ece_k = os.path.join(kd_dir,   \"TEST__ece_per_emotion.csv\")\n",
    "    if os.path.exists(ece_b) and os.path.exists(ece_k):\n",
    "        eb = pd.read_csv(ece_b).rename(columns={\"ECE\":\"ECE_base\"})\n",
    "        ek = pd.read_csv(ece_k).rename(columns={\"ECE\":\"ECE_kd\"})\n",
    "        m = m.merge(ek, on=\"emotion\").merge(eb, on=\"emotion\")\n",
    "        m[\"ΔECE\"] = m[\"ECE_kd\"] - m[\"ECE_base\"]\n",
    "\n",
    "    cols = [\"emotion\",\"acc_base\",\"acc_kd\",\"ΔAcc\",\"macro_f1_base\",\"macro_f1_kd\",\"ΔF1\"]\n",
    "    if \"ΔECE\" in m.columns: cols += [\"ECE_base\",\"ECE_kd\",\"ΔECE\"]\n",
    "    m = m[cols].sort_values(\"ΔAcc\")  # peggiori in alto\n",
    "\n",
    "    out_csv = f\"reports/diagnose__{tag}__{split}.csv\"\n",
    "    os.makedirs(\"reports\", exist_ok=True)\n",
    "    m.to_csv(out_csv, index=False)\n",
    "    print(f\"\\n== {tag} vs baseline ({split}) — peggiori ΔAcc in alto ==\")\n",
    "    print(m.to_string(index=False))\n",
    "    print(f\"[saved] {out_csv}\")\n",
    "    return out_csv\n",
    "\n",
    "def train_and_collect(cfg, split):\n",
    "    \"\"\"Allena UNA run, ritorna (run_dir, summary).\"\"\"\n",
    "    best_ckpt, run_name, summary = train_one_run_emotion(cfg, split_key=split)\n",
    "    run_dir = os.path.join(\"reports\", run_name)\n",
    "    _ensure_test_files(run_dir)\n",
    "    summary = {**summary, \"run_name\": run_name}\n",
    "    return run_dir, summary\n",
    "\n",
    "# ---------- COSA RIESGUIRE ----------\n",
    "SPLITS = [\"neutral_only_F0\"]  # aggiungi \"full_F0\" se vuoi rifare anche quello\n",
    "\n",
    "# set di esperimenti NO-GATE, come nei risultati che hai postato\n",
    "EXPS = [\n",
    "    # KD top+mid (base)\n",
    "    dict(run_id=\"E1b_noGate_both_base\",\n",
    "         USE_L2_ML=True, LAMBDA_L2_TOP=1.0, LAMBDA_L2_MID=0.5,\n",
    "         L2_APPLY_PROB=1.0, L2_SCHEDULE='const',\n",
    "         CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "    # KD top-only\n",
    "    dict(run_id=\"E4_noGate_top_only\",\n",
    "         USE_L2_ML=True, LAMBDA_L2_TOP=1.0, LAMBDA_L2_MID=0.0,\n",
    "         L2_APPLY_PROB=1.0, L2_SCHEDULE='const',\n",
    "         CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "    # KD mid-only\n",
    "    dict(run_id=\"E7_noGate_mid_only\",\n",
    "         USE_L2_ML=True, LAMBDA_L2_TOP=0.0, LAMBDA_L2_MID=0.5,\n",
    "         L2_APPLY_PROB=1.0, L2_SCHEDULE='const',\n",
    "         CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "]\n",
    "\n",
    "# ---------- ESECUZIONE ----------\n",
    "all_summaries = []\n",
    "for split in SPLITS:\n",
    "    run_dirs = {}\n",
    "    print(f\"\\n======= RE-TRAIN on split = {split} =======\")\n",
    "    for cfg in EXPS:\n",
    "        run_dir, summary = train_and_collect(cfg, split)\n",
    "        run_dirs[cfg[\"run_id\"]] = run_dir\n",
    "        all_summaries.append(summary)\n",
    "\n",
    "    # diagnosi per-emozione vs baseline\n",
    "    base_dir = run_dirs[\"E0_noKD\"]\n",
    "    for tag, kd_dir in run_dirs.items():\n",
    "        if tag == \"E0_noKD\": \n",
    "            continue\n",
    "        diagnose_by_dirs(base_dir, kd_dir, split, tag)\n",
    "\n",
    "# ---------- SUMMARY Δ vs baseline (uno per split) ----------\n",
    "df = pd.DataFrame(all_summaries)\n",
    "rows = []\n",
    "for split, g in df.groupby(\"split\"):\n",
    "    base = g[g[\"run\"]==\"E0_noKD\"].iloc[0]\n",
    "    gg = g.copy()\n",
    "    gg[\"ΔF1_vs_noKD\"]    = gg[\"test_macro_f1\"] - base[\"test_macro_f1\"]\n",
    "    gg[\"ΔESI_vs_noKD\"]   = base[\"test_esi\"] - gg[\"test_esi\"]                 # + = più uniforme tra emozioni\n",
    "    gg[\"ΔWorst_vs_noKD\"] = gg[\"test_worst_emotion_acc\"] - base[\"test_worst_emotion_acc\"]\n",
    "    out_csv = f\"reports/emotion_kd_nogate_summary_{split}.csv\"\n",
    "    gg.sort_values(\"run\").to_csv(out_csv, index=False)\n",
    "    print(f\"[saved] {out_csv}\")\n",
    "    rows.append(gg)\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a184e32b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Nessun diagnose__*__neutral_only_F0.csv trovato in reports e baseline non reperita.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 129\u001b[0m\n\u001b[1;32m    126\u001b[0m         diag_files \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE0_noKD\u001b[39m\u001b[38;5;124m\"\u001b[39m: df_base, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdiag_files}  \u001b[38;5;66;03m# baseline per prima\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m diag_files:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNessun diagnose__*__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSPLIT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv trovato in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mREPORTS_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m e baseline non reperita.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun trovate:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([_display_name(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m diag_files\u001b[38;5;241m.\u001b[39mkeys()]))\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# ---------- PLOTTA TUTTO ----------\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Nessun diagnose__*__neutral_only_F0.csv trovato in reports e baseline non reperita."
     ]
    }
   ],
   "source": [
    "# ===================== EVAL SOLO DAI DATASET (niente diagnose) =====================\n",
    "\n",
    "EMO_TEX_ORDER = [\"sorpresa\",\"rabbia\",\"neutro\",\"gioia\",\"paura\",\"disgusto\",\"tristezza\"]\n",
    "\n",
    "def _latex_per_emozione(per_emo_df: pd.DataFrame, ece_df: pd.DataFrame, caption: str, label: str) -> str:\n",
    "    m = per_emo_df.merge(ece_df, on=\"emotion\", how=\"left\")\n",
    "    m[\"ord\"] = m[\"emotion\"].map({n:i for i,n in enumerate(EMO_TEX_ORDER)})\n",
    "    m = m.sort_values(\"ord\").drop(columns=[\"ord\"])\n",
    "    lines = [\n",
    "        r\"\\begin{table}[h!]\",\n",
    "        r\"\\centering\",\n",
    "        rf\"\\caption{{{caption}}}\",\n",
    "        rf\"\\label{{{label}}}\",\n",
    "        r\"\\begin{tabular}{llll}\",\n",
    "        r\"\\hline\",\n",
    "        r\"\\textbf{Emozione} & \\textbf{Accuracy} & \\textbf{Macro-F1} & \\textbf{Calibrazione} \\\\ \\hline\"\n",
    "    ]\n",
    "    for _, r in m.iterrows():\n",
    "        lines.append(f\"{str(r['emotion']).capitalize()} & {float(r['acc']):.3f} & {float(r['macro_f1']):.3f} & {float(r['ECE']):.3f} \\\\\\\\\")\n",
    "    lines += [r\"\\hline\", r\"\\end{tabular}\", r\"\\end{table}\"]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def eval_from_datasets_only():\n",
    "    TEST_FULL   = DATA_SPLITS[\"full_F0\"][\"test\"]\n",
    "    TEST_NEUTRO = DATA_SPLITS[\"neutral_only_F0\"][\"test\"]\n",
    "\n",
    "    EVALS = [\n",
    "        # Emotion-ON (full_F0)\n",
    "        dict(name=\"E0_noKD__full_F0\",\n",
    "             csv=TEST_FULL,\n",
    "             ckpt=\"ckpts/E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E1_KD_both_base__full_F0\",\n",
    "             csv=TEST_FULL,\n",
    "             ckpt=\"ckpts/E1_KD_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E2_KD_both_emaware_softgate__full_F0\",\n",
    "             csv=TEST_FULL,\n",
    "             ckpt=\"ckpts/E2_KD_both_emaware_softgate__full_F0__L21__top1__mid0.5__p1__schedwarmup__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E3_KD_both_emaware_hardgate__full_F0\",\n",
    "             csv=TEST_FULL,\n",
    "             ckpt=\"ckpts/E3_KD_both_emaware_hardgate__full_F0__L21__top1__mid0.5__p1__schedwarmup__gatehard/best_student.pt\"),\n",
    "\n",
    "        # Emotion-OFF (neutral_only_F0)\n",
    "        dict(name=\"E0_noKD__neutral_only_F0\",\n",
    "             csv=TEST_NEUTRO,\n",
    "             ckpt=\"ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E1_KD_both_base__neutral_only_F0\",\n",
    "             csv=TEST_NEUTRO,\n",
    "             ckpt=\"ckpts/E1_KD_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E2_KD_both_emaware_softgate__neutral_only_F0\",\n",
    "             csv=TEST_NEUTRO,\n",
    "             ckpt=\"ckpts/E2_KD_both_emaware_softgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E3_KD_both_emaware_hardgate__neutral_only_F0\",\n",
    "             csv=TEST_NEUTRO,\n",
    "             ckpt=\"ckpts/E3_KD_both_emaware_hardgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatehard/best_student.pt\"),\n",
    "    ]\n",
    "\n",
    "    out_root = Path(\"reports_eval_only\"); out_root.mkdir(parents=True, exist_ok=True)\n",
    "    # Dummy moduli richiesti da evaluate_emotion in firma (non usati in eval)\n",
    "    dummy_proj_top = nn.Linear(512, 128)\n",
    "    dummy_proj_mid = nn.Linear(512, 512)\n",
    "    dummy_top_adapter = nn.Identity()\n",
    "    dummy_mid_adapter = nn.Identity()\n",
    "\n",
    "    summary = []\n",
    "    for e in EVALS:\n",
    "        name, csv, ckpt = e[\"name\"], e[\"csv\"], e[\"ckpt\"]\n",
    "        run_dir = out_root / name; run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        rep = evaluate_emotion(\n",
    "            csv_path=csv,\n",
    "            ckpt_path=ckpt,\n",
    "            proj_l11_top=dummy_proj_top,\n",
    "            proj_l10_mid=dummy_proj_mid,\n",
    "            top_adapter=dummy_top_adapter,\n",
    "            mid_adapter=dummy_mid_adapter,\n",
    "            proj_dim=128,\n",
    "            run_dir=str(run_dir),\n",
    "            title=\"TEST\"\n",
    "        )\n",
    "\n",
    "        tex = _latex_per_emozione(rep[\"per_emotion\"], rep[\"ece\"],\n",
    "                                   caption=f\"Prestazioni per emozione — {name.replace('_','\\\\_')}\",\n",
    "                                   label=f\"tab:per-emozione-{name.replace('_','-')}\")\n",
    "        (run_dir / f\"per_emozione_{name}.tex\").write_text(tex, encoding=\"utf-8\")\n",
    "\n",
    "        # log rapido + LaTeX in stdout\n",
    "        print(f\"\\n[{name}] N={rep['N']}  Acc={rep['acc']:.3f}  Macro-F1={rep['macro_f1']:.3f}  ESI={rep['esi']:.3f}  WorstAcc={rep['worst_acc']:.3f}\")\n",
    "        print(\"\\n----- Tabella LaTeX -----\\n\")\n",
    "        print(tex)\n",
    "        print(\"\\n-------------------------\")\n",
    "\n",
    "        summary.append(dict(name=name, **{k: rep[k] for k in [\"N\",\"acc\",\"macro_f1\",\"esi\",\"worst_acc\"]}))\n",
    "\n",
    "    pd.DataFrame(summary).to_csv(out_root / \"summary_eval_only.csv\", index=False)\n",
    "    print(\"\\n[OK] Salvato:\", (out_root / \"summary_eval_only.csv\").resolve())\n",
    "\n",
    "# ===== Entry point (usa solo i dataset forniti) =====\n",
    "if __name__ == \"__main__\":\n",
    "    # Disattiva qualunque cella che cerchi file 'diagnose__*'\n",
    "    # run_suite_emotion()  # <- lascia commentato se non vuoi allenare\n",
    "    eval_from_datasets_only()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5c287a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST] N=49  Acc=0.571  Macro-F1=0.529\n",
      "    en  it  es\n",
      "en  13   7   1\n",
      "it   8  13   0\n",
      "es   5   0   2\n",
      "\n",
      "[E0_noKD__full_F0] N=49  Acc=0.571  Macro-F1=0.529  ESI=0.185  WorstAcc=0.400\n",
      "\n",
      "----- Tabella LaTeX -----\n",
      "\n",
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\caption{Prestazioni per emozione — E0\\_noKD\\_\\_full\\_F0}\n",
      "\\label{tab:per-emozione-E0-noKD--full-F0}\n",
      "\\begin{tabular}{llll}\n",
      "\\hline\n",
      "\\textbf{Emozione} & \\textbf{Accuracy} & \\textbf{Macro-F1} & \\textbf{Calibrazione} \\\\ \\hline\n",
      "Sorpresa & 0.667 & 0.489 & 0.135 \\\\\n",
      "Rabbia & 0.400 & 0.300 & 0.292 \\\\\n",
      "Neutro & 0.571 & 0.657 & 0.434 \\\\\n",
      "Gioia & 0.500 & 0.389 & 0.244 \\\\\n",
      "Paura & 0.444 & 0.315 & 0.226 \\\\\n",
      "Disgusto & 0.750 & 0.806 & 0.261 \\\\\n",
      "Tristezza & 0.667 & 0.489 & 0.352 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "-------------------------\n",
      "\n",
      "[TEST] N=49  Acc=0.347  Macro-F1=0.340\n",
      "    en  it  es\n",
      "en   8   7   6\n",
      "it   7   5   9\n",
      "es   3   0   4\n",
      "\n",
      "[E1_KD_both_base__full_F0] N=49  Acc=0.347  Macro-F1=0.340  ESI=0.240  WorstAcc=0.000\n",
      "\n",
      "----- Tabella LaTeX -----\n",
      "\n",
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\caption{Prestazioni per emozione — E1\\_KD\\_both\\_base\\_\\_full\\_F0}\n",
      "\\label{tab:per-emozione-E1-KD-both-base--full-F0}\n",
      "\\begin{tabular}{llll}\n",
      "\\hline\n",
      "\\textbf{Emozione} & \\textbf{Accuracy} & \\textbf{Macro-F1} & \\textbf{Calibrazione} \\\\ \\hline\n",
      "Sorpresa & 0.500 & 0.500 & 0.447 \\\\\n",
      "Rabbia & 0.000 & 0.000 & 0.545 \\\\\n",
      "Neutro & 0.143 & 0.111 & 0.489 \\\\\n",
      "Gioia & 0.500 & 0.524 & 0.324 \\\\\n",
      "Paura & 0.667 & 0.600 & 0.275 \\\\\n",
      "Disgusto & 0.250 & 0.148 & 0.411 \\\\\n",
      "Tristezza & 0.167 & 0.167 & 0.421 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "-------------------------\n",
      "\n",
      "[TEST] N=49  Acc=0.571  Macro-F1=0.600\n",
      "    en  it  es\n",
      "en  10   9   2\n",
      "it   7  11   3\n",
      "es   0   0   7\n",
      "\n",
      "[E2_KD_both_emaware_softgate__full_F0] N=49  Acc=0.571  Macro-F1=0.600  ESI=0.138  WorstAcc=0.429\n",
      "\n",
      "----- Tabella LaTeX -----\n",
      "\n",
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\caption{Prestazioni per emozione — E2\\_KD\\_both\\_emaware\\_softgate\\_\\_full\\_F0}\n",
      "\\label{tab:per-emozione-E2-KD-both-emaware-softgate--full-F0}\n",
      "\\begin{tabular}{llll}\n",
      "\\hline\n",
      "\\textbf{Emozione} & \\textbf{Accuracy} & \\textbf{Macro-F1} & \\textbf{Calibrazione} \\\\ \\hline\n",
      "Sorpresa & 0.500 & 0.522 & 0.335 \\\\\n",
      "Rabbia & 0.600 & 0.611 & 0.293 \\\\\n",
      "Neutro & 0.429 & 0.500 & 0.316 \\\\\n",
      "Gioia & 0.500 & 0.490 & 0.411 \\\\\n",
      "Paura & 0.667 & 0.746 & 0.312 \\\\\n",
      "Disgusto & 0.750 & 0.806 & 0.217 \\\\\n",
      "Tristezza & 0.500 & 0.444 & 0.057 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "-------------------------\n",
      "\n",
      "[TEST] N=49  Acc=0.469  Macro-F1=0.435\n",
      "    en  it  es\n",
      "en  14   5   2\n",
      "it  14   7   0\n",
      "es   5   0   2\n",
      "\n",
      "[E3_KD_both_emaware_hardgate__full_F0] N=49  Acc=0.469  Macro-F1=0.435  ESI=0.205  WorstAcc=0.286\n",
      "\n",
      "----- Tabella LaTeX -----\n",
      "\n",
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\caption{Prestazioni per emozione — E3\\_KD\\_both\\_emaware\\_hardgate\\_\\_full\\_F0}\n",
      "\\label{tab:per-emozione-E3-KD-both-emaware-hardgate--full-F0}\n",
      "\\begin{tabular}{llll}\n",
      "\\hline\n",
      "\\textbf{Emozione} & \\textbf{Accuracy} & \\textbf{Macro-F1} & \\textbf{Calibrazione} \\\\ \\hline\n",
      "Sorpresa & 0.667 & 0.722 & 0.459 \\\\\n",
      "Rabbia & 0.600 & 0.667 & 0.433 \\\\\n",
      "Neutro & 0.286 & 0.206 & 0.351 \\\\\n",
      "Gioia & 0.625 & 0.409 & 0.441 \\\\\n",
      "Paura & 0.444 & 0.293 & 0.302 \\\\\n",
      "Disgusto & 0.375 & 0.281 & 0.277 \\\\\n",
      "Tristezza & 0.333 & 0.278 & 0.436 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "-------------------------\n",
      "\n",
      "[TEST] N=49  Acc=0.449  Macro-F1=0.432\n",
      "    en  it  es\n",
      "en   4   9   8\n",
      "it   1  11   9\n",
      "es   0   0   7\n",
      "\n",
      "[E0_noKD__neutral_only_F0] N=49  Acc=0.449  Macro-F1=0.432  ESI=0.174  WorstAcc=0.286\n",
      "\n",
      "----- Tabella LaTeX -----\n",
      "\n",
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\caption{Prestazioni per emozione — E0\\_noKD\\_\\_neutral\\_only\\_F0}\n",
      "\\label{tab:per-emozione-E0-noKD--neutral-only-F0}\n",
      "\\begin{tabular}{llll}\n",
      "\\hline\n",
      "\\textbf{Emozione} & \\textbf{Accuracy} & \\textbf{Macro-F1} & \\textbf{Calibrazione} \\\\ \\hline\n",
      "Sorpresa & 0.667 & 0.656 & 0.355 \\\\\n",
      "Rabbia & 0.400 & 0.300 & 0.466 \\\\\n",
      "Neutro & 0.286 & 0.262 & 0.398 \\\\\n",
      "Gioia & 0.375 & 0.333 & 0.279 \\\\\n",
      "Paura & 0.667 & 0.663 & 0.427 \\\\\n",
      "Disgusto & 0.375 & 0.333 & 0.331 \\\\\n",
      "Tristezza & 0.333 & 0.300 & 0.328 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "-------------------------\n",
      "\n",
      "[TEST] N=49  Acc=0.469  Macro-F1=0.418\n",
      "    en  it  es\n",
      "en   1  19   1\n",
      "it   0  17   4\n",
      "es   0   2   5\n",
      "\n",
      "[E1_KD_both_base__neutral_only_F0] N=49  Acc=0.469  Macro-F1=0.418  ESI=0.139  WorstAcc=0.250\n",
      "\n",
      "----- Tabella LaTeX -----\n",
      "\n",
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\caption{Prestazioni per emozione — E1\\_KD\\_both\\_base\\_\\_neutral\\_only\\_F0}\n",
      "\\label{tab:per-emozione-E1-KD-both-base--neutral-only-F0}\n",
      "\\begin{tabular}{llll}\n",
      "\\hline\n",
      "\\textbf{Emozione} & \\textbf{Accuracy} & \\textbf{Macro-F1} & \\textbf{Calibrazione} \\\\ \\hline\n",
      "Sorpresa & 0.667 & 0.583 & 0.417 \\\\\n",
      "Rabbia & 0.600 & 0.444 & 0.429 \\\\\n",
      "Neutro & 0.429 & 0.389 & 0.484 \\\\\n",
      "Gioia & 0.250 & 0.148 & 0.494 \\\\\n",
      "Paura & 0.444 & 0.515 & 0.362 \\\\\n",
      "Disgusto & 0.375 & 0.370 & 0.372 \\\\\n",
      "Tristezza & 0.667 & 0.472 & 0.386 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "-------------------------\n",
      "\n",
      "[TEST] N=49  Acc=0.408  Macro-F1=0.309\n",
      "    en  it  es\n",
      "en   8   9   4\n",
      "it   9  12   0\n",
      "es   7   0   0\n",
      "\n",
      "[E2_KD_both_emaware_softgate__neutral_only_F0] N=49  Acc=0.408  Macro-F1=0.309  ESI=0.052  WorstAcc=0.333\n",
      "\n",
      "----- Tabella LaTeX -----\n",
      "\n",
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\caption{Prestazioni per emozione — E2\\_KD\\_both\\_emaware\\_softgate\\_\\_neutral\\_only\\_F0}\n",
      "\\label{tab:per-emozione-E2-KD-both-emaware-softgate--neutral-only-F0}\n",
      "\\begin{tabular}{llll}\n",
      "\\hline\n",
      "\\textbf{Emozione} & \\textbf{Accuracy} & \\textbf{Macro-F1} & \\textbf{Calibrazione} \\\\ \\hline\n",
      "Sorpresa & 0.333 & 0.222 & 0.278 \\\\\n",
      "Rabbia & 0.400 & 0.222 & 0.282 \\\\\n",
      "Neutro & 0.429 & 0.333 & 0.178 \\\\\n",
      "Gioia & 0.375 & 0.281 & 0.375 \\\\\n",
      "Paura & 0.444 & 0.315 & 0.247 \\\\\n",
      "Disgusto & 0.500 & 0.357 & 0.141 \\\\\n",
      "Tristezza & 0.333 & 0.278 & 0.446 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "-------------------------\n",
      "\n",
      "[TEST] N=49  Acc=0.510  Macro-F1=0.426\n",
      "    en  it  es\n",
      "en   1  18   2\n",
      "it   0  21   0\n",
      "es   4   0   3\n",
      "\n",
      "[E3_KD_both_emaware_hardgate__neutral_only_F0] N=49  Acc=0.510  Macro-F1=0.426  ESI=0.149  WorstAcc=0.375\n",
      "\n",
      "----- Tabella LaTeX -----\n",
      "\n",
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\caption{Prestazioni per emozione — E3\\_KD\\_both\\_emaware\\_hardgate\\_\\_neutral\\_only\\_F0}\n",
      "\\label{tab:per-emozione-E3-KD-both-emaware-hardgate--neutral-only-F0}\n",
      "\\begin{tabular}{llll}\n",
      "\\hline\n",
      "\\textbf{Emozione} & \\textbf{Accuracy} & \\textbf{Macro-F1} & \\textbf{Calibrazione} \\\\ \\hline\n",
      "Sorpresa & 0.667 & 0.583 & 0.281 \\\\\n",
      "Rabbia & 0.600 & 0.286 & 0.325 \\\\\n",
      "Neutro & 0.429 & 0.222 & 0.389 \\\\\n",
      "Gioia & 0.500 & 0.417 & 0.427 \\\\\n",
      "Paura & 0.444 & 0.515 & 0.501 \\\\\n",
      "Disgusto & 0.375 & 0.200 & 0.382 \\\\\n",
      "Tristezza & 0.667 & 0.452 & 0.287 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "-------------------------\n",
      "\n",
      "[OK] Salvato: /Users/ludovicagenovese/Documents/GitHub/mothertongueVSspoken/reports_eval_only/summary_eval_only.csv\n"
     ]
    }
   ],
   "source": [
    "# ===================== EVAL SOLO DAI DATASET (niente diagnose) =====================\n",
    "\n",
    "EMO_TEX_ORDER = [\"sorpresa\",\"rabbia\",\"neutro\",\"gioia\",\"paura\",\"disgusto\",\"tristezza\"]\n",
    "\n",
    "def _latex_per_emozione(per_emo_df: pd.DataFrame, ece_df: pd.DataFrame, caption: str, label: str) -> str:\n",
    "    m = per_emo_df.merge(ece_df, on=\"emotion\", how=\"left\")\n",
    "    m[\"ord\"] = m[\"emotion\"].map({n:i for i,n in enumerate(EMO_TEX_ORDER)})\n",
    "    m = m.sort_values(\"ord\").drop(columns=[\"ord\"])\n",
    "    lines = [\n",
    "        r\"\\begin{table}[h!]\",\n",
    "        r\"\\centering\",\n",
    "        rf\"\\caption{{{caption}}}\",\n",
    "        rf\"\\label{{{label}}}\",\n",
    "        r\"\\begin{tabular}{llll}\",\n",
    "        r\"\\hline\",\n",
    "        r\"\\textbf{Emozione} & \\textbf{Accuracy} & \\textbf{Macro-F1} & \\textbf{Calibrazione} \\\\ \\hline\"\n",
    "    ]\n",
    "    for _, r in m.iterrows():\n",
    "        lines.append(f\"{str(r['emotion']).capitalize()} & {float(r['acc']):.3f} & {float(r['macro_f1']):.3f} & {float(r['ECE']):.3f} \\\\\\\\\")\n",
    "    lines += [r\"\\hline\", r\"\\end{tabular}\", r\"\\end{table}\"]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def eval_from_datasets_only():\n",
    "    TEST_FULL   = DATA_SPLITS[\"full_F0\"][\"test\"]\n",
    "    TEST_NEUTRO = DATA_SPLITS[\"neutral_only_F0\"][\"test\"]\n",
    "\n",
    "    EVALS = [\n",
    "        # Emotion-ON (full_F0)\n",
    "        dict(name=\"E0_noKD__full_F0\",\n",
    "             csv=TEST_FULL,\n",
    "             ckpt=\"ckpts/E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E1_KD_both_base__full_F0\",\n",
    "             csv=TEST_FULL,\n",
    "             ckpt=\"ckpts/E1_KD_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E2_KD_both_emaware_softgate__full_F0\",\n",
    "             csv=TEST_FULL,\n",
    "             ckpt=\"ckpts/E2_KD_both_emaware_softgate__full_F0__L21__top1__mid0.5__p1__schedwarmup__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E3_KD_both_emaware_hardgate__full_F0\",\n",
    "             csv=TEST_FULL,\n",
    "             ckpt=\"ckpts/E3_KD_both_emaware_hardgate__full_F0__L21__top1__mid0.5__p1__schedwarmup__gatehard/best_student.pt\"),\n",
    "\n",
    "        # Emotion-OFF (neutral_only_F0)\n",
    "        dict(name=\"E0_noKD__neutral_only_F0\",\n",
    "             csv=TEST_NEUTRO,\n",
    "             ckpt=\"ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E1_KD_both_base__neutral_only_F0\",\n",
    "             csv=TEST_NEUTRO,\n",
    "             ckpt=\"ckpts/E1_KD_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E2_KD_both_emaware_softgate__neutral_only_F0\",\n",
    "             csv=TEST_NEUTRO,\n",
    "             ckpt=\"ckpts/E2_KD_both_emaware_softgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatesoft/best_student.pt\"),\n",
    "        dict(name=\"E3_KD_both_emaware_hardgate__neutral_only_F0\",\n",
    "             csv=TEST_NEUTRO,\n",
    "             ckpt=\"ckpts/E3_KD_both_emaware_hardgate__neutral_only_F0__L21__top1__mid0.5__p1__schedwarmup__gatehard/best_student.pt\"),\n",
    "    ]\n",
    "\n",
    "    out_root = Path(\"reports_eval_only\")\n",
    "    out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Dummy moduli richiesti da evaluate_emotion in firma (non usati in eval)\n",
    "    dummy_proj_top = nn.Linear(512, 128)\n",
    "    dummy_proj_mid = nn.Linear(512, 512)\n",
    "    dummy_top_adapter = nn.Identity()\n",
    "    dummy_mid_adapter = nn.Identity()\n",
    "\n",
    "    summary = []\n",
    "    for e in EVALS:\n",
    "        name, csv, ckpt = e[\"name\"], e[\"csv\"], e[\"ckpt\"]\n",
    "\n",
    "        # Skip se file mancanti\n",
    "        if not Path(csv).exists():\n",
    "            print(f\"[SKIP] CSV test mancante: {csv}\")\n",
    "            continue\n",
    "        if not Path(ckpt).exists():\n",
    "            print(f\"[SKIP] Checkpoint mancante: {ckpt}\")\n",
    "            continue\n",
    "\n",
    "        run_dir = out_root / name\n",
    "        run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        rep = evaluate_emotion(\n",
    "            csv_path=csv,\n",
    "            ckpt_path=ckpt,\n",
    "            proj_l11_top=dummy_proj_top,\n",
    "            proj_l10_mid=dummy_proj_mid,\n",
    "            top_adapter=dummy_top_adapter,\n",
    "            mid_adapter=dummy_mid_adapter,\n",
    "            proj_dim=128,\n",
    "            run_dir=str(run_dir),\n",
    "            title=\"TEST\"\n",
    "        )\n",
    "\n",
    "        # Prepara caption/label compatibili con LaTeX\n",
    "        safe_name_for_tex = name.replace('_', r'\\_')\n",
    "        safe_label        = name.replace('_', '-')\n",
    "\n",
    "        tex = _latex_per_emozione(\n",
    "            rep[\"per_emotion\"], rep[\"ece\"],\n",
    "            caption=\"Prestazioni per emozione — \" + safe_name_for_tex,\n",
    "            label=f\"tab:per-emozione-{safe_label}\"\n",
    "        )\n",
    "        (run_dir / f\"per_emozione_{name}.tex\").write_text(tex, encoding=\"utf-8\")\n",
    "\n",
    "        # Log console\n",
    "        print(f\"\\n[{name}] N={rep['N']}  Acc={rep['acc']:.3f}  Macro-F1={rep['macro_f1']:.3f}  ESI={rep['esi']:.3f}  WorstAcc={rep['worst_acc']:.3f}\")\n",
    "        print(\"\\n----- Tabella LaTeX -----\\n\")\n",
    "        print(tex)\n",
    "        print(\"\\n-------------------------\")\n",
    "\n",
    "        summary.append(dict(\n",
    "            name=name,\n",
    "            N=rep[\"N\"],\n",
    "            acc=rep[\"acc\"],\n",
    "            macro_f1=rep[\"macro_f1\"],\n",
    "            esi=rep[\"esi\"],\n",
    "            worst_acc=rep[\"worst_acc\"]\n",
    "        ))\n",
    "\n",
    "    pd.DataFrame(summary).to_csv(out_root / \"summary_eval_only.csv\", index=False)\n",
    "    print(\"\\n[OK] Salvato:\", (out_root / \"summary_eval_only.csv\").resolve())\n",
    "\n",
    "# ===== Entry point (usa solo i dataset forniti) =====\n",
    "if __name__ == \"__main__\":\n",
    "    # run_suite_emotion()  # lascia commentato se non vuoi allenare\n",
    "    eval_from_datasets_only()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6398375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Split: full_F0 ===\n",
      "  [WARN] baseline 'E0_noKD' non trovata per split=full_F0. Salto.\n",
      "\n",
      "=== Split: neutral_only_F0 ===\n",
      "  [WARN] baseline 'E0_noKD' non trovata per split=neutral_only_F0. Salto.\n",
      "\n",
      "[ZIP] reports/plots_per_emotion_ALL.zip creato.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Per-emotion analysis + McNemar significance (FDR) per tutte le run.\n",
    "\n",
    "- Baseline: 'E0_noKD'\n",
    "- Per ciascuno split ('full_F0', 'neutral_only_F0'):\n",
    "    • trova la baseline più recente\n",
    "    • per ogni altra run nello stesso split:\n",
    "        - calcola ΔAcc e ΔF1 per emozione (vs baseline)\n",
    "        - stima McNemar per emozione da TEST__preds.csv (two-sided exact)\n",
    "        - applica FDR 0.05\n",
    "        - salva CSV di diagnosi e McNemar\n",
    "        - genera due grafici (ΔF1, ΔAcc) con * sulle emozioni significative\n",
    "- Salva tutto sotto reports/\n",
    "- Crea anche uno ZIP con tutti i plot.\n",
    "\n",
    "Nota: l’allineamento per McNemar assume che l’ordine del test loader sia identico\n",
    "tra baseline e KD (com’è nella tua pipeline). In caso contrario, adegua qui\n",
    "aggiungendo un ID stabile nella generazione dei preds.\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, warnings, zipfile\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import comb\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Config\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "REPORTS_DIR = Path(\"reports\")\n",
    "SPLITS = [\"full_F0\", \"neutral_only_F0\"]          # modifica se serve\n",
    "BASE_TAG = \"E0_noKD\"\n",
    "\n",
    "# Metti None per considerare \"tutte\" le run trovate (eccetto baseline).\n",
    "# In alternativa specifica i tag che vuoi plottare.\n",
    "RUN_TAGS = None\n",
    "# RUN_TAGS = [\"E1b_noGate_both_base\",\"E4_noGate_top_only\",\"E5_noGate_light\",\"E7_noGate_mid_only\"]\n",
    "\n",
    "EMOTIONS_ORDER = [\"neutro\",\"rabbia\",\"disgusto\",\"paura\",\"gioia\",\"tristezza\",\"sorpresa\"]\n",
    "ALPHA_FDR = 0.05\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Helpers: file system\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def _find_latest_report_dir(tag: str, split: str) -> Path | None:\n",
    "    pats = [f\"{REPORTS_DIR}/*{tag}*__{split}\", f\"{REPORTS_DIR}/**/*{tag}*__{split}\"]\n",
    "    cands = []\n",
    "    for p in pats:\n",
    "        cands += glob.glob(p, recursive=True)\n",
    "    if not cands:\n",
    "        return None\n",
    "    cands.sort(key=lambda p: os.path.getmtime(p))\n",
    "    return Path(cands[-1])\n",
    "\n",
    "def _ensure_test_files(run_dir: Path):\n",
    "    req = [\"TEST__per_emotion.csv\", \"TEST__preds.csv\"]\n",
    "    miss = [f for f in req if not (run_dir / f).exists()]\n",
    "    if miss:\n",
    "        raise FileNotFoundError(f\"Mancano file {miss} in {run_dir}\")\n",
    "\n",
    "def _load_per_emotion(run_dir: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(run_dir / \"TEST__per_emotion.csv\")\n",
    "    need = {\"emotion\",\"acc\",\"macro_f1\"}\n",
    "    if not need.issubset(df.columns):\n",
    "        raise ValueError(f\"Colonne mancanti in {run_dir/'TEST__per_emotion.csv'}; attese {need}\")\n",
    "    return df\n",
    "\n",
    "def _load_preds(run_dir: Path) -> pd.DataFrame:\n",
    "    p = run_dir / \"TEST__preds.csv\"\n",
    "    df = pd.read_csv(p)\n",
    "    need = {\"y\",\"yhat\",\"emotion\",\"prob_en\",\"prob_it\",\"prob_es\"}\n",
    "    if not need.issubset(df.columns):\n",
    "        raise ValueError(f\"Colonne mancanti in {p}; attese {need}\")\n",
    "    return df\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Helpers: McNemar + FDR\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def mcnemar_exact_p(b: int, c: int) -> float:\n",
    "    \"\"\"Two-sided exact binomial McNemar: p = 2 * sum_{i<=min(b,c)} C(b+c, i) * 0.5^(b+c).\"\"\"\n",
    "    n = b + c\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    k = min(b, c)\n",
    "    tail = sum(comb(n, i) for i in range(0, k+1))\n",
    "    p = 2.0 * tail * (0.5 ** n)\n",
    "    return float(min(p, 1.0))\n",
    "\n",
    "def fdr_bh(pvals: list[float], alpha: float = 0.05) -> np.ndarray:\n",
    "    pv = np.array([np.nan if (p is None) else p for p in pvals], dtype=float)\n",
    "    m = np.sum(~np.isnan(pv))\n",
    "    if m == 0:\n",
    "        return np.array([False]*len(pv))\n",
    "    order = np.argsort(pv)\n",
    "    rank = np.empty_like(order)\n",
    "    rank[order] = np.arange(1, len(pv)+1)\n",
    "    thresh = alpha * rank / m\n",
    "    sig = pv <= thresh\n",
    "    max_k = np.where(sig)[0].max() if sig.any() else -1\n",
    "    if max_k >= 0:\n",
    "        sig = np.zeros_like(sig, dtype=bool)\n",
    "        sig[order[:max_k+1]] = True\n",
    "    return sig\n",
    "\n",
    "def mcnemar_per_emotion(base_preds: pd.DataFrame, kd_preds: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Restituisce: emotion, N, b, c, mcnemar_p, FDR_sig_0.05.\"\"\"\n",
    "    if len(base_preds) != len(kd_preds):\n",
    "        raise ValueError(\"Predictions length mismatch tra baseline e KD.\")\n",
    "    rows = []\n",
    "    # grouping by emotion; assumiamo stesso ordine del loader → allineamento per indice\n",
    "    for emo, g_base in base_preds.groupby(\"emotion\"):\n",
    "        idx = g_base.index\n",
    "        g_kd = kd_preds.loc[idx]\n",
    "        y   = g_base[\"y\"].values\n",
    "        base_correct = (g_base[\"yhat\"].values == y)\n",
    "        kd_correct   = (g_kd[\"yhat\"].values == y)\n",
    "        b = int(np.sum((base_correct == 1) & (kd_correct == 0)))  # baseline giusta, kd sbaglia\n",
    "        c = int(np.sum((base_correct == 0) & (kd_correct == 1)))  # baseline sbaglia, kd giusta\n",
    "        p = mcnemar_exact_p(b, c)\n",
    "        rows.append({\"emotion\": emo, \"N\": int(len(g_base)), \"b\": b, \"c\": c, \"mcnemar_p\": p})\n",
    "    out = pd.DataFrame(rows).sort_values(\"emotion\")\n",
    "    out[\"FDR_sig_0.05\"] = fdr_bh(out[\"mcnemar_p\"].tolist(), alpha=ALPHA_FDR)\n",
    "    return out\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Δ per-emozione (Acc/F1) e merge con McNemar\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def compute_delta_tables_with_stats(base_dir: Path, kd_dir: Path) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Ritorna:\n",
    "      - delta_df: emotion, acc_base, acc_kd, ΔAcc, macro_f1_base, macro_f1_kd, ΔF1 (+ eventuali ΔECE)\n",
    "      - mcn_df:   emotion, N, b, c, mcnemar_p, FDR_sig_0.05\n",
    "      - merged:   delta_df + mcn_df (merge on 'emotion')\n",
    "    \"\"\"\n",
    "    _ensure_test_files(base_dir)\n",
    "    _ensure_test_files(kd_dir)\n",
    "\n",
    "    # Δ per-emozione da TEST__per_emotion.csv\n",
    "    pe_base = _load_per_emotion(base_dir).rename(columns={\"acc\":\"acc_base\",\"macro_f1\":\"macro_f1_base\"})\n",
    "    pe_kd   = _load_per_emotion(kd_dir).rename(columns={\"acc\":\"acc_kd\",\"macro_f1\":\"macro_f1_kd\"})\n",
    "    delta_df = pe_kd.merge(pe_base, on=\"emotion\", how=\"inner\")\n",
    "    delta_df[\"ΔAcc\"] = delta_df[\"acc_kd\"] - delta_df[\"acc_base\"]\n",
    "    delta_df[\"ΔF1\"]  = delta_df[\"macro_f1_kd\"] - delta_df[\"macro_f1_base\"]\n",
    "\n",
    "    # (opzionale) ECE\n",
    "    eceb = base_dir / \"TEST__ece_per_emotion.csv\"\n",
    "    ecek = kd_dir   / \"TEST__ece_per_emotion.csv\"\n",
    "    if eceb.exists() and ecek.exists():\n",
    "        eb = pd.read_csv(eceb).rename(columns={\"ECE\":\"ECE_base\"})\n",
    "        ek = pd.read_csv(ecek).rename(columns={\"ECE\":\"ECE_kd\"})\n",
    "        delta_df = delta_df.merge(ek, on=\"emotion\", how=\"left\").merge(eb, on=\"emotion\", how=\"left\")\n",
    "        delta_df[\"ΔECE\"] = delta_df[\"ECE_kd\"] - delta_df[\"ECE_base\"]\n",
    "\n",
    "    # McNemar per-emozione da TEST__preds.csv\n",
    "    base_preds = _load_preds(base_dir)\n",
    "    kd_preds   = _load_preds(kd_dir)\n",
    "    mcn_df = mcnemar_per_emotion(base_preds, kd_preds)\n",
    "\n",
    "    # Merge + ordering\n",
    "    merged = delta_df.merge(mcn_df, on=\"emotion\", how=\"left\")\n",
    "    if set(EMOTIONS_ORDER).issuperset(set(merged[\"emotion\"].unique())):\n",
    "        merged[\"__ord\"] = merged[\"emotion\"].map({e:i for i,e in enumerate(EMOTIONS_ORDER)})\n",
    "        merged = merged.sort_values(\"__ord\").drop(columns=\"__ord\")\n",
    "        delta_df = merged[[c for c in delta_df.columns if c in merged.columns]]\n",
    "        mcn_df   = merged[[c for c in mcn_df.columns if c in merged.columns]]\n",
    "\n",
    "    return delta_df, mcn_df, merged\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Plotting\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def plot_delta_bar(merged_df: pd.DataFrame, metric: str, title: str, out_png: Path):\n",
    "    \"\"\"\n",
    "    Grafico a barre orizzontali per 'metric' (ΔF1 oppure ΔAcc).\n",
    "    Barre annotate con valore e * per FDR_sig_0.05.\n",
    "    \"\"\"\n",
    "    if metric not in merged_df.columns:\n",
    "        warnings.warn(f\"Metric '{metric}' non presente; skip {out_png.name}\")\n",
    "        return\n",
    "\n",
    "    df = merged_df.copy()\n",
    "    # ordine emozioni noto\n",
    "    if set(EMOTIONS_ORDER).issuperset(set(df[\"emotion\"].unique())):\n",
    "        df[\"__ord\"] = df[\"emotion\"].map({e:i for i,e in enumerate(EMOTIONS_ORDER)})\n",
    "        df = df.sort_values(\"__ord\").drop(columns=\"__ord\")\n",
    "    else:\n",
    "        df = df.sort_values(\"emotion\")\n",
    "\n",
    "    emos = df[\"emotion\"].tolist()\n",
    "    vals = df[metric].astype(float).values\n",
    "    sigs = df.get(\"FDR_sig_0.05\", pd.Series([False]*len(df))).astype(bool).values\n",
    "\n",
    "    y = np.arange(len(emos))\n",
    "    plt.figure(figsize=(8.0, 4.8))\n",
    "    plt.barh(y, vals)\n",
    "    plt.axvline(0.0, linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    for i, (v, s) in enumerate(zip(vals, sigs)):\n",
    "        label = f\"{v:+.3f}\" + (\" *\" if s else \"\")\n",
    "        plt.text(v + (0.01 if v>=0 else -0.01), i, label,\n",
    "                 va=\"center\", ha=\"left\" if v>=0 else \"right\", fontsize=9)\n",
    "\n",
    "    plt.yticks(y, emos)\n",
    "    plt.xlabel(metric)\n",
    "    plt.title(title + (\"  ( * = FDR<0.05 )\" if sigs.any() else \"\"))\n",
    "    plt.tight_layout()\n",
    "    out_png.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(out_png, dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "def zip_dir(src_dir: Path, zip_path: Path):\n",
    "    with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "        for p in src_dir.rglob(\"*\"):\n",
    "            if p.is_file():\n",
    "                zf.write(p, p.relative_to(src_dir))\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Main\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def main():\n",
    "    if not REPORTS_DIR.exists():\n",
    "        raise SystemExit(\"Cartella 'reports/' non trovata.\")\n",
    "\n",
    "    out_root = REPORTS_DIR / \"plots_per_emotion_ALL\"\n",
    "    out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for split in SPLITS:\n",
    "        print(f\"\\n=== Split: {split} ===\")\n",
    "        base_dir = _find_latest_report_dir(BASE_TAG, split)\n",
    "        if base_dir is None:\n",
    "            print(f\"  [WARN] baseline '{BASE_TAG}' non trovata per split={split}. Salto.\")\n",
    "            continue\n",
    "\n",
    "        # scopri tutte le run per lo split (tranne baseline)\n",
    "        candidates = sorted(glob.glob(f\"{REPORTS_DIR}/*__{split}\"))\n",
    "        runs = []\n",
    "        for c in candidates:\n",
    "            cpath = Path(c)\n",
    "            tag = cpath.name.split(\"__\")[0]\n",
    "            if tag == BASE_TAG:\n",
    "                continue\n",
    "            if RUN_TAGS is not None and tag not in RUN_TAGS:\n",
    "                continue\n",
    "            runs.append((tag, cpath))\n",
    "\n",
    "        if not runs:\n",
    "            print(f\"  [WARN] Nessuna run trovata per split={split}.\")\n",
    "            continue\n",
    "\n",
    "        out_dir_split = out_root / split\n",
    "        out_dir_split.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # cartella per CSV McNemar\n",
    "        posthoc_dir = REPORTS_DIR / f\"posthoc__{split}\"\n",
    "        posthoc_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for tag, kd_dir in runs:\n",
    "            try:\n",
    "                delta_df, mcn_df, merged = compute_delta_tables_with_stats(base_dir, kd_dir)\n",
    "            except Exception as e:\n",
    "                print(f\"  [WARN] Skip {tag}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # salva CSV diagnosi e McNemar\n",
    "            diag_csv = REPORTS_DIR / f\"diagnose__{tag}__{split}.csv\"\n",
    "            diag_stats_csv = REPORTS_DIR / f\"diagnose__{tag}__{split}__with_stats.csv\"\n",
    "            mcn_csv  = posthoc_dir / f\"mcnemar_{tag}.csv\"\n",
    "\n",
    "            # tabelle pulite\n",
    "            delta_df.to_csv(diag_csv, index=False)\n",
    "            merged.to_csv(diag_stats_csv, index=False)\n",
    "            mcn_df.to_csv(mcn_csv, index=False)\n",
    "\n",
    "            print(f\"  [saved] {diag_csv.name}, {diag_stats_csv.name}, posthoc__ mcnemar_{tag}.csv\")\n",
    "\n",
    "            # plot ΔF1 e ΔAcc con marcatori di significatività\n",
    "            title_f1  = f\"{tag} vs {BASE_TAG} — {split} — ΔF1 per emozione\"\n",
    "            title_acc = f\"{tag} vs {BASE_TAG} — {split} — ΔAccuracy per emozione\"\n",
    "            out_f1  = out_dir_split / f\"{tag}__{split}__deltaF1.png\"\n",
    "            out_acc = out_dir_split / f\"{tag}__{split}__deltaACC.png\"\n",
    "\n",
    "            plot_delta_bar(merged, \"ΔF1\",  title_f1,  out_f1)\n",
    "            plot_delta_bar(merged, \"ΔAcc\", title_acc, out_acc)\n",
    "\n",
    "            print(f\"  [saved] {out_f1.name}, {out_acc.name}\")\n",
    "\n",
    "    # zip di tutti i plot\n",
    "    zip_path = REPORTS_DIR / \"plots_per_emotion_ALL.zip\"\n",
    "    zip_dir(out_root, zip_path)\n",
    "    print(f\"\\n[ZIP] {zip_path} creato.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee81b1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Nessun report baseline per tag=E0_noKD split=full_F0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m pick_run_dir_or_none(BASE_TAG, SPLIT)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNessun report baseline per tag=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_TAG\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m split=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSPLIT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m kd_dirs \u001b[38;5;241m=\u001b[39m {k: d \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m KD_TAGS \u001b[38;5;28;01mif\u001b[39;00m (d \u001b[38;5;241m:=\u001b[39m pick_run_dir_or_none(k, SPLIT)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBASE:\u001b[39m\u001b[38;5;124m\"\u001b[39m, base_dir)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Nessun report baseline per tag=E0_noKD split=full_F0"
     ]
    }
   ],
   "source": [
    "# === POST-STEP: Analisi significatività per emozione (aggiornato con E4) ===\n",
    "import os, glob, json, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "REPORTS_DIR = Path(\"reports\")\n",
    "\n",
    "# scegli split e quali run confrontare\n",
    "SPLIT = \"full_F0\"  # \"full_F0\" | \"neutral_only_F0\"\n",
    "BASE_TAG = \"E0_noKD\"\n",
    "# aggiunto E4 top-only\n",
    "KD_TAGS  = [\n",
    "    \"E0_noKD\",\n",
    "    \"E1b_noGate_both_base\",\n",
    "    \"E4_noGate_top_only\",\n",
    "    \"E5_noGate_light\",\n",
    "    \"E7_noGate_mid_only\",\n",
    "]\n",
    "\n",
    "def pick_run_dir_or_none(tag, split):\n",
    "    cand = sorted(glob.glob(f\"{REPORTS_DIR}/*{tag}*__{split}\"))\n",
    "    return cand[-1] if cand else None\n",
    "\n",
    "base_dir = pick_run_dir_or_none(BASE_TAG, SPLIT)\n",
    "if base_dir is None:\n",
    "    raise FileNotFoundError(f\"Nessun report baseline per tag={BASE_TAG} split={SPLIT}\")\n",
    "kd_dirs = {k: d for k in KD_TAGS if (d := pick_run_dir_or_none(k, SPLIT)) is not None}\n",
    "\n",
    "print(\"BASE:\", base_dir)\n",
    "print(\"KD trovate:\", kd_dirs)\n",
    "\n",
    "# carica preds (stessa ordine del test loader)\n",
    "def load_preds_csv(run_dir: str|Path):\n",
    "    p = Path(run_dir)/\"TEST__preds.csv\"\n",
    "    df = pd.read_csv(p)\n",
    "    req = [\"y\",\"yhat\",\"emotion\",\"prob_en\",\"prob_it\",\"prob_es\"]\n",
    "    miss = [c for c in req if c not in df.columns]\n",
    "    if miss: raise ValueError(f\"Mancano colonne in {p}: {miss}\")\n",
    "    return df\n",
    "\n",
    "base_df = load_preds_csv(base_dir)\n",
    "kd_dfs  = {k: load_preds_csv(v) for k,v in kd_dirs.items()}\n",
    "\n",
    "# sanity: stesse lunghezze\n",
    "for k,df in kd_dfs.items():\n",
    "    assert len(df)==len(base_df), f\"Lunghezze diverse tra {k} e baseline\"\n",
    "print(f\"N test = {len(base_df)}\")\n",
    "\n",
    "from math import comb\n",
    "\n",
    "def mcnemar_exact_p(b, c):\n",
    "    n = b + c\n",
    "    if n == 0: return np.nan\n",
    "    k = min(b, c)\n",
    "    tail = sum(comb(n, i) for i in range(0, k+1))\n",
    "    p = 2.0 * tail * (0.5 ** n)\n",
    "    return float(min(p, 1.0))\n",
    "\n",
    "def fdr_bh(pvals, alpha=0.05):\n",
    "    pv = np.array([np.nan if (p is None) else p for p in pvals], dtype=float)\n",
    "    m = np.sum(~np.isnan(pv))\n",
    "    if m == 0: return np.array([False]*len(pv))\n",
    "    order = np.argsort(pv)\n",
    "    rank = np.empty_like(order); rank[order] = np.arange(1, len(pv)+1)\n",
    "    thresh = alpha * rank / m\n",
    "    sig = pv <= thresh\n",
    "    max_k = np.where(sig)[0].max() if sig.any() else -1\n",
    "    if max_k >= 0:\n",
    "        sig = np.zeros_like(sig, dtype=bool); sig[order[:max_k+1]] = True\n",
    "    return sig\n",
    "\n",
    "def per_emotion_delta_and_mcnemar(base_df, kd_df):\n",
    "    rows=[]\n",
    "    for emo, g_base in base_df.groupby(\"emotion\"):\n",
    "        g_kd = kd_df.iloc[g_base.index]  # allineamento per indice\n",
    "        y   = g_base[\"y\"].values\n",
    "        b_c = (g_base[\"yhat\"].values == y)\n",
    "        k_c = (g_kd[\"yhat\"].values == y)\n",
    "        b = np.sum((b_c == 1) & (k_c == 0))  # baseline right, kd wrong\n",
    "        c = np.sum((b_c == 0) & (k_c == 1))  # baseline wrong, kd right\n",
    "        p = mcnemar_exact_p(b, c)\n",
    "\n",
    "        from sklearn.metrics import accuracy_score, f1_score\n",
    "        acc_b = accuracy_score(y, g_base[\"yhat\"].values) if len(y) else np.nan\n",
    "        acc_k = accuracy_score(y, g_kd[\"yhat\"].values)   if len(y) else np.nan\n",
    "        f1_b  = f1_score(y, g_base[\"yhat\"].values, average=\"macro\") if len(y) else np.nan\n",
    "        f1_k  = f1_score(y, g_kd[\"yhat\"].values,   average=\"macro\") if len(y) else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"emotion\": emo,\n",
    "            \"N\": int(len(g_base)),\n",
    "            \"b\": int(b), \"c\": int(c), \"mcnemar_p\": p,\n",
    "            \"acc_base\": acc_b, \"acc_kd\": acc_k, \"ΔAcc\": acc_k-acc_b,\n",
    "            \"F1_base\": f1_b,  \"F1_kd\":  f1_k,   \"ΔF1\": f1_k-f1_b\n",
    "        })\n",
    "    out = pd.DataFrame(rows).sort_values(\"emotion\")\n",
    "    out[\"FDR_sig_0.05\"] = fdr_bh(out[\"mcnemar_p\"].values, alpha=0.05)\n",
    "    return out\n",
    "\n",
    "# genera tabelle per ciascuna KD e salva\n",
    "OUT_DIR = REPORTS_DIR / f\"posthoc__{SPLIT}\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tables = {}\n",
    "for tag, dfk in kd_dfs.items():\n",
    "    tbl = per_emotion_delta_and_mcnemar(base_df, dfk)\n",
    "    tables[tag] = tbl\n",
    "    p_csv = OUT_DIR / f\"mcnemar_{tag}.csv\"\n",
    "    tbl.to_csv(p_csv, index=False)\n",
    "    print(f\"[saved] {p_csv}\")\n",
    "\n",
    "# riassunto rapido\n",
    "for tag,tbl in tables.items():\n",
    "    print(f\"\\n== {tag} ==\")\n",
    "    print(tbl[[\"emotion\",\"N\",\"ΔF1\",\"ΔAcc\",\"mcnemar_p\",\"FDR_sig_0.05\"]].to_string(index=False))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "PLOTS_DIR = OUT_DIR / \"plots\"\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def reliability_plot(df, title, out_png):\n",
    "    probs = df[[\"prob_en\",\"prob_it\",\"prob_es\"]].values\n",
    "    yhat  = probs.argmax(1)\n",
    "    y     = df[\"y\"].values\n",
    "    conf  = probs.max(1)\n",
    "    correct = (yhat == y).astype(int)\n",
    "    frac_pos, mean_pred = calibration_curve(correct, conf, n_bins=12, strategy=\"uniform\")\n",
    "    plt.figure(figsize=(4.8,4.8))\n",
    "    plt.plot([0,1],[0,1], linestyle=\"--\", label=\"perfetta\")\n",
    "    plt.plot(mean_pred, frac_pos, marker=\"o\", label=\"osservata\")\n",
    "    plt.xlabel(\"Confidenza media nel bin\")\n",
    "    plt.ylabel(\"Accuratezza osservata\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "# funzione ΔF1 globale (macro)\n",
    "def total_delta_F1(base, kd):\n",
    "    from sklearn.metrics import f1_score\n",
    "    return f1_score(base[\"y\"].values, kd[\"yhat\"].values, average=\"macro\") - \\\n",
    "           f1_score(base[\"y\"].values, base[\"yhat\"].values, average=\"macro\")\n",
    "\n",
    "# scegli la KD migliore tra quelle presenti (potrebbe includere E4)\n",
    "if len(kd_dfs)==0:\n",
    "    raise RuntimeError(\"Nessuna KD trovata per lo split selezionato.\")\n",
    "best_tag = max(kd_dfs.keys(), key=lambda t: total_delta_F1(base_df, kd_dfs[t]))\n",
    "print(\"KD migliore secondo ΔF1 globale:\", best_tag)\n",
    "\n",
    "# reliability globale (baseline vs best KD)\n",
    "reliability_plot(base_df, f\"Reliability — {BASE_TAG}\", PLOTS_DIR/f\"reliability_{BASE_TAG}.png\")\n",
    "reliability_plot(kd_dfs[best_tag], f\"Reliability — {best_tag}\", PLOTS_DIR/f\"reliability_{best_tag}.png\")\n",
    "print(f\"[saved] reliability plots in {PLOTS_DIR}\")\n",
    "\n",
    "# Radar per-emozione (F1): baseline vs KD migliore\n",
    "import numpy as np\n",
    "\n",
    "def radar_per_emotion(tbl_base, tbl_kd, tag_kd, out_png):\n",
    "    emos = tbl_base[\"emotion\"].tolist()\n",
    "    f1b  = tbl_base[\"F1_base\"].values\n",
    "    f1k  = tbl_kd[\"F1_kd\"].values\n",
    "    angles = np.linspace(0, 2*np.pi, len(emos), endpoint=False).tolist()\n",
    "    f1b_c = np.concatenate([f1b, f1b[:1]])\n",
    "    f1k_c = np.concatenate([f1k, f1k[:1]])\n",
    "    ang_c = angles + angles[:1]\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "    ax.plot(ang_c, f1b_c, linewidth=2, label=\"Baseline\")\n",
    "    ax.fill(ang_c, f1b_c, alpha=0.1)\n",
    "    ax.plot(ang_c, f1k_c, linewidth=2, label=tag_kd)\n",
    "    ax.fill(ang_c, f1k_c, alpha=0.1)\n",
    "    ax.set_thetagrids(np.degrees(angles), emos)\n",
    "    ax.set_title(f\"Macro-F1 per emozione — {SPLIT}\")\n",
    "    ax.legend(loc=\"lower right\", bbox_to_anchor=(1.25, -0.1))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=160, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "# usa una delle tabelle (qualsiasi KD) per recuperare i valori 'F1_base'\n",
    "first_tag = next(iter(tables.keys()))\n",
    "tbl_base = tables[first_tag][[\"emotion\",\"F1_base\"]].copy()\n",
    "tbl_kd   = tables[best_tag]\n",
    "radar_per_emotion(tbl_base, tbl_kd, best_tag, PLOTS_DIR/f\"radar_per_emotion_{best_tag}.png\")\n",
    "print(f\"[saved] radar in {PLOTS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8d909405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TRAIN E0_noKD (full_F0) | L2=False  top=0.0 mid=0.0  p=0.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.536\n",
      "    en  it  es\n",
      "en   1   9   7\n",
      "it   3  16   1\n",
      "es   0   1  20\n",
      "  → New best: Val-F1=0.536  saved: ckpts/E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.595\n",
      "    en  it  es\n",
      "en   7   4   6\n",
      "it  11   9   0\n",
      "es   1   0  20\n",
      "  → New best: Val-F1=0.595  saved: ckpts/E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 03  Val-F1=0.648\n",
      "    en  it  es\n",
      "en   7   3   7\n",
      "it   8  12   0\n",
      "es   1   0  20\n",
      "  → New best: Val-F1=0.648  saved: ckpts/E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 04  Val-F1=0.658\n",
      "    en  it  es\n",
      "en  10   2   5\n",
      "it   7  13   0\n",
      "es   6   0  15\n",
      "  → New best: Val-F1=0.658  saved: ckpts/E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 05  Val-F1=0.643\n",
      "    en  it  es\n",
      "en  11   2   4\n",
      "it   9  11   0\n",
      "es   6   0  15\n",
      "Epoch 06  Val-F1=0.719\n",
      "    en  it  es\n",
      "en  10   3   4\n",
      "it   3  17   0\n",
      "es   6   0  15\n",
      "  → New best: Val-F1=0.719  saved: ckpts/E0_noKD__full_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 07  Val-F1=0.514\n",
      "    en  it  es\n",
      "en  13   0   4\n",
      "it  16   4   0\n",
      "es   7   0  14\n",
      "Epoch 08  Val-F1=0.637\n",
      "    en  it  es\n",
      "en  11   1   5\n",
      "it  10   8   2\n",
      "es   2   0  19\n",
      "Epoch 09  Val-F1=0.670\n",
      "    en  it  es\n",
      "en   6   6   5\n",
      "it   0  20   0\n",
      "es   4   2  15\n",
      "Epoch 10  Val-F1=0.584\n",
      "    en  it  es\n",
      "en   4   7   6\n",
      "it   0  20   0\n",
      "es   3   5  13\n",
      "Epoch 11  Val-F1=0.430\n",
      "    en  it  es\n",
      "en  16   1   0\n",
      "it   7  13   0\n",
      "es  21   0   0\n",
      "Epoch 12  Val-F1=0.430\n",
      "    en  it  es\n",
      "en  16   1   0\n",
      "it   7  13   0\n",
      "es  21   0   0\n",
      "Epoch 13  Val-F1=0.715\n",
      "    en  it  es\n",
      "en  14   3   0\n",
      "it   7  13   0\n",
      "es   7   0  14\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.719\n",
      "\n",
      "[TEST] N=49  Acc=0.490  Macro-F1=0.429\n",
      "    en  it  es\n",
      "en  15   4   2\n",
      "it   9   7   5\n",
      "es   4   1   2\n",
      "\n",
      "===== TRAIN E1b_noGate_both_base (full_F0) | L2=True  top=1.0 mid=0.5  p=1.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.362\n",
      "    en  it  es\n",
      "en   2   4  11\n",
      "it   7   4   9\n",
      "es   0   1  20\n",
      "  → New best: Val-F1=0.362  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.373\n",
      "    en  it  es\n",
      "en   3   3  11\n",
      "it   7   3  10\n",
      "es   0   0  21\n",
      "  → New best: Val-F1=0.373  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 03  Val-F1=0.435\n",
      "    en  it  es\n",
      "en   7   1   9\n",
      "it  14   2   4\n",
      "es   0   0  21\n",
      "  → New best: Val-F1=0.435  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 04  Val-F1=0.551\n",
      "    en  it  es\n",
      "en   4   8   5\n",
      "it   9  11   0\n",
      "es   1   1  19\n",
      "  → New best: Val-F1=0.551  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 05  Val-F1=0.590\n",
      "    en  it  es\n",
      "en   3   7   7\n",
      "it   0  20   0\n",
      "es   5   1  15\n",
      "  → New best: Val-F1=0.590  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 06  Val-F1=0.429\n",
      "    en  it  es\n",
      "en  13   0   4\n",
      "it  18   2   0\n",
      "es   9   0  12\n",
      "Epoch 07  Val-F1=0.593\n",
      "    en  it  es\n",
      "en  13   3   1\n",
      "it  12   8   0\n",
      "es   8   0  13\n",
      "  → New best: Val-F1=0.593  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 08  Val-F1=0.628\n",
      "    en  it  es\n",
      "en   8   1   8\n",
      "it  11   9   0\n",
      "es   0   0  21\n",
      "  → New best: Val-F1=0.628  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 09  Val-F1=0.422\n",
      "    en  it  es\n",
      "en  11   0   6\n",
      "it  20   0   0\n",
      "es   2   0  19\n",
      "Epoch 10  Val-F1=0.613\n",
      "    en  it  es\n",
      "en   7   3   7\n",
      "it  10  10   0\n",
      "es   1   0  20\n",
      "Epoch 11  Val-F1=0.620\n",
      "    en  it  es\n",
      "en   2   8   7\n",
      "it   0  19   1\n",
      "es   0   0  21\n",
      "Epoch 12  Val-F1=0.565\n",
      "    en  it  es\n",
      "en   2   6   9\n",
      "it   1  15   4\n",
      "es   0   0  21\n",
      "Epoch 13  Val-F1=0.413\n",
      "    en  it  es\n",
      "en  10   7   0\n",
      "it   3  17   0\n",
      "es  17   3   1\n",
      "Epoch 14  Val-F1=0.627\n",
      "    en  it  es\n",
      "en   7   4   6\n",
      "it   6  11   3\n",
      "es   1   0  20\n",
      "Epoch 15  Val-F1=0.649\n",
      "    en  it  es\n",
      "en   4  10   3\n",
      "it   0  20   0\n",
      "es   3   1  17\n",
      "  → New best: Val-F1=0.649  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 16  Val-F1=0.660\n",
      "    en  it  es\n",
      "en  15   0   2\n",
      "it  13   7   0\n",
      "es   4   0  17\n",
      "  → New best: Val-F1=0.660  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 17  Val-F1=0.594\n",
      "    en  it  es\n",
      "en   4   2  11\n",
      "it   0  13   7\n",
      "es   0   1  20\n",
      "Epoch 18  Val-F1=0.576\n",
      "    en  it  es\n",
      "en  16   0   1\n",
      "it   9   7   4\n",
      "es  10   0  11\n",
      "Epoch 19  Val-F1=0.530\n",
      "    en  it  es\n",
      "en   6   1  10\n",
      "it   7   7   6\n",
      "es   1   0  20\n",
      "Epoch 20  Val-F1=0.290\n",
      "    en  it  es\n",
      "en  17   0   0\n",
      "it  20   0   0\n",
      "es  16   0   5\n",
      "Epoch 21  Val-F1=0.673\n",
      "    en  it  es\n",
      "en   6   7   4\n",
      "it   1  19   0\n",
      "es   5   0  16\n",
      "  → New best: Val-F1=0.673  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 22  Val-F1=0.663\n",
      "    en  it  es\n",
      "en  12   3   2\n",
      "it   8  12   0\n",
      "es   7   0  14\n",
      "Epoch 23  Val-F1=0.630\n",
      "    en  it  es\n",
      "en  10   2   5\n",
      "it   5  10   5\n",
      "es   4   0  17\n",
      "Epoch 24  Val-F1=0.539\n",
      "    en  it  es\n",
      "en   7   1   9\n",
      "it   6   7   7\n",
      "es   2   0  19\n",
      "Epoch 25  Val-F1=0.539\n",
      "    en  it  es\n",
      "en   0  10   7\n",
      "it   0  20   0\n",
      "es   0   1  20\n",
      "Epoch 26  Val-F1=0.639\n",
      "    en  it  es\n",
      "en  10   1   6\n",
      "it   6   9   5\n",
      "es   2   0  19\n",
      "Epoch 27  Val-F1=0.679\n",
      "    en  it  es\n",
      "en  16   0   1\n",
      "it  10   8   2\n",
      "es   5   0  16\n",
      "  → New best: Val-F1=0.679  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 28  Val-F1=0.566\n",
      "    en  it  es\n",
      "en   5   2  10\n",
      "it   4  10   6\n",
      "es   1   0  20\n",
      "Epoch 29  Val-F1=0.682\n",
      "    en  it  es\n",
      "en  13   2   2\n",
      "it   5  10   5\n",
      "es   4   0  17\n",
      "  → New best: Val-F1=0.682  saved: ckpts/E1b_noGate_both_base__full_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 30  Val-F1=0.534\n",
      "    en  it  es\n",
      "en   6   3   8\n",
      "it   5  10   5\n",
      "es   4   1  16\n",
      "Epoch 31  Val-F1=0.628\n",
      "    en  it  es\n",
      "en  11   2   4\n",
      "it   5   9   6\n",
      "es   4   0  17\n",
      "Epoch 32  Val-F1=0.532\n",
      "    en  it  es\n",
      "en   6   2   9\n",
      "it   5   9   6\n",
      "es   4   0  17\n",
      "Epoch 33  Val-F1=0.670\n",
      "    en  it  es\n",
      "en  13   2   2\n",
      "it   8  10   2\n",
      "es   5   0  16\n",
      "Epoch 34  Val-F1=0.642\n",
      "    en  it  es\n",
      "en  13   1   3\n",
      "it   8   8   4\n",
      "es   4   0  17\n",
      "Epoch 35  Val-F1=0.659\n",
      "    en  it  es\n",
      "en  14   1   2\n",
      "it   8   8   4\n",
      "es   4   0  17\n",
      "Epoch 36  Val-F1=0.619\n",
      "    en  it  es\n",
      "en  13   1   3\n",
      "it   8   7   5\n",
      "es   4   0  17\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.682\n",
      "\n",
      "[TEST] N=49  Acc=0.633  Macro-F1=0.474\n",
      "    en  it  es\n",
      "en  18   1   2\n",
      "it   7  13   1\n",
      "es   7   0   0\n",
      "\n",
      "===== TRAIN E4_noGate_top_only (full_F0) | L2=True  top=1.0 mid=0.0  p=1.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.341\n",
      "    en  it  es\n",
      "en  15   0   2\n",
      "it  19   1   0\n",
      "es  14   0   7\n",
      "  → New best: Val-F1=0.341  saved: ckpts/E4_noGate_top_only__full_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.474\n",
      "    en  it  es\n",
      "en  12   1   4\n",
      "it  17   3   0\n",
      "es   7   0  14\n",
      "  → New best: Val-F1=0.474  saved: ckpts/E4_noGate_top_only__full_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 03  Val-F1=0.639\n",
      "    en  it  es\n",
      "en  10   6   1\n",
      "it   4  16   0\n",
      "es  10   0  11\n",
      "  → New best: Val-F1=0.639  saved: ckpts/E4_noGate_top_only__full_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 04  Val-F1=0.663\n",
      "    en  it  es\n",
      "en   5   5   7\n",
      "it   3  17   0\n",
      "es   2   0  19\n",
      "  → New best: Val-F1=0.663  saved: ckpts/E4_noGate_top_only__full_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 05  Val-F1=0.544\n",
      "    en  it  es\n",
      "en  11   2   4\n",
      "it  12   8   0\n",
      "es   9   0  12\n",
      "Epoch 06  Val-F1=0.669\n",
      "    en  it  es\n",
      "en   3   7   7\n",
      "it   0  20   0\n",
      "es   0   0  21\n",
      "  → New best: Val-F1=0.669  saved: ckpts/E4_noGate_top_only__full_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 07  Val-F1=0.349\n",
      "    en  it  es\n",
      "en   5  12   0\n",
      "it   0  20   0\n",
      "es   9  11   1\n",
      "Epoch 08  Val-F1=0.550\n",
      "    en  it  es\n",
      "en  14   3   0\n",
      "it   8  12   0\n",
      "es  15   0   6\n",
      "Epoch 09  Val-F1=0.811\n",
      "    en  it  es\n",
      "en  10   3   4\n",
      "it   0  20   0\n",
      "es   3   0  18\n",
      "  → New best: Val-F1=0.811  saved: ckpts/E4_noGate_top_only__full_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 10  Val-F1=0.642\n",
      "    en  it  es\n",
      "en  10   4   3\n",
      "it   7  13   0\n",
      "es   7   0  14\n",
      "Epoch 11  Val-F1=0.687\n",
      "    en  it  es\n",
      "en   6   4   7\n",
      "it   2  18   0\n",
      "es   1   2  18\n",
      "Epoch 12  Val-F1=0.657\n",
      "    en  it  es\n",
      "en  12   3   2\n",
      "it   2  14   4\n",
      "es   9   0  12\n",
      "Epoch 13  Val-F1=0.727\n",
      "    en  it  es\n",
      "en   7   5   5\n",
      "it   2  18   0\n",
      "es   2   0  19\n",
      "Epoch 14  Val-F1=0.549\n",
      "    en  it  es\n",
      "en   6   9   2\n",
      "it   0  20   0\n",
      "es   5   8   8\n",
      "Epoch 15  Val-F1=0.736\n",
      "    en  it  es\n",
      "en  11   0   6\n",
      "it   7  13   0\n",
      "es   2   0  19\n",
      "Epoch 16  Val-F1=0.634\n",
      "    en  it  es\n",
      "en   2   7   8\n",
      "it   0  20   0\n",
      "es   0   0  21\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.811\n",
      "\n",
      "[TEST] N=49  Acc=0.408  Macro-F1=0.193\n",
      "    en  it  es\n",
      "en  20   1   0\n",
      "it  21   0   0\n",
      "es   7   0   0\n",
      "\n",
      "===== TRAIN E5_noGate_light (full_F0) | L2=True  top=0.5 mid=0.25  p=0.3 sched=warmup gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.440\n",
      "    en  it  es\n",
      "en   8   4   5\n",
      "it   6  11   3\n",
      "es  15   0   6\n",
      "  → New best: Val-F1=0.440  saved: ckpts/E5_noGate_light__full_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.400\n",
      "    en  it  es\n",
      "en   7   6   4\n",
      "it   4  15   1\n",
      "es  13   5   3\n",
      "Epoch 03  Val-F1=0.504\n",
      "    en  it  es\n",
      "en   5   8   4\n",
      "it   0  20   0\n",
      "es   8   6   7\n",
      "  → New best: Val-F1=0.504  saved: ckpts/E5_noGate_light__full_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 04  Val-F1=0.429\n",
      "    en  it  es\n",
      "en  15   0   2\n",
      "it  12   8   0\n",
      "es  18   0   3\n",
      "Epoch 05  Val-F1=0.316\n",
      "    en  it  es\n",
      "en   5  12   0\n",
      "it   0  20   0\n",
      "es  11  10   0\n",
      "Epoch 06  Val-F1=0.592\n",
      "    en  it  es\n",
      "en   4   9   4\n",
      "it   0  20   0\n",
      "es   8   0  13\n",
      "  → New best: Val-F1=0.592  saved: ckpts/E5_noGate_light__full_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 07  Val-F1=0.676\n",
      "    en  it  es\n",
      "en  11   2   4\n",
      "it   7  13   0\n",
      "es   6   0  15\n",
      "  → New best: Val-F1=0.676  saved: ckpts/E5_noGate_light__full_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 08  Val-F1=0.705\n",
      "    en  it  es\n",
      "en   5   4   8\n",
      "it   2  18   0\n",
      "es   0   0  21\n",
      "  → New best: Val-F1=0.705  saved: ckpts/E5_noGate_light__full_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 09  Val-F1=0.545\n",
      "    en  it  es\n",
      "en   2  11   4\n",
      "it   1  19   0\n",
      "es   2   4  15\n",
      "Epoch 10  Val-F1=0.482\n",
      "    en  it  es\n",
      "en   6  10   1\n",
      "it   0  20   0\n",
      "es   9   7   5\n",
      "Epoch 11  Val-F1=0.609\n",
      "    en  it  es\n",
      "en   5   7   5\n",
      "it   5  15   0\n",
      "es   4   0  17\n",
      "Epoch 12  Val-F1=0.612\n",
      "    en  it  es\n",
      "en   7   6   4\n",
      "it   4  16   0\n",
      "es   8   0  13\n",
      "Epoch 13  Val-F1=0.682\n",
      "    en  it  es\n",
      "en   7   2   8\n",
      "it   4  14   2\n",
      "es   1   0  20\n",
      "Epoch 14  Val-F1=0.696\n",
      "    en  it  es\n",
      "en   7   3   7\n",
      "it   5  15   0\n",
      "es   1   0  20\n",
      "Epoch 15  Val-F1=0.615\n",
      "    en  it  es\n",
      "en  13   0   4\n",
      "it  10  10   0\n",
      "es   9   0  12\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.705\n",
      "\n",
      "[TEST] N=49  Acc=0.347  Macro-F1=0.413\n",
      "    en  it  es\n",
      "en   8  10   3\n",
      "it  18   2   1\n",
      "es   0   0   7\n",
      "\n",
      "===== TRAIN E7_noGate_mid_only (full_F0) | L2=True  top=0.0 mid=0.5  p=1.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.343\n",
      "    en  it  es\n",
      "en   9   0   8\n",
      "it  20   0   0\n",
      "es   6   0  15\n",
      "  → New best: Val-F1=0.343  saved: ckpts/E7_noGate_mid_only__full_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.572\n",
      "    en  it  es\n",
      "en   9   5   3\n",
      "it   8  12   0\n",
      "es   6   3  12\n",
      "  → New best: Val-F1=0.572  saved: ckpts/E7_noGate_mid_only__full_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 03  Val-F1=0.545\n",
      "    en  it  es\n",
      "en   8   6   3\n",
      "it   2  18   0\n",
      "es  10   4   7\n",
      "Epoch 04  Val-F1=0.626\n",
      "    en  it  es\n",
      "en  13   1   3\n",
      "it  11   9   0\n",
      "es   7   0  14\n",
      "  → New best: Val-F1=0.626  saved: ckpts/E7_noGate_mid_only__full_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 05  Val-F1=0.612\n",
      "    en  it  es\n",
      "en   8   5   4\n",
      "it   4  16   0\n",
      "es   7   2  12\n",
      "Epoch 06  Val-F1=0.688\n",
      "    en  it  es\n",
      "en   6   5   6\n",
      "it   1  19   0\n",
      "es   4   0  17\n",
      "  → New best: Val-F1=0.688  saved: ckpts/E7_noGate_mid_only__full_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 07  Val-F1=0.602\n",
      "    en  it  es\n",
      "en   3   5   9\n",
      "it   0  17   3\n",
      "es   1   1  19\n",
      "Epoch 08  Val-F1=0.356\n",
      "    en  it  es\n",
      "en   7  10   0\n",
      "it   0  20   0\n",
      "es  13   8   0\n",
      "Epoch 09  Val-F1=0.499\n",
      "    en  it  es\n",
      "en   1  10   6\n",
      "it   0  20   0\n",
      "es   0   7  14\n",
      "Epoch 10  Val-F1=0.594\n",
      "    en  it  es\n",
      "en  14   3   0\n",
      "it   5  15   0\n",
      "es  15   0   6\n",
      "Epoch 11  Val-F1=0.699\n",
      "    en  it  es\n",
      "en   7   4   6\n",
      "it   0  18   2\n",
      "es   4   0  17\n",
      "  → New best: Val-F1=0.699  saved: ckpts/E7_noGate_mid_only__full_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 12  Val-F1=0.471\n",
      "    en  it  es\n",
      "en  11   0   6\n",
      "it  14   1   5\n",
      "es   0   0  21\n",
      "Epoch 13  Val-F1=0.615\n",
      "    en  it  es\n",
      "en   4   6   7\n",
      "it   4  14   2\n",
      "es   0   0  21\n",
      "Epoch 14  Val-F1=0.711\n",
      "    en  it  es\n",
      "en  14   0   3\n",
      "it   9  11   0\n",
      "es   5   0  16\n",
      "  → New best: Val-F1=0.711  saved: ckpts/E7_noGate_mid_only__full_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 15  Val-F1=0.684\n",
      "    en  it  es\n",
      "en  11   1   5\n",
      "it   7   9   4\n",
      "es   0   0  21\n",
      "Epoch 16  Val-F1=0.677\n",
      "    en  it  es\n",
      "en   7   3   7\n",
      "it   7  13   0\n",
      "es   0   0  21\n",
      "Epoch 17  Val-F1=0.680\n",
      "    en  it  es\n",
      "en   7   3   7\n",
      "it   3  14   3\n",
      "es   1   0  20\n",
      "Epoch 18  Val-F1=0.457\n",
      "    en  it  es\n",
      "en  17   0   0\n",
      "it  19   1   0\n",
      "es   9   0  12\n",
      "Epoch 19  Val-F1=0.768\n",
      "    en  it  es\n",
      "en  11   3   3\n",
      "it   2  18   0\n",
      "es   4   1  16\n",
      "  → New best: Val-F1=0.768  saved: ckpts/E7_noGate_mid_only__full_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 20  Val-F1=0.686\n",
      "    en  it  es\n",
      "en   8   5   4\n",
      "it   0  20   0\n",
      "es   8   0  13\n",
      "Epoch 21  Val-F1=0.702\n",
      "    en  it  es\n",
      "en   6   5   6\n",
      "it   0  20   0\n",
      "es   4   0  17\n",
      "Epoch 22  Val-F1=0.730\n",
      "    en  it  es\n",
      "en  12   0   5\n",
      "it   5  15   0\n",
      "es   6   0  15\n",
      "Epoch 23  Val-F1=0.727\n",
      "    en  it  es\n",
      "en  12   2   3\n",
      "it   5  15   0\n",
      "es   6   0  15\n",
      "Epoch 24  Val-F1=0.680\n",
      "    en  it  es\n",
      "en   9   3   5\n",
      "it   3  14   3\n",
      "es   4   0  17\n",
      "Epoch 25  Val-F1=0.744\n",
      "    en  it  es\n",
      "en  15   0   2\n",
      "it   7  12   1\n",
      "es   5   0  16\n",
      "Epoch 26  Val-F1=0.706\n",
      "    en  it  es\n",
      "en   8   0   9\n",
      "it   4  13   3\n",
      "es   0   0  21\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.768\n",
      "\n",
      "[TEST] N=49  Acc=0.673  Macro-F1=0.693\n",
      "    en  it  es\n",
      "en  17   3   1\n",
      "it  10  11   0\n",
      "es   2   0   5\n",
      "\n",
      "===== TRAIN E0_noKD (neutral_only_F0) | L2=False  top=0.0 mid=0.0  p=0.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.417\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   1   1   1\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.417  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.517\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   2   1\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.517  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 03  Val-F1=0.517\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   2   1\n",
      "es   0   0   3\n",
      "Epoch 04  Val-F1=0.517\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   2   1\n",
      "es   0   0   3\n",
      "Epoch 05  Val-F1=0.517\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   2   1\n",
      "es   0   0   3\n",
      "Epoch 06  Val-F1=0.517\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   2   1\n",
      "es   0   0   3\n",
      "Epoch 07  Val-F1=0.552\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   1   2   0\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.552  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 08  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.619  saved: ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 09  Val-F1=0.508\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   1   2\n",
      "Epoch 10  Val-F1=0.508\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   1   2\n",
      "Epoch 11  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Epoch 12  Val-F1=0.413\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   2   1\n",
      "es   0   1   2\n",
      "Epoch 13  Val-F1=0.517\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   2   1\n",
      "es   0   0   3\n",
      "Epoch 14  Val-F1=0.222\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   1   0   2\n",
      "es   0   0   3\n",
      "Epoch 15  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.619\n",
      "\n",
      "[TEST] N=49  Acc=0.469  Macro-F1=0.465\n",
      "    en  it  es\n",
      "en   5  13   3\n",
      "it   6  14   1\n",
      "es   0   3   4\n",
      "\n",
      "===== TRAIN E1b_noGate_both_base (neutral_only_F0) | L2=True  top=1.0 mid=0.5  p=1.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.083\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   3   0   0\n",
      "es   3   0   0\n",
      "  → New best: Val-F1=0.083  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.133\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   2   1   0\n",
      "es   3   0   0\n",
      "  → New best: Val-F1=0.133  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 03  Val-F1=0.111\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   2   1   0\n",
      "es   2   1   0\n",
      "Epoch 04  Val-F1=0.222\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   1   2   0\n",
      "es   2   1   0\n",
      "  → New best: Val-F1=0.222  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 05  Val-F1=0.419\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   1   1   1\n",
      "  → New best: Val-F1=0.419  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 06  Val-F1=0.419\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   1   1   1\n",
      "Epoch 07  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.619  saved: ckpts/E1b_noGate_both_base__neutral_only_F0__L21__top1__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 08  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Epoch 09  Val-F1=0.508\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   1   2\n",
      "Epoch 10  Val-F1=0.467\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   0   3   0\n",
      "es   3   0   0\n",
      "Epoch 11  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Epoch 12  Val-F1=0.467\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   0   3   0\n",
      "es   3   0   0\n",
      "Epoch 13  Val-F1=0.467\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   0   3   0\n",
      "es   3   0   0\n",
      "Epoch 14  Val-F1=0.467\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   0   3   0\n",
      "es   3   0   0\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.619\n",
      "\n",
      "[TEST] N=49  Acc=0.449  Macro-F1=0.365\n",
      "    en  it  es\n",
      "en   0  14   7\n",
      "it   0  16   5\n",
      "es   0   1   6\n",
      "\n",
      "===== TRAIN E4_noGate_top_only (neutral_only_F0) | L2=True  top=1.0 mid=0.0  p=1.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.200\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   0   3\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.200  saved: ckpts/E4_noGate_top_only__neutral_only_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.619  saved: ckpts/E4_noGate_top_only__neutral_only_F0__L21__top1__mid0__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 03  Val-F1=0.508\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   1   2\n",
      "Epoch 04  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Epoch 05  Val-F1=0.383\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   2   1\n",
      "Epoch 06  Val-F1=0.383\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   2   1\n",
      "Epoch 07  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Epoch 08  Val-F1=0.508\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   1   2\n",
      "Epoch 09  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.619\n",
      "\n",
      "[TEST] N=49  Acc=0.306  Macro-F1=0.263\n",
      "    en  it  es\n",
      "en   0  15   6\n",
      "it   0   8  13\n",
      "es   0   0   7\n",
      "\n",
      "===== TRAIN E5_noGate_light (neutral_only_F0) | L2=True  top=0.5 mid=0.25  p=0.3 sched=warmup gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.222\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   0   3   0\n",
      "es   1   2   0\n",
      "  → New best: Val-F1=0.222  saved: ckpts/E5_noGate_light__neutral_only_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.222\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   0   3   0\n",
      "es   1   2   0\n",
      "Epoch 03  Val-F1=0.300\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   0   2   1\n",
      "es   0   2   1\n",
      "  → New best: Val-F1=0.300  saved: ckpts/E5_noGate_light__neutral_only_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 04  Val-F1=0.300\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   0   2   1\n",
      "es   0   2   1\n",
      "Epoch 05  Val-F1=0.206\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   0   1   2\n",
      "es   0   2   1\n",
      "Epoch 06  Val-F1=0.508\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   1   2\n",
      "  → New best: Val-F1=0.508  saved: ckpts/E5_noGate_light__neutral_only_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 07  Val-F1=0.517\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   2   1\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.517  saved: ckpts/E5_noGate_light__neutral_only_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 08  Val-F1=0.517\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   2   1\n",
      "es   0   0   3\n",
      "Epoch 09  Val-F1=0.517\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   2   1\n",
      "es   0   0   3\n",
      "Epoch 10  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.619  saved: ckpts/E5_noGate_light__neutral_only_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\n",
      "Epoch 11  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Epoch 12  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Epoch 13  Val-F1=0.356\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   1   2   0\n",
      "es   2   1   0\n",
      "Epoch 14  Val-F1=0.200\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   0   3   0\n",
      "es   0   3   0\n",
      "Epoch 15  Val-F1=0.619\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   3   0\n",
      "es   0   0   3\n",
      "Epoch 16  Val-F1=0.400\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   1   2   0\n",
      "es   2   0   1\n",
      "Epoch 17  Val-F1=0.262\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   2   1   0\n",
      "es   3   0   0\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.619\n",
      "\n",
      "[TEST] N=49  Acc=0.531  Macro-F1=0.476\n",
      "    en  it  es\n",
      "en   2  14   5\n",
      "it   2  19   0\n",
      "es   0   2   5\n",
      "\n",
      "===== TRAIN E7_noGate_mid_only (neutral_only_F0) | L2=True  top=0.0 mid=0.5  p=1.0 sched=const gate=none emo=none =====\n",
      "Epoch 01  Val-F1=0.556\n",
      "    en  it  es\n",
      "en   1   0   0\n",
      "it   0   0   3\n",
      "es   0   0   3\n",
      "  → New best: Val-F1=0.556  saved: ckpts/E7_noGate_mid_only__neutral_only_F0__L21__top0__mid0.5__p1__schedconst__gatenone__emonone/best_student.pt\n",
      "Epoch 02  Val-F1=0.200\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   0   0   3\n",
      "es   0   0   3\n",
      "Epoch 03  Val-F1=0.222\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   1   0   2\n",
      "es   0   0   3\n",
      "Epoch 04  Val-F1=0.222\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   1   0   2\n",
      "es   0   0   3\n",
      "Epoch 05  Val-F1=0.552\n",
      "    en  it  es\n",
      "en   0   0   1\n",
      "it   1   2   0\n",
      "es   0   0   3\n",
      "Epoch 06  Val-F1=0.200\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   0   3   0\n",
      "es   0   3   0\n",
      "Epoch 07  Val-F1=0.417\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   0   3   0\n",
      "es   1   1   1\n",
      "Epoch 08  Val-F1=0.389\n",
      "    en  it  es\n",
      "en   0   1   0\n",
      "it   0   3   0\n",
      "es   0   2   1\n",
      "Early stopping\n",
      "Best Val-F1 (VAL) = 0.556\n",
      "\n",
      "[TEST] N=49  Acc=0.204  Macro-F1=0.191\n",
      "    en  it  es\n",
      "en   7   0  14\n",
      "it   7   2  12\n",
      "es   6   0   1\n",
      "\n",
      "[Saved] reports/emotion_kd_nogate_summary_all.csv\n",
      "                 run           split  test_macro_f1  test_acc  test_esi  test_worst_emotion_acc\n",
      "             E0_noKD         full_F0       0.428829  0.489796  0.226474                0.000000\n",
      "E1b_noGate_both_base         full_F0       0.474034  0.632653  0.070616                0.400000\n",
      "  E4_noGate_top_only         full_F0       0.193237  0.408163  0.041955                0.200000\n",
      "     E5_noGate_light         full_F0       0.413138  0.346939  0.128767                0.166667\n",
      "  E7_noGate_mid_only         full_F0       0.692601  0.673469  0.231834                0.333333\n",
      "             E0_noKD neutral_only_F0       0.464951  0.469388  0.183782                0.250000\n",
      "E1b_noGate_both_base neutral_only_F0       0.365128  0.448980  0.087540                0.333333\n",
      "  E4_noGate_top_only neutral_only_F0       0.262626  0.306122  0.041144                0.222222\n",
      "     E5_noGate_light neutral_only_F0       0.475602  0.530612  0.194696                0.250000\n",
      "  E7_noGate_mid_only neutral_only_F0       0.191400  0.204082  0.128636                0.000000\n"
     ]
    }
   ],
   "source": [
    "# ==================== TRAIN (NO GATE / NO EMO-WEIGHTS) + REPORT & CONFUSION MATRICES ====================\n",
    "import os, math, json, glob, contextlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "# --- SALVATAGGIO ROBUSTO + CREAZIONE CARTELLE ---\n",
    "from pathlib import Path\n",
    "import torch, os\n",
    "\n",
    "def _ensure_parent(path):\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _safe_save(obj, path, use_legacy=True):\n",
    "    \"\"\"\n",
    "    Crea la cartella padre e salva in modo robusto.\n",
    "    use_legacy=True usa il vecchio serializer (niente ZIP) -> più stabile su macOS.\n",
    "    \"\"\"\n",
    "    _ensure_parent(path)\n",
    "    with open(path, \"wb\") as f:\n",
    "        torch.save(obj, f, _use_new_zipfile_serialization=not use_legacy, pickle_protocol=4)\n",
    "\n",
    "\n",
    "# ---------------- helper: plot CM con colorbar e CSV ----------------\n",
    "def _plot_and_save_cm(y_true, y_pred, labels, title, out_png, normalize=False):\n",
    "    if normalize:\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=list(range(len(labels))), normalize='true')\n",
    "    else:\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=list(range(len(labels))))\n",
    "    fig, ax = plt.subplots(figsize=(5.4, 4.8), dpi=150)\n",
    "    im = ax.imshow(cm, interpolation='nearest', aspect='auto')\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Frequenza' if normalize else 'Conteggi', rotation=90, labelpad=8)\n",
    "\n",
    "    ax.set_title(title, pad=10)\n",
    "    ax.set_xlabel('Predetta'); ax.set_ylabel('Vera')\n",
    "    ax.set_xticks(np.arange(len(labels))); ax.set_xticklabels(labels)\n",
    "    ax.set_yticks(np.arange(len(labels))); ax.set_yticklabels(labels)\n",
    "\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = cm.max() / 2. if cm.size else 0.5\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            val = cm[i, j]\n",
    "            ax.text(j, i, format(val, fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if val > thresh else \"black\")\n",
    "\n",
    "    Path(out_png).parent.mkdir(parents=True, exist_ok=True)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_png, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    pd.DataFrame(cm, index=labels, columns=labels).to_csv(out_png.replace(\".png\",\".csv\"))\n",
    "\n",
    "# ---------------- PATCH: train_one_run_emotion con gate='none' e emo_weights='none' ----------------\n",
    "def train_one_run_emotion_nogate(run_cfg, split_key=\"full_F0\"):\n",
    "    \"\"\"\n",
    "    Come la tua train_one_run_emotion, ma aggiunge:\n",
    "      - CONF_GATE_MODE: 'none' | 'soft' | 'hard'  (qui useremo 'none')\n",
    "      - EMO_WEIGHTS_MODE: 'none' | 'default'      (qui useremo 'none')\n",
    "    \"\"\"\n",
    "    # prende variabili globali già definite nel tuo notebook:\n",
    "    # DATA_SPLITS, L, LANGS, BATCH_SIZE, NUM_WORKERS, LR, WD,\n",
    "    # EPOCHS, MAX_LR, DIV_FACTOR, FINAL_DIV, PATIENCE, Student,\n",
    "    # MouthDSEmotion, build_loaders, SoftFocalLoss, LAM_TOP_EMO, LAM_MID_EMO, e evaluate_emotion\n",
    "    TRAIN_CSV = DATA_SPLITS[split_key][\"train\"]\n",
    "    VAL_CSV   = DATA_SPLITS[split_key][\"val\"]\n",
    "    TEST_CSV  = DATA_SPLITS[split_key][\"test\"]\n",
    "\n",
    "    RUN_ID         = run_cfg['run_id']\n",
    "    USE_L2_ML      = run_cfg.get('USE_L2_ML', False)\n",
    "    LAMBDA_L2_TOP  = float(run_cfg.get('LAMBDA_L2_TOP', 0.0))\n",
    "    LAMBDA_L2_MID  = float(run_cfg.get('LAMBDA_L2_MID', 0.0))\n",
    "    L2_APPLY_PROB  = float(run_cfg.get('L2_APPLY_PROB', 1.0))\n",
    "    L2_SCHEDULE    = run_cfg.get('L2_SCHEDULE', 'const')        # 'const' | 'warmup'\n",
    "    L2_WARMUP_E    = int(run_cfg.get('L2_WARMUP_EPOCHS', 5))\n",
    "    PROJ_DIM       = int(run_cfg.get('PROJ_DIM', 128))\n",
    "\n",
    "    CONF_GATE_MODE   = run_cfg.get('CONF_GATE_MODE', 'none')    # <—— aggiunto 'none'\n",
    "    CONF_GATE_THRESH = float(run_cfg.get('CONF_GATE_THRESH', 0.60))\n",
    "    EMO_WEIGHTS_MODE = run_cfg.get('EMO_WEIGHTS_MODE', 'none')  # <—— 'none' (peso 1.0), 'default' usa dizionari\n",
    "\n",
    "    need_teacher = USE_L2_ML\n",
    "    dl_tr, dl_va = build_loaders(TRAIN_CSV, VAL_CSV, need_teacher=need_teacher)\n",
    "\n",
    "    model = Student(proj_dim=PROJ_DIM)\n",
    "\n",
    "    proj_l11_top = nn.Linear(512, PROJ_DIM)   # teacher top → proj_dim\n",
    "    proj_l10_mid = nn.Linear(512, 512)        # teacher mid → 512\n",
    "\n",
    "    # Freeze BN\n",
    "    for m in model.backbone.modules():\n",
    "        if isinstance(m, nn.BatchNorm3d):\n",
    "            m.eval(); m.weight.requires_grad_(False); m.bias.requires_grad_(False)\n",
    "\n",
    "    # adapter sui real dims teacher\n",
    "    if USE_L2_ML:\n",
    "        d10, d11 = infer_teacher_dims(TRAIN_CSV)\n",
    "        mid_adapter = (nn.Identity() if d10 == 512 else nn.Linear(d10, 512))\n",
    "        top_adapter = (nn.Identity() if d11 == 512 else nn.Linear(d11, 512))\n",
    "    else:\n",
    "        mid_adapter = nn.Identity()\n",
    "        top_adapter = nn.Identity()\n",
    "\n",
    "    params = list(model.parameters()) \\\n",
    "           + list(proj_l11_top.parameters()) \\\n",
    "           + list(proj_l10_mid.parameters())\n",
    "    if isinstance(top_adapter, nn.Linear): params += list(top_adapter.parameters())\n",
    "    if isinstance(mid_adapter, nn.Linear): params += list(mid_adapter.parameters())\n",
    "    opt   = AdamW(params, lr=LR, weight_decay=WD)\n",
    "\n",
    "    total = EPOCHS * max(1, len(dl_tr))\n",
    "    sched = OneCycleLR(opt, max_lr=MAX_LR, total_steps=total, pct_start=0.3,\n",
    "                       div_factor=DIV_FACTOR, final_div_factor=FINAL_DIV, anneal_strategy='cos')\n",
    "    crit  = SoftFocalLoss()\n",
    "\n",
    "    # --- naming: aggiungo tag __gatenone / __emonone ---\n",
    "    run_name = (f\"{RUN_ID}__{split_key}\"\n",
    "                f\"__L2{int(USE_L2_ML)}__top{LAMBDA_L2_TOP:g}__mid{LAMBDA_L2_MID:g}\"\n",
    "                f\"__p{L2_APPLY_PROB:g}__sched{L2_SCHEDULE}\"\n",
    "                f\"__gate{CONF_GATE_MODE}__emo{EMO_WEIGHTS_MODE}\")\n",
    "    ckpt_dir = os.path.join(\"ckpts\", run_name); os.makedirs(ckpt_dir, exist_ok=True)\n",
    "    best_path_student = os.path.join(ckpt_dir, \"best_student.pt\")\n",
    "    best_path_proj_l11 = os.path.join(ckpt_dir, \"best_proj_l11_top.pt\")\n",
    "    best_path_proj_l10 = os.path.join(ckpt_dir, \"best_proj_l10_mid.pt\")\n",
    "    last_path_student = os.path.join(ckpt_dir, \"last_student.pt\")\n",
    "    last_path_proj_l11 = os.path.join(ckpt_dir, \"last_proj_l11_top.pt\")\n",
    "    last_path_proj_l10 = os.path.join(ckpt_dir, \"last_proj_l10_mid.pt\")\n",
    "\n",
    "    run_dir = os.path.join(\"reports\", run_name); os.makedirs(run_dir, exist_ok=True)\n",
    "    epoch_logs = []\n",
    "    best_f1, patience = -1.0, 0\n",
    "\n",
    "    def eff_lambda(base, ep):\n",
    "        if L2_SCHEDULE == 'warmup' and L2_WARMUP_E>0:\n",
    "            return float(base) * min(1.0, ep / L2_WARMUP_E)\n",
    "        return float(base)\n",
    "\n",
    "    print(f\"\\n===== TRAIN {RUN_ID} ({split_key}) | L2={USE_L2_ML}  top={LAMBDA_L2_TOP} mid={LAMBDA_L2_MID}  p={L2_APPLY_PROB} sched={L2_SCHEDULE} gate={CONF_GATE_MODE} emo={EMO_WEIGHTS_MODE} =====\")\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train(); proj_l11_top.train(); proj_l10_mid.train()\n",
    "        if isinstance(top_adapter, nn.Module): top_adapter.train()\n",
    "        if isinstance(mid_adapter, nn.Module): mid_adapter.train()\n",
    "\n",
    "        sup_loss_sum = 0.0\n",
    "        l2_top_sum = 0.0\n",
    "        l2_mid_sum = 0.0\n",
    "        cover_cnt = 0\n",
    "        seen_cnt  = 0\n",
    "\n",
    "        for batch in dl_tr:\n",
    "            if USE_L2_ML:\n",
    "                x, y, emos, tconfs, l10, l11 = batch\n",
    "            else:\n",
    "                x, y, emos, tconfs = batch\n",
    "                l10 = l11 = None\n",
    "\n",
    "            x = x.to('cpu'); y = y.to('cpu'); tconfs = tconfs.to('cpu')\n",
    "\n",
    "            # mixup\n",
    "            y_onehot = F.one_hot(y, len(LANGS)).float()\n",
    "            x_m, y_m, lam, idx = mixup_return_params(x, y_onehot)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            amp_ctx = contextlib.nullcontext\n",
    "\n",
    "            with amp_ctx():\n",
    "                logits_m, f_m, z_v_m = model(x_m)\n",
    "                loss_sup = crit(logits_m, y_m)\n",
    "\n",
    "                l2_top = torch.tensor(0.0)\n",
    "                l2_mid = torch.tensor(0.0)\n",
    "\n",
    "                if USE_L2_ML:\n",
    "                    logits_c, f_c, z_v_c = model(x)\n",
    "\n",
    "                    B = x.size(0)\n",
    "                    have = torch.tensor(\n",
    "                        [(isinstance(l10[i], torch.Tensor)) and (isinstance(l11[i], torch.Tensor)) for i in range(B)],\n",
    "                        dtype=torch.bool\n",
    "                    )\n",
    "                    seen_cnt += int(B); cover_cnt += int(have.sum().item())\n",
    "\n",
    "                    if have.any():\n",
    "                        idxs = torch.nonzero(have).squeeze(1)\n",
    "                        l10_t = torch.stack([l10[i.item()] for i in idxs], dim=0)  # [M, d10]\n",
    "                        l11_t = torch.stack([l11[i.item()] for i in idxs], dim=0)  # [M, d11]\n",
    "                        conf_sel = tconfs[idxs]                                    # [M]\n",
    "                        emo_sel  = [emos[i.item()] for i in idxs]\n",
    "\n",
    "                        # adattatori → 512\n",
    "                        l10_512 = mid_adapter(l10_t)    # [M,512]\n",
    "                        l11_512 = top_adapter(l11_t)    # [M,512]\n",
    "\n",
    "                        f_sel  = f_c[have]              # [M,512]\n",
    "                        z_sel  = z_v_c[have]            # [M,proj]\n",
    "                        pt     = proj_l11_top(l11_512)  # [M,proj]\n",
    "                        pm     = proj_l10_mid(l10_512)  # [M,512]\n",
    "\n",
    "                        # ---- gate confidenza (aggiunto 'none') ----\n",
    "                        if CONF_GATE_MODE == 'soft':\n",
    "                            gate = conf_sel.clamp(0,1)\n",
    "                        elif CONF_GATE_MODE == 'hard':\n",
    "                            gate = (conf_sel >= CONF_GATE_THRESH).float()\n",
    "                        else:  # 'none'\n",
    "                            gate = torch.ones_like(conf_sel)\n",
    "\n",
    "                        # ---- emo weights (aggiunto 'none') ----\n",
    "                        if EMO_WEIGHTS_MODE == 'default':\n",
    "                            lam_top_e = torch.tensor([LAM_TOP_EMO.get(e,1.0) for e in emo_sel], dtype=torch.float32)\n",
    "                            lam_mid_e = torch.tensor([LAM_MID_EMO.get(e,1.0) for e in emo_sel], dtype=torch.float32)\n",
    "                        else:\n",
    "                            lam_top_e = torch.ones(len(emo_sel), dtype=torch.float32)\n",
    "                            lam_mid_e = torch.ones(len(emo_sel), dtype=torch.float32)\n",
    "\n",
    "                        # ---- schedule ----\n",
    "                        lam_top_base = eff_lambda(LAMBDA_L2_TOP, ep)\n",
    "                        lam_mid_base = eff_lambda(LAMBDA_L2_MID, ep)\n",
    "\n",
    "                        # ---- Bernoulli mask per L2_APPLY_PROB (se <1.0) ----\n",
    "                        if L2_APPLY_PROB < 1.0:\n",
    "                            mask = torch.bernoulli(torch.full_like(gate, L2_APPLY_PROB))\n",
    "                        else:\n",
    "                            mask = torch.ones_like(gate)\n",
    "\n",
    "                        # ---- MSE per-sample (normalizzata) ----\n",
    "                        z_n  = F.normalize(z_sel, dim=1);  pt_n = F.normalize(pt, dim=1)\n",
    "                        f_n  = F.normalize(f_sel, dim=1);  pm_n = F.normalize(pm, dim=1)\n",
    "                        top_vec = ((z_n - pt_n)**2).sum(1)   # [M]\n",
    "                        mid_vec = ((f_n - pm_n)**2).sum(1)   # [M]\n",
    "\n",
    "                        # ---- loss pesata ----\n",
    "                        w_top = lam_top_base * lam_top_e * gate * mask\n",
    "                        w_mid = lam_mid_base * lam_mid_e * gate * mask\n",
    "\n",
    "                        eps = 1e-6\n",
    "                        if w_top.sum() > 0:\n",
    "                            l2_top = (w_top * top_vec).sum() / (w_top.sum() + eps)\n",
    "                            loss_sup = loss_sup + l2_top\n",
    "                        if w_mid.sum() > 0:\n",
    "                            l2_mid = (w_mid * mid_vec).sum() / (w_mid.sum() + eps)\n",
    "                            loss_sup = loss_sup + l2_mid\n",
    "\n",
    "                loss = loss_sup\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                list(model.parameters())\n",
    "                + list(proj_l11_top.parameters())\n",
    "                + list(proj_l10_mid.parameters())\n",
    "                + (list(top_adapter.parameters()) if isinstance(top_adapter, nn.Linear) else [])\n",
    "                + (list(mid_adapter.parameters()) if isinstance(mid_adapter, nn.Linear) else []),\n",
    "                1.0\n",
    "            )\n",
    "            opt.step(); opt.zero_grad()\n",
    "            sched.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                sup_loss_sum += float(loss_sup.item())\n",
    "                l2_top_sum   += float(l2_top.item()) if isinstance(l2_top, torch.Tensor) else float(l2_top)\n",
    "                l2_mid_sum   += float(l2_mid.item()) if isinstance(l2_mid, torch.Tensor) else float(l2_mid)\n",
    "\n",
    "        # ---- Validation (macro F1) ----\n",
    "        model.eval()\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in DataLoader(MouthDSEmotion(VAL_CSV, L, augment=False, need_teacher=False),\n",
    "                                    batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False,\n",
    "                                    collate_fn=collate_with_optional_teacher):\n",
    "                x,y,_,_ = batch\n",
    "                logits,_,_ = model(x)\n",
    "                preds += logits.argmax(1).cpu().tolist()\n",
    "                gts   += y.cpu().tolist()\n",
    "        f1 = f1_score(gts, preds, average=\"macro\") if len(gts) else 0.0\n",
    "        cm = confusion_matrix(gts, preds, labels=list(range(len(LANGS))))\n",
    "        print(f\"Epoch {ep:02d}  Val-F1={f1:.3f}\")\n",
    "        print(pd.DataFrame(cm, index=LANGS, columns=LANGS))\n",
    "\n",
    "        # log epoch\n",
    "        loss_sup_mean = sup_loss_sum / max(1, len(dl_tr))\n",
    "        l2_top_mean   = l2_top_sum / max(1, len(dl_tr))\n",
    "        l2_mid_mean   = l2_mid_sum / max(1, len(dl_tr))\n",
    "        cover_rate    = (cover_cnt / max(1, seen_cnt)) * 100.0\n",
    "        epoch_logs.append(dict(epoch=ep, val_f1=float(f1),\n",
    "                               loss_sup_mean=loss_sup_mean,\n",
    "                               loss_l2_top_mean=l2_top_mean,\n",
    "                               loss_l2_mid_mean=l2_mid_mean,\n",
    "                               teacher_cover_pct=cover_rate))\n",
    "        pd.DataFrame(epoch_logs).to_csv(os.path.join(run_dir, \"epoch_log.csv\"), index=False)\n",
    "\n",
    "        # early stopping\n",
    "        improved = f1 > best_f1 + 1e-6\n",
    "        if improved:\n",
    "            best_f1, patience = f1, 0\n",
    "            torch.save(model.state_dict(), best_path_student)\n",
    "            torch.save(proj_l11_top.state_dict(), best_path_proj_l11)\n",
    "            torch.save(proj_l10_mid.state_dict(), best_path_proj_l10)\n",
    "            print(f\"  → New best: Val-F1={f1:.3f}  saved: {best_path_student}\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= PATIENCE:\n",
    "                print(\"Early stopping\"); break\n",
    "\n",
    "    # save last\n",
    "    torch.save(model.state_dict(), last_path_student)\n",
    "    torch.save(proj_l11_top.state_dict(), last_path_proj_l11)\n",
    "    torch.save(proj_l10_mid.state_dict(), last_path_proj_l10)\n",
    "    print(f\"Best Val-F1 (VAL) = {best_f1:.3f}\")\n",
    "\n",
    "    # ---- TEST + report (usa evaluate_emotion già definita) ----\n",
    "    test_report = evaluate_emotion(TEST_CSV, best_path_student,\n",
    "                                   proj_l11_top, proj_l10_mid, top_adapter, mid_adapter,\n",
    "                                   proj_dim=PROJ_DIM, run_dir=run_dir, title=\"TEST\")\n",
    "\n",
    "    # ---- Confusion matrices (PNG + CSV) sul TEST ----\n",
    "    dfp = test_report[\"preds\"]\n",
    "    y_true = dfp[\"y\"].values\n",
    "    y_pred = dfp[\"yhat\"].values\n",
    "    _plot_and_save_cm(y_true, y_pred, labels=LANGS,\n",
    "                      title=f\"{run_name} — CM (raw)\",\n",
    "                      out_png=os.path.join(run_dir, \"cm_raw.png\"),\n",
    "                      normalize=False)\n",
    "    _plot_and_save_cm(y_true, y_pred, labels=LANGS,\n",
    "                      title=f\"{run_name} — CM (normalized)\",\n",
    "                      out_png=os.path.join(run_dir, \"cm_norm.png\"),\n",
    "                      normalize=True)\n",
    "\n",
    "    # ---- summary.json ----\n",
    "    summary = {\n",
    "        \"run\": RUN_ID,\n",
    "        \"split\": split_key,\n",
    "        \"USE_L2_ML\": int(USE_L2_ML),\n",
    "        \"L2_top\": LAMBDA_L2_TOP,\n",
    "        \"L2_mid\": LAMBDA_L2_MID,\n",
    "        \"L2_apply_prob\": L2_APPLY_PROB,\n",
    "        \"L2_schedule\": L2_SCHEDULE,\n",
    "        \"gate_mode\": CONF_GATE_MODE,\n",
    "        \"gate_thresh\": CONF_GATE_THRESH,\n",
    "        \"emo_weights\": EMO_WEIGHTS_MODE,\n",
    "        \"best_val_macro_f1\": float(best_f1),\n",
    "        \"test_macro_f1\": float(test_report[\"macro_f1\"]),\n",
    "        \"test_acc\": float(test_report[\"acc\"]),\n",
    "        \"test_esi\": float(test_report[\"esi\"]),\n",
    "        \"test_worst_emotion_acc\": float(test_report[\"worst_acc\"]),\n",
    "        \"run_name\": run_name,\n",
    "        \"ckpt_dir\": ckpt_dir,\n",
    "        \"run_dir\": run_dir,\n",
    "    }\n",
    "    with open(os.path.join(run_dir, \"summary.json\"), \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    return best_path_student, run_name, summary\n",
    "\n",
    "# ---------------- SUITE: baseline + KD (NO GATE) per entrambi gli split ----------------\n",
    "def run_suite_emotion_nogate():\n",
    "    EXPS = [\n",
    "        # baseline\n",
    "        dict(run_id=\"E0_noKD\",\n",
    "             USE_L2_ML=False, LAMBDA_L2_TOP=0.0, LAMBDA_L2_MID=0.0,\n",
    "             L2_APPLY_PROB=0.0, L2_SCHEDULE='const',\n",
    "             CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "        # KD top+mid (base no-gate)\n",
    "        dict(run_id=\"E1b_noGate_both_base\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=1.0, LAMBDA_L2_MID=0.5,\n",
    "             L2_APPLY_PROB=1.0, L2_SCHEDULE='const',\n",
    "             CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "        # KD top-only\n",
    "        dict(run_id=\"E4_noGate_top_only\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=1.0, LAMBDA_L2_MID=0.0,\n",
    "             L2_APPLY_PROB=1.0, L2_SCHEDULE='const',\n",
    "             CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "        # KD light (debole + warmup + prob <1)\n",
    "        dict(run_id=\"E5_noGate_light\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=0.5, LAMBDA_L2_MID=0.25,\n",
    "             L2_APPLY_PROB=0.3, L2_SCHEDULE='warmup', L2_WARMUP_EPOCHS=5,\n",
    "             CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "        # KD mid-only\n",
    "        dict(run_id=\"E7_noGate_mid_only\",\n",
    "             USE_L2_ML=True, LAMBDA_L2_TOP=0.0, LAMBDA_L2_MID=0.5,\n",
    "             L2_APPLY_PROB=1.0, L2_SCHEDULE='const',\n",
    "             CONF_GATE_MODE='none', EMO_WEIGHTS_MODE='none'),\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    for split_key in [\"full_F0\", \"neutral_only_F0\"]:\n",
    "        for cfg in EXPS:\n",
    "            best_ckpt, run_name, summary = train_one_run_emotion_nogate(cfg, split_key=split_key)\n",
    "            results.append(summary)\n",
    "\n",
    "    # riassunto CSV cumulativo\n",
    "    df = pd.DataFrame(results).sort_values([\"split\",\"run\"])\n",
    "    os.makedirs(\"reports\", exist_ok=True)\n",
    "    out_csv = \"reports/emotion_kd_nogate_summary_all.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"\\n[Saved] {out_csv}\")\n",
    "    print(df[[\"run\",\"split\",\"test_macro_f1\",\"test_acc\",\"test_esi\",\"test_worst_emotion_acc\"]].to_string(index=False))\n",
    "\n",
    "# ==================== AVVIO ====================\n",
    "if __name__ == \"__main__\":\n",
    "    run_suite_emotion_nogate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7dbc1eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[BASE] N=49  Acc=0.469  Macro-F1=0.465\n",
      "    en  it  es\n",
      "en   5  13   3\n",
      "it   6  14   1\n",
      "es   0   3   4\n",
      "\n",
      "[BEST] N=49  Acc=0.531  Macro-F1=0.476\n",
      "    en  it  es\n",
      "en   2  14   5\n",
      "it   2  19   0\n",
      "es   0   2   5\n",
      "[OK] Saved: /Users/ludovicagenovese/Documents/GitHub/mothertongueVSspoken/Figure/capitolo 4/cm_emotionOFF_light.png\n",
      "[OK] Saved: /Users/ludovicagenovese/Documents/GitHub/mothertongueVSspoken/Figure/capitolo 4/dAcc_light_no_neutro.png\n",
      "[OK] Saved: /Users/ludovicagenovese/Documents/GitHub/mothertongueVSspoken/Figure/capitolo 4/dF1_light_no_neutro.png\n",
      "[OK] Saved: /Users/ludovicagenovese/Documents/GitHub/mothertongueVSspoken/reports_eval_only/emotion_deltas_neutral_only_F0_light_vs_nokd.csv\n",
      "[OK] Saved: /Users/ludovicagenovese/Documents/GitHub/mothertongueVSspoken/reports_eval_only/emotion_deltas_neutral_only_F0_light_vs_nokd_no_neutro.csv\n"
     ]
    }
   ],
   "source": [
    "# ============== EMOTION-OFF: CM + ΔAcc/ΔF1 direttamente dai CKPT ==============\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch.nn as nn\n",
    "\n",
    "# --- percorsi test & ckpt (dai tuoi log) ---\n",
    "TEST_CSV = DATA_SPLITS[\"neutral_only_F0\"][\"test\"]\n",
    "\n",
    "CKPT_BASE = \"ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\"\n",
    "CKPT_BEST = \"ckpts/E5_noGate_light__neutral_only_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\"\n",
    "\n",
    "# --- out dirs ---\n",
    "figdir = Path(\"Figure/capitolo 4\"); figdir.mkdir(parents=True, exist_ok=True)\n",
    "repodir = Path(\"reports_eval_only\"); repodir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- moduli \"dummy\" richiesti da evaluate_emotion (non usati in eval pura) ---\n",
    "proj_top = nn.Linear(512, 128)\n",
    "proj_mid = nn.Linear(512, 512)\n",
    "idn = nn.Identity()\n",
    "\n",
    "# --- run eval per baseline e best ---\n",
    "rep_base = evaluate_emotion(\n",
    "    csv_path=TEST_CSV, ckpt_path=CKPT_BASE,\n",
    "    proj_l11_top=proj_top, proj_l10_mid=proj_mid,\n",
    "    top_adapter=idn, mid_adapter=idn,\n",
    "    proj_dim=128, run_dir=None, title=\"BASE\"\n",
    ")\n",
    "rep_best = evaluate_emotion(\n",
    "    csv_path=TEST_CSV, ckpt_path=CKPT_BEST,\n",
    "    proj_l11_top=proj_top, proj_l10_mid=proj_mid,\n",
    "    top_adapter=idn, mid_adapter=idn,\n",
    "    proj_dim=128, run_dir=None, title=\"BEST\"\n",
    ")\n",
    "\n",
    "# ---------------- Matrice di confusione (best run: KD light) ------------------\n",
    "labels = [\"en\",\"it\",\"es\"]\n",
    "cm = confusion_matrix(rep_best[\"preds\"][\"y\"], rep_best[\"preds\"][\"yhat\"], labels=[0,1,2])\n",
    "\n",
    "plt.figure(figsize=(6,5.2))\n",
    "im = plt.imshow(cm, interpolation=\"nearest\")\n",
    "plt.title(\"KD light — CROSS-DOMAIN (Emotion-OFF)\")\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "tick_idx = np.arange(len(labels))\n",
    "plt.xticks(tick_idx, labels); plt.yticks(tick_idx, labels)\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "\n",
    "# annotazioni sulle celle\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, int(cm[i, j]),\n",
    "                 ha=\"center\", va=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "cm_path = figdir / \"cm_emotionOFF_light.png\"\n",
    "plt.savefig(cm_path, dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"[OK] Saved:\", cm_path.resolve())\n",
    "\n",
    "# --------------- ΔAcc / ΔF1 per emozione (KD light - NoKD) --------------------\n",
    "# ordina emozioni come in tesi\n",
    "EMO_TEX_ORDER = [\"sorpresa\",\"rabbia\",\"neutro\",\"gioia\",\"paura\",\"disgusto\",\"tristezza\"]\n",
    "order_map = {n:i for i,n in enumerate(EMO_TEX_ORDER)}\n",
    "\n",
    "m = rep_best[\"per_emotion\"].merge(rep_base[\"per_emotion\"], on=\"emotion\",\n",
    "                                  suffixes=(\"_kd\",\"_base\"))\n",
    "m[\"dAcc\"] = m[\"acc_kd\"] - m[\"acc_base\"]\n",
    "m[\"dF1\"]  = m[\"macro_f1_kd\"] - m[\"macro_f1_base\"]\n",
    "m[\"ord\"]  = m[\"emotion\"].map(order_map)\n",
    "m = m.sort_values(\"ord\").drop(columns=[\"ord\"])\n",
    "\n",
    "# --- Escludi 'neutro' SOLO per i grafici ---\n",
    "plot_df = m[m[\"emotion\"].str.lower() != \"neutro\"].copy()\n",
    "\n",
    "# ΔAcc (senza 'neutro')\n",
    "plt.figure(figsize=(6.2,3.2))\n",
    "plt.bar(plot_df[\"emotion\"], plot_df[\"dAcc\"])\n",
    "plt.axhline(0, linewidth=1)\n",
    "plt.ylabel(r\"$\\Delta$Acc\")\n",
    "plt.title(\"KD light — $\\Delta$Acc per Emozione (neutral\\\\_only\\\\_F0) — senza 'neutro'\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "dacc_path = figdir / \"dAcc_light_no_neutro.png\"\n",
    "plt.savefig(dacc_path, dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"[OK] Saved:\", dacc_path.resolve())\n",
    "\n",
    "# ΔF1 (senza 'neutro')\n",
    "plt.figure(figsize=(6.2,3.2))\n",
    "plt.bar(plot_df[\"emotion\"], plot_df[\"dF1\"])\n",
    "plt.axhline(0, linewidth=1)\n",
    "plt.ylabel(r\"$\\Delta$F1\")\n",
    "plt.title(\"KD light — $\\Delta$F1 per Emozione (neutral\\\\_only\\\\_F0) — senza 'neutro'\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "df1_path = figdir / \"dF1_light_no_neutro.png\"\n",
    "plt.savefig(df1_path, dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"[OK] Saved:\", df1_path.resolve())\n",
    "\n",
    "# salva i numeri in CSV: versione completa + versione senza 'neutro'\n",
    "full_csv = repodir / \"emotion_deltas_neutral_only_F0_light_vs_nokd.csv\"\n",
    "m.to_csv(full_csv, index=False)\n",
    "print(\"[OK] Saved:\", full_csv.resolve())\n",
    "\n",
    "no_neutro_csv = repodir / \"emotion_deltas_neutral_only_F0_light_vs_nokd_no_neutro.csv\"\n",
    "plot_df.to_csv(no_neutro_csv, index=False)\n",
    "print(\"[OK] Saved:\", no_neutro_csv.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e0e5c7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OK] Salvati:\n",
      "  - /Users/ludovicagenovese/Documents/GitHub/mothertongueVSspoken/Figure/capitolo 4/cm_emotionOFF_light.png\n",
      "  - /Users/ludovicagenovese/Documents/GitHub/mothertongueVSspoken/Figure/capitolo 4/dAcc_light.png\n",
      "  - /Users/ludovicagenovese/Documents/GitHub/mothertongueVSspoken/Figure/capitolo 4/dF1_light.png\n",
      "  - per-emozione CSV in /Users/ludovicagenovese/Documents/GitHub/mothertongueVSspoken/reports_eval_only/best__light__neutral_only_F0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# Eval per-emozione da checkpoint (EMODB Emotion-OFF) + figure pronte per la tesi\n",
    "# NIENTE argparse: modifica solo i path qui sotto.\n",
    "\n",
    "import os, math, json, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ────────────────────────────── CONFIG ──────────────────────────────\n",
    "DEVICE = torch.device('cpu')\n",
    "LANGS  = ['en','it','es']\n",
    "EMO_ID2NAME = {0:\"neutro\",1:\"rabbia\",2:\"disgusto\",3:\"paura\",4:\"gioia\",5:\"tristezza\",6:\"sorpresa\"}\n",
    "EMO_PLOT_ORDER = [\"sorpresa\",\"rabbia\",\"neutro\",\"gioia\",\"paura\",\"disgusto\",\"tristezza\"]  # per grafici\n",
    "\n",
    "# Dati EMODB – Emotion-OFF\n",
    "TEST_CSV = \"splits_session2/neutral_only_F0/test.csv\"\n",
    "\n",
    "# Checkpoint baseline (No KD) e best (KD light nei tuoi log)\n",
    "BASELINE_CKPT = \"ckpts/E0_noKD__neutral_only_F0__L20__top0__mid0__p0__schedconst__gatenone__emonone/best_student.pt\"\n",
    "BEST_CKPT     = \"ckpts/E5_noGate_light__neutral_only_F0__L21__top0.5__mid0.25__p0.3__schedwarmup__gatenone__emonone/best_student.pt\"\n",
    "BEST_TAG      = \"light\"   # usato nei nomi file: dAcc_light.png, dF1_light.png\n",
    "\n",
    "# Output figure/cartelle\n",
    "OUT_FIG_DIR = Path(\"Figure/capitolo 4\"); OUT_FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_REP_DIR = Path(\"reports_eval_only\");  OUT_REP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dimensioni input (come in train)\n",
    "L, OUT_H, OUT_W = 32, 64, 64\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "\n",
    "# ────────────────────────────── DATASET ──────────────────────────────\n",
    "class MouthDSEmotion(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, L=32):\n",
    "        df = pd.read_csv(csv_path).copy()\n",
    "        if 'mouth_path' in df.columns:\n",
    "            df = df.query('mouth_path.notna()').reset_index(drop=True)\n",
    "\n",
    "        # lingua → [0..2]\n",
    "        if 'lang' in df.columns:\n",
    "            df['label'] = df['lang'].astype(str).str.lower()\n",
    "        elif 'label' in df.columns:\n",
    "            df['label'] = df['label'].astype(str).str.lower()\n",
    "        else:\n",
    "            raise ValueError(\"Manca colonna lingua: attesa 'lang' o 'label'.\")\n",
    "\n",
    "        # emozione testo\n",
    "        if 'emotion' not in df.columns and 'emotion_id' in df.columns:\n",
    "            df['emotion'] = df['emotion_id'].map(EMO_ID2NAME)\n",
    "        df['emotion'] = df['emotion'].astype(str)\n",
    "\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.L  = L\n",
    "        self.lab2i = {l:i for i,l in enumerate(LANGS)}\n",
    "\n",
    "    def _align(self, a):\n",
    "        T0 = a.shape[0]\n",
    "        if T0 >= self.L:\n",
    "            idx = np.linspace(0, T0-1, self.L).astype(int)\n",
    "        else:\n",
    "            idx = np.concatenate([np.arange(T0), np.full(self.L-T0, T0-1)])\n",
    "        return a[idx]\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        r = self.df.iloc[i]\n",
    "        a = np.load(r.mouth_path, allow_pickle=True).astype('float32')\n",
    "        if a.ndim==4 and a.shape[-1]==3: a = a.mean(-1)\n",
    "        if a.max() > 1.0: a = a/255.0\n",
    "        a = self._align(a)              # [L,H,W]\n",
    "        v = torch.from_numpy(a).unsqueeze(0).unsqueeze(0)  # [1,1,L,H,W]\n",
    "        v = F.interpolate(v, size=(L,OUT_H,OUT_W), mode='trilinear', align_corners=False)\n",
    "        x = (v - 0.5)/0.5               # normalize to [-1,1]\n",
    "        x = x.squeeze(0)                # [1,L,H,W]\n",
    "        y = torch.tensor(self.lab2i[str(r.label).lower()], dtype=torch.long)\n",
    "        emo = str(r.emotion)\n",
    "        return x, y, emo\n",
    "\n",
    "\n",
    "def collate(batch):\n",
    "    xs, ys, emos = [], [], []\n",
    "    for x,y,emo in batch:\n",
    "        xs.append(x); ys.append(y); emos.append(emo)\n",
    "    return torch.stack(xs,0), torch.stack(ys,0), emos\n",
    "\n",
    "\n",
    "# ────────────────────────────── MODELLO ──────────────────────────────\n",
    "class Identity(nn.Module):\n",
    "    def forward(self, x): return x\n",
    "\n",
    "class Student(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        from torchvision.models.video import r3d_18, R3D_18_Weights\n",
    "        try:\n",
    "            bb = r3d_18(weights=R3D_18_Weights.DEFAULT)\n",
    "        except Exception:\n",
    "            bb = r3d_18(weights=None)\n",
    "        bb.fc = nn.Identity()\n",
    "        self.backbone = bb\n",
    "        self.mixstyle = Identity()  # in eval è neutro\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Linear(512,256), nn.GELU(), nn.Dropout(0.1),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: [B,1,L,H,W]\n",
    "        x = x.repeat(1,3,1,1,1)\n",
    "        f = self.backbone(x)\n",
    "        f = self.mixstyle(f)\n",
    "        logits = self.head(f)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# ────────────────────────────── EVAL ──────────────────────────────\n",
    "def evaluate(csv_path, ckpt_path, title, out_prefix):\n",
    "    ds = MouthDSEmotion(csv_path, L=L)\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                                     num_workers=0, pin_memory=False, collate_fn=collate)\n",
    "\n",
    "    model = Student(num_classes=len(LANGS)).to(DEVICE)\n",
    "    state = torch.load(ckpt_path, map_location=DEVICE)\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred, emos = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x,y,emo in dl:\n",
    "            x = x.to(DEVICE)\n",
    "            logits = model(x)\n",
    "            y_pred += logits.argmax(1).cpu().tolist()\n",
    "            y_true += y.cpu().tolist()\n",
    "            emos   += list(emo)\n",
    "\n",
    "    # confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(LANGS))))\n",
    "\n",
    "    # per-emozione\n",
    "    df = pd.DataFrame({\"y\":y_true, \"yhat\":y_pred, \"emotion\":emos})\n",
    "    rows=[]\n",
    "    for emo,g in df.groupby(\"emotion\"):\n",
    "        acc = accuracy_score(g.y, g.yhat)\n",
    "        mf1 = f1_score(g.y, g.yhat, average=\"macro\")\n",
    "        rows.append({\"emotion\":emo, \"acc\":acc, \"macro_f1\":mf1})\n",
    "    per_emo = pd.DataFrame(rows).sort_values(\"emotion\")\n",
    "    repdir = OUT_REP_DIR / out_prefix; repdir.mkdir(parents=True, exist_ok=True)\n",
    "    per_emo.to_csv(repdir / \"TEST__per_emotion.csv\", index=False)\n",
    "\n",
    "    # CM figure: NO griglia, colorbar a destra, annotazioni intere\n",
    "    fig, ax = plt.subplots(figsize=(6.2,6.2), dpi=160)\n",
    "    im = ax.imshow(cm, interpolation='nearest')\n",
    "    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)  # legenda a destra\n",
    "    cbar.ax.set_ylabel('Count', rotation=90, va='center')\n",
    "\n",
    "    ax.set_title(f\"{title}\", pad=14)\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
    "    ax.set_xticks(np.arange(len(LANGS))); ax.set_yticks(np.arange(len(LANGS)))\n",
    "    ax.set_xticklabels(LANGS); ax.set_yticklabels(LANGS)\n",
    "\n",
    "    # niente linee bianche\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    ax.grid(False)\n",
    "\n",
    "    # annotazioni\n",
    "    for i in range(len(LANGS)):\n",
    "        for j in range(len(LANGS)):\n",
    "            ax.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\", fontsize=11)\n",
    "\n",
    "    out_cm = OUT_FIG_DIR / f\"cm_emotionOFF_{BEST_TAG}.png\"\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_cm, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # metriche totali\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    mf1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    summary = {\"N\":len(y_true), \"acc\":acc, \"macro_f1\":mf1}\n",
    "    with open(repdir / \"summary.json\", \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    return per_emo, cm, summary\n",
    "\n",
    "\n",
    "def bar_delta(per_base: pd.DataFrame, per_best: pd.DataFrame, metric: str, fname: Path, title: str):\n",
    "    m = per_best.merge(per_base, on=\"emotion\", suffixes=(\"_best\",\"_base\"))\n",
    "    m[\"delta\"] = m[f\"{metric}_best\"] - m[f\"{metric}_base\"]\n",
    "    # ordina per la sequenza desiderata (se manca un'emozione, la salta)\n",
    "    m[\"ord\"] = m[\"emotion\"].map({n:i for i,n in enumerate(EMO_PLOT_ORDER)})\n",
    "    m = m.sort_values(\"ord\")\n",
    "    xs = list(m[\"emotion\"].str.capitalize())\n",
    "    ys = list(m[\"delta\"])\n",
    "\n",
    "    plt.figure(figsize=(6.6,3.4), dpi=160)\n",
    "    bars = plt.bar(xs, ys)\n",
    "    plt.axhline(0, linewidth=1)\n",
    "    plt.ylabel(f\"Δ{metric.upper()} (best − base)\")\n",
    "    plt.title(title)\n",
    "    # etichette sopra/sotto\n",
    "    for b,val in zip(bars, ys):\n",
    "        plt.text(b.get_x()+b.get_width()/2, b.get_height()+ (0.01 if val>=0 else -0.01),\n",
    "                 f\"{val:+.2f}\", ha='center', va='bottom' if val>=0 else 'top', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) baseline\n",
    "    per_base, cm_base, s_base = evaluate(\n",
    "        TEST_CSV, BASELINE_CKPT,\n",
    "        title=\"No KD — Emotion-OFF (neutral_only_F0)\",\n",
    "        out_prefix=\"E0_noKD__neutral_only_F0\"\n",
    "    )\n",
    "    # 2) best\n",
    "    per_best, cm_best, s_best = evaluate(\n",
    "        TEST_CSV, BEST_CKPT,\n",
    "        title=f\"KD {BEST_TAG} — Emotion-OFF (neutral_only_F0)\",\n",
    "        out_prefix=f\"best__{BEST_TAG}__neutral_only_F0\"\n",
    "    )\n",
    "\n",
    "    # 3) Δ per emozione (best − baseline)\n",
    "    bar_delta(per_base, per_best, \"acc\",\n",
    "              OUT_FIG_DIR / f\"dAcc_{BEST_TAG}.png\",\n",
    "              title=f\"{BEST_TAG} — ΔAcc per Emozione (neutral_only_F0)\")\n",
    "    bar_delta(per_base, per_best, \"macro_f1\",\n",
    "              OUT_FIG_DIR / f\"dF1_{BEST_TAG}.png\",\n",
    "              title=f\"{BEST_TAG} — ΔF1 per Emozione (neutral_only_F0)\")\n",
    "\n",
    "    print(\"\\n[OK] Salvati:\")\n",
    "    print(\"  -\", (OUT_FIG_DIR / f\"cm_emotionOFF_{BEST_TAG}.png\").resolve())\n",
    "    print(\"  -\", (OUT_FIG_DIR / f\"dAcc_{BEST_TAG}.png\").resolve())\n",
    "    print(\"  -\", (OUT_FIG_DIR / f\"dF1_{BEST_TAG}.png\").resolve())\n",
    "    print(\"  - per-emozione CSV in\", (OUT_REP_DIR / f\"best__{BEST_TAG}__neutral_only_F0\").resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
